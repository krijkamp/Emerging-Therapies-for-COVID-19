---
title: "Making Drug Approval Decisions in the face of Uncertainty: Cumulative Evidence versus Value of Information"  
output:
  word_document: default
  html_document: default
---
# Project information
This code, downloaded from https://github.com/krijkamp/Emerging-Therapies-for-COVID-19, is part of the paper Making Drug Approval Decisions in the face of Uncertainty: Cumulative Evidence versus Value of Information published in Medical Decision Making.

The code is part of a larger project on the evaluation of emerging COVID-19 therapies, for which we refer to our earlier publication:
Dijk, S. W., Krijkamp, E. M., Kunst, N., Gross, C. P., Wong, J. B., & Hunink, M. M. (2022). Emerging therapies for COVID-19: the value of information from more clinical trials. Value in Health, 25(8), 1268-1280. Available from: https://www.valueinhealthjournal.com/article/S1098-3015(22)00158-9/fulltext 

This section runs the main analysis.

# Checklist before running the code:
- Have you set the pathways to files that are loaded to the correct pathways (for example ./data/filename.RData or ../data/filename.RData)
- Have you created a backup (if you wanted to)?
- Has the correct version of parameters been selected?
- Have you run the Meta-analysis you wished to run in the meta-analysis code, or selected the default main analysis?
- Has the latest dataset for hospitalizations been imported from IHME? Did any new dataset predictions end in peaks, and have you added these to the peaklist?
- Did you select whether to run the analysis with or without extended peak data?
- Has the correct ordering been applied (based on date, alphabetic, based on result)
- Has the correct number of iterations for the PA been selected? Note: The process can be computationally intense. May not work optimally with Mac OS Ventura. The default setting is 10.000 iterations. For trial runs, choose a lower number for faster completion, however do not choose a number lower than 10 to prevent issues in the VOI section of the code.
- Are any of chunks of code that have been turned to Eval = FALSE that shouldn't be? Note: Some code-chunks have been deactivated as they are only relevant once, but not every time when the full code is re-run. This option is especially relevant when only small (visual) changes have been made that do not require the PA to re-run.


# 00 Clean global environment
```{r, eval = FALSE}
# Clean list
rm(list = ls())
```

## 00 Choose options to run main or sensitivity analysis
```{r}
# Sensitivity analysis
n_iter                 <- 10      # number of iterations for the PA. Note, depending on the computer on which the model is run this can take between 0.5 to 2 hours. For "quick checks" to see whether the model works, we recommend temporarily tuning this number down. For more reliable results, we recommend running (at least) 10000 iterations. This number should not be set to less than 10 to prevent the VOI code from not working
trial_duration         <- 2 # trial duration in months; note: the current IHME datasets at times only have predictions of 4 months, we therefore chose to set the number of months for current patients to 2 so that at least half the predictin time is dedicated to future patients; In sensitivity analyses or future analyses with new, longer predictions, you may want to consider assigning more time to the trial being conducted, results being reported and a new decision being made on starting a new trial or implementation.
extended_peak_analysis <- "Yes" #"Yes #"No" # This parameter represents whether if the IHME predictions end mid-peak, whether the peak should be extended (mirrored) based on the common epidemiological principle that in pandemics peaks rise and fall.
ma_analysis_type       <- "CMA"   #"CMA" # "CMA" "CMA FDA" "CMA IL6" "Traditional MA""Traditional MA FDA", "CMA Nonadjusted"
sa_suffixes            <- "cma_full" # Write here the suffix under which you would like to save the sensitivity analysis in the SA folder; This can also be used for debugging purposes if you would like to compare the outcomes of two versions of the code

wtp_level_main              <- 100000 # Choose WTP level, consider 100000 and 150000  for base analysis
```

## 00 Knitting setup
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "./") # set working directory to the root directory rather than another sub-folder where the RMarkdown file is saved
```

# 01 Load packages
```{r, eval = TRUE, echo = FALSE, warning = FALSE, message = FALSE}
if (!require('pacman')) install.packages('pacman'); library(pacman) 
# use this package to conveniently install other packages
p_load("matrixStats", "ggplot2", 
        "scales",  "reshape2",
        "nlme", "mgcv", "BCEA", 
        "inlabru", "devtools",
        "tibble", "tidyverse", "ggpubr",
        "rms", "europepmc", "xaringan", "Rmisc",
        "fmsb", "remotes", "readxl", "plyr", "stats", "triangle",
        "EnvStats", "e1071", "meta","metafor","gridExtra", 
        "here", "dplyr","ellipse", "ggplot2","lazyeval", 
        "igraph", "ggraph","knitr", "plyr", "stats", "diagram",
        "triangle", "HMDHFDplus", "blscrapeR", "here", "gridExtra", "foreach", "mondate", "parallel", "imguR", "readr", "lubridate", "DescTools", "vistime", "tictoc", "mondate", "cowplot", "grid", "writexl", "readxl", "patchwork", "magick")

# install_github("DARTH-git/dampack", force = TRUE) # Uncomment if there is a newer version
# install_github("DARTH-git/darthpack", force = TRUE) # Uncomment if there is a newer version
# install_github("DARTH-git/darthtools", force = TRUE) # Uncomment if there is a newer version #NOTE! requires the newest devtools and R version 
# devtools::install_github("collectivemedia/tictoc") # install to measure the time

p_load_gh("DARTH-git/dampack") # coding framework to construct model-based cost-effectiveness analysis in R
p_load_gh("DARTH-git/darthpack") # package for analyzing and visualizing the health economic outputs of mathematical models
p_load_gh("DARTH-git/darthtools") # a R package that contains tools frequently used by the DARTH workgroup
p_load_gh("collectivemedia/tictoc") # package to measure the time of an analysis 
```


# 02 Load functions
```{r, eval = TRUE, echo = FALSE, warning = FALSE, message = FALSE}
# General functions are now in darthtools
source("../functions/00_general_mycolour.R")
source("../functions/00_general_format_table_function.R")
source("../functions/01_model_input_data_hospitalization_functions.R") # functions for the model
source("../functions/01_model_inputs_functions.R")  # functions for the data
# source("../functions/01_smaller_ihme_dataset.R") # function that transforms large .csv files from ihme website into the specific RData required. Uncomment this function if the raw data is used instead of the provided files
source("../functions/02_decision_model_functions.R") # functions for model structure & to run the model 
source("../functions/02_decision_model_plot_functions.R") # plot functions
source("../functions/02_decision_model_calcout_functions.R") # the entire model
source("../functions/05a_probabilistic_analysis_functions.R")   # functions for the PSA
source("../functions/06_VOI_functions.R")   # functions for the VOI
source("../functions/06_VOI_ENB_functions.R")

```

# 03 Input parameters 

## 03.1.1 External 
```{r, eval = TRUE}
# Note: The Rx data is imported directly from the meta-analysis code

# Load dataset for main analysis (CMA) or the chosen sensitivity analysis
if (ma_analysis_type == "CMA") {
  load(file = "../output/rr_ci_full.RData")
  load(file = "../output/rr_ci_qual_full.RData")
  #rr_ci <- rr_ci
  #rr_ci_qual <- rr_ci_qual_full
  rr_ci <- rr_ci
  rr_ci_qual <- rr_ci_qual
} else if (ma_analysis_type == "CMA FDA") {
  load(file = "../output/rr_ci_FDA.RData")
  load(file = "../output/rr_ci_qual_FDA.RData")
  rr_ci <- rr_ci_FDA
  rr_ci_qual <- rr_ci_qual_FDA
} else if (ma_analysis_type == "CMA Nonadjusted") {
  load(file = "../output/rr_ci_full_nonadj.RData")
  load(file = "../output/rr_ci_qual_full_nonadj.RData")
  rr_ci <- rr_ci_full_nonadj
  rr_ci_qual <- rr_ci_qual_full_nonadj
} else if (ma_analysis_type == "Traditional MA") {
  load(file = "../output/rr_ci_full_trad.RData")
  load(file = "../output/rr_ci_qual_full_trad.RData")
  rr_ci <- rr_ci_full_trad
  rr_ci_qual <- rr_ci_qual_full_trad
} else if (ma_analysis_type == "Traditional MA FDA") {
  load(file = "../output/rr_ci_FDA_trad.RData")
  load(file = "../output/rr_ci_qual_FDA_trad.RData")
  rr_ci <- rr_ci_FDA_trad
  rr_ci_qual <- rr_ci_qual_FDA_trad
} else if (ma_analysis_type == "CMA IL6") {
  load(file = "../output/rr_ci_IL6.RData")
  load(file = "../output/rr_ci_qual_IL6.RData")
  rr_ci <- rr_ci_IL6
  rr_ci_qual <- rr_ci_qual_IL6
} else {
  cat("Invalid input for ma_analysis_type.\n")
}


#### Load data ####
param       <- data.frame(readxl::read_xlsx("../data/parameters_cumulative_4.xlsx", 
                                            sheet = "cohort")) # Parameters relating to the study population
param_trt   <- data.frame(readxl::read_xlsx("../data/parameters_cumulative_4.xlsx", 
                                            sheet = "Rx")) # Parameters relating to treatment

param_trt <- rbind(param_trt, rr_ci)

# Use excel loading if qualitative parameters are added as excel structure
#param_qual <- readxl::read_xlsx("../data/parameters_cumulative_2.xlsx",  sheet = "Rx_qual",    col_types = c("text")) # Qualitative parameters relating to treatment
param_qual <- rr_ci_qual


df_r_HD     <- read.csv("../data/USA_Mx_1x1_2017.csv", sep = ",")

# df_trials_NMA <- data.frame(readxl::read_xls("../data/data_files_upload_covid_nma_database_2021-03-03.xls")) # Uncomment if interested in reviewing new emerging trials registry

param_trt
param_qual

color_print <- "#dfb94c"

```


### 03.1.2 Remove parameters without unit
```{r}
# Use the function to remove the values without a unit and change to numeric value
param     <- remove_param_without_unit(df_param = param)
param_trt <- remove_param_without_unit(df_param = param_trt)
param_qual # do not with bovementioned function, this set contains qualitative data

# Document which parameters do not have a unit
param_NA <- param_qual[which(is.na(param_qual$Unit)), ]
# Remove parameters without unit
df_param <- param_qual[!is.na(param_qual$Unit), ]
param_qual <- df_param

# This step is relevant to remove for example empty rows in the datafile that make the file more readable in Excel
param_qual
```

### 03.1.3 Adjust qualitative dataset
```{r}

# select rows where "Param" is "rct_start", "rct_end" or "rct_publ"
rct_dates <- param_qual[param_qual$Param %in% c("rct_start", "rct_end", "rct_publ"), ]
rct_dates$Med <- as.Date(rct_dates$Med, format = "%d_%m_%Y")
rct_dates$Med <- format(rct_dates$Med, format = "%Y-%m-%d")

# print the resulting data frame
param_qual[param_qual$Param %in% c("rct_start", "rct_end", "rct_publ"), ] <- rct_dates

param_qual


# Get publication dates
# Select rows where the value in the "Param" column is "rct_publ" and keep only specific columns
param_qual_rctpubl <- param_qual %>%
  filter(Param == "rct_start") %>%
  select(Treatment, Param, Med)

param_qual_rctpubl
param_qual_rctpubl_time <- param_qual_rctpubl[order(param_qual_rctpubl$Med),]

# Note: One could also repeat the meta analysis and sort the results based on startdate. In our case, we use the publication date as this is the date when the information becomes available to decision makers

param_qual_rctpubl_time
v_names_time <- param_qual_rctpubl_time$Treatment


param_qual_n_enrolled <- param_qual %>%
  filter(Param == "N_cumsum") %>%
  select(Treatment, Param, Med)
v_enrolled_cumsum <- as.numeric(param_qual_n_enrolled$Med)
```


### 03.1.4 Load new hospital data if a new updated file exists

Use the first (by default eval = FALSE) chunk if downloading new datasets from the IHME website. Use the second chunk to skip this process and immediately import the saved and converted .RData files

The following datasets are available on https://www.healthdata.org/node/8787
For 2020
March 25, 2020 | March 26, 2020 | March 27, 2020 | March 29, 2020 | March 30, 2020 | March 31, 2020 | April 1, 2020 | April 5, 2020 | April 7, 2020 | April 8, 2020 | April 10, 2020 | April 13, 2020 | April 17, 2020 | April 21, 2020 | April 22, 2020 | April 27, 2020 | April 28, 2020 | April 29, 2020 | May 4, 2020 | May 10, 2020 | May 12, 2020 | May 20, 2020 | May 25, 2020 | May 26, 2020 | May 29, 2020 | June 5, 2020 | June 8, 2020 | June 10, 2020 | June 15, 2020 | June 25, 2020 | June 29, 2020 | July 7, 2020 | July 14, 2020 | July 22, 2020 | July 30, 2020 | August 06, 2020 | August 21, 2020 | August 27, 2020 | September 03, 2020 | September 11, 2020 | September 18, 2020 | September 24, 2020 | October 2, 2020 | October 9, 2020 | October 15, 2020 | October 22, 2020 | October 29, 2020 | November 12, 2020 | November 19, 2020 | December 3, 2020 | December 10, 2020 | December 17, 2020 | December 23, 2020 

For 2021
January 15, 2021 | January 22, 2021 | January 28, 2021 | February 4, 2021 | February 12, 2021 | February 20, 2021 | February 25, 2021 | March 6, 2021 | March 11, 2021 | March 17, 2021 | March 25, 2021 | April 1, 2021 | April 9, 2021 | April 16, 2021 | April 23, 2021 | April 30, 2021 | May 6, 2021 | May 14, 2021 | May 21, 2021 | May 28, 2021 | June 4, 2021 | June 10, 2021 | June 18, 2021 | June 25, 2021 | July 2, 2021 | July 15, 2021 | July 23, 2021 | July 30, 2021 | August 6, 2021 | August 20, 2021 | August 26, 2021 | September 2, 2021 | September 10, 2021 | September 16, 2021| September 23, 2021 | September 30, 2021 | October 15, 2021 | October 21, 2021 | November 4, 2021 | November 19, 2021 | December 21, 2021

The selected dataset in the prospective analysis is the last available dataset at the date of publication. For example: for a paper published on April 3rd, the dataset of April 1st will be used.
Publication sets that were pre-downloaded and converted to .csv files in the current project (left: publication date, right: dataset):
2020
"2020-09-12 UTC" =  # ihme_2020_09_11
"2020-09-28 UTC" =  # ihme_2020_09_24
"2020-10-20 UTC" =  # ihme_2020_10_15
"2020-10-23 UTC" =  # ihme_2020_10_22
"2020-12-02 UTC" =  # ihme_2020_11_19
2021
"2021-01-09 UTC" =  # ihme_2020_12_23
"2021-01-20 UTC" =  # ihme_2021_01_15
"2021-02-11 UTC" =  # ihme_2021_02_04
"2021-03-04 UTC" =  # ihme_2021_02_25
"2021-03-17 UTC" =  # ihme_2021_03_17 
"2021-05-05 UTC" =  # ihme_2021_04_23 #Note: the dataset 2021_04_30 contains no data (as of February 2021)
"2021-09-08 UTC" =  # ihme_2021_09-02
"2021-10-29 UTC" =  # ihme_2021_10_21
"2021-12-10 UTC" =  # ihme_2021_11_19
Retrospective (end of timeline, last available dataset)
"2021-12-31 UTC" = ihme_2021_12_21
Remdacta (FDA sensitivity analysis)
"2021-10-05 UTC" = ihme_2021_09_30


Steps to import new IHME datasets:
Download original/desired/latest file from http://www.healthdata.org/covid/data-downloads or historic predictions from https://www.healthdata.org/node/8787 and save in data folder. Save each prediction file (named reference_hospitalization_all_locs or similar, note that this changes across datasets) in the following format: "ihme_2020_03_25.csv"
If two datasets exist for 2020 and 2021 seperately, download both and name them a and b; This is necessary as the IHME split datasets into two parts for later dates.



Note: the dataset 2021_04_30 contains no data (as of February 2021)

Run the following chunk
```{r, eval = FALSE}

## Select all filenames from folder where information on hospitalizations is saved
file_list <- list.files("../data/reference_hospitalization_all_locs_timeline")
# Store as vector
file_list <- as.vector(file_list)
# Select only those that include ihme
file_list <- file_list[grepl("ihm", file_list) & grepl("csv", file_list)]

#file_name <- file_list[15:17] #use for debugging to find out which datasets give any errors

# Loop over the file list and process each file
for (file_name in file_list) {
  # Load the CSV file
  data <- read.csv(paste0("../data/reference_hospitalization_all_locs_timeline/", file_name), header=TRUE, stringsAsFactors=FALSE)
  
  # Subset the data to only include rows where location_name is "United States of America"
  data_subset <- data[data$location_name == "United States of America", ]
  
  # Rename 'date_reported' column to 'date' if it exists
  # This is needed as there are some variations of this column across the datasets
  if ("date_reported" %in% colnames(data_subset)) {
    colnames(data_subset)[which(colnames(data_subset) == "date_reported")] <- "date"
  }
  
  # Keep only the columns we want
  data_subset <- data_subset[, c("date", "admis_mean", "admis_upper", "admis_lower")]
  
  # Save specific data subset
  
  
  # Save the subsetted data as an RData file
  save(data_subset, file = paste0("../data/reference_hospitalization_all_locs_timeline/", gsub(".csv", ".RData", file_name)))
}

# Create an empty data frame to store the results
ihme_range <- data.frame(file_name = character(),
                      first_date = character(),
                      last_date = character(),
                      stringsAsFactors = FALSE)

for (file_name in file_list) {
  # Load the RData file
  load(paste0("../data/reference_hospitalization_all_locs_timeline/", gsub(".csv", ".RData", file_name)))
  
  # Assign the loaded data to the file name without the extension
  assign(gsub(".csv", "", file_name), data_subset)
  
  # Get the first and last dates
  first_date <- as.character(range(data_subset$date)[1])
  last_date <- as.character(range(data_subset$date)[2])
  
  # Add the results to the data frame
  ihme_range <- rbind(ihme_range, data.frame(file_name = file_name,
                                       first_date = first_date,
                                       last_date = last_date,
                                       stringsAsFactors = FALSE))
  
}
ihme_range

```




### 03.1.4 Load  hospital data 
Run the previous chunk if new IHME datasets were downloaded, run this chunk always
```{r, eval = TRUE}

## Select all filenames from folder where information on hospitalizations is saved
file_list <- list.files("../data/reference_hospitalization_all_locs_timeline")
# Store as vector
file_list <- as.vector(file_list)
# Select only those that include ihme
file_list <- file_list[grepl("ihm", file_list) & grepl("RData", file_list)]

# Create an empty data frame to store the results
ihme_range <- data.frame(file_name = character(),
                      first_date = character(),
                      last_date = character(),
                      stringsAsFactors = FALSE)

data_list <- list()


for (file_name in file_list) {
  # Load the RData file
  load(paste0("../data/reference_hospitalization_all_locs_timeline/", gsub(".csv", ".RData", file_name)))
  
  # Assign the loaded data to the file name without the extension
  assign(gsub(".csv", "", file_name), data_subset)
  
  # Get the first and last dates
  first_date <- as.character(range(data_subset$date)[1])
  last_date <- as.character(range(data_subset$date)[2])
  
  # Add the results to the data frame
  ihme_range <- rbind(ihme_range, data.frame(file_name = file_name,
                                       first_date = first_date,
                                       last_date = last_date,
                                       stringsAsFactors = FALSE))
  # Add the loaded data to the list
  data_list[[file_name]] <- data_subset
  
}
ihme_range

# Note: Latest files contain only one year (2020 or 2021), which is why for the retrospective analyses the last two datasets must be combined
ihme_2021_12_21 <- rbind(ihme_2021_12_21a.RData,ihme_2021_12_21b.RData)
ihme_2021_09_30 <- rbind(ihme_2021_09_30a.RData,ihme_2021_09_30b.RData)
ihme_2021_11_19 <- rbind(ihme_2021_11_19a.RData,ihme_2021_11_19b.RData)
ihme_2021_10_21 <- rbind(ihme_2021_10_21a.RData,ihme_2021_10_21b.RData)

# Replace data_list items with complete datasets

###1
data_list$ihme_2021_12_21.RData <- ihme_2021_12_21

if ("ihme_2021_12_21a.RData" %in% names(data_list)) {
  data_list[["ihme_2021_12_21a.RData"]] <- NULL
  rm(ihme_2021_12_21a)
}
if ("ihme_2021_12_21b.RData" %in% names(data_list)) {
  data_list[["ihme_2021_12_21b.RData"]] <- NULL
  rm(ihme_2021_12_21b)
}

###2
# Replace data_list items with complete datasets
data_list$ihme_2021_09_30.RData <- ihme_2021_09_30

if ("ihme_2021_09_30a.RData" %in% names(data_list)) {
  data_list[["ihme_2021_09_30a.RData"]] <- NULL
  rm(ihme_2021_09_30a)
}
if ("ihme_2021_09_30b.RData" %in% names(data_list)) {
  data_list[["ihme_2021_09_30b.RData"]] <- NULL
  rm(ihme_2021_09_30b)
}

###3
# Replace data_list items with complete datasets
data_list$ihme_2021_11_19.RData <- ihme_2021_11_19

if ("ihme_2021_11_19a.RData" %in% names(data_list)) {
  data_list[["ihme_2021_11_19a.RData"]] <- NULL
  rm(ihme_2021_11_19a)
}
if ("ihme_2021_11_19b.RData" %in% names(data_list)) {
  data_list[["ihme_2021_11_19b.RData"]] <- NULL
  rm(ihme_2021_11_19b)
}

###4
# Replace data_list items with complete datasets
data_list$ihme_2021_10_21.RData <- ihme_2021_10_21

if ("ihme_2021_10_21a.RData" %in% names(data_list)) {
  data_list[["ihme_2021_10_21a.RData"]] <- NULL
  rm(ihme_2021_10_21a)
}
if ("ihme_2021_10_21b.RData" %in% names(data_list)) {
  data_list[["ihme_2021_10_21b.RData"]] <- NULL
  rm(ihme_2021_10_21b)
}

names(data_list)

# Check code: Show the heads of all datasets in this list
# lapply(data_list, head)

# Check datastructure for all datasets
# for (i in 1:length(data_list)) {
#    cat(paste0("Dataset ", i, ":\n"))
#    str(data_list[[i]])}

```

### 03.1.5 Substract names 
```{r}
l_names <- list()
v_names_time # chronological list
v_names_time_trt <- c("All", v_names_time)

#time_order <- intersect(time_order, l_names$v_names_trt_report_full)

# If sorting alphabetically rather than chronologically (This is not what we do for the cumulative VOI, but what could be done when running all treatments seperately rather than cumulatively)

#l_names$names_notrt <- names_notrt<- sort(unique(param$Treatment))  # subtract the treatment names and order them in alphabetic order 
#l_names$names_treatment <- names_treatment<- sort(unique(param_trt$Treatment))  # subtract the treatment names and order them in alphabetic order 
#l_names$names_trt <- names_trt <- v_names_trt <- names_treatment[-(names_treatment == "All")] # names of the treatments without the parameters that are applicable for all 

# If sorting chronologically
l_names$names_notrt <- names_notrt<- (unique(param$Treatment))  # usual care
l_names$names_treatment <- names_treatment <- v_names_time_trt  # subtract the treatment names and order them in alphabetic order 
l_names$names_trt <- names_trt <- v_names_trt <- names_treatment[-(names_treatment == "All")] # names of the treatments without the parameters that are applicable for all 


save(v_names_trt, file = "../output/v_names_trt.rda")

# The county data is not used in the analysis at this moment in time. In future analyses we may consider adding additional perspectives.
#l_names$names_countries     <- names_countries <- sort(unique(param$Country))  # select the country names
#l_names$names_countries_trt <- names_countries_trt <- sort(unique(param_trt$Country)) # select the country names


# Select the parameters of interest for the reporting
# Please note -> needs to be update if the order changes
# l_names$v_names_trt_report <- v_names_trt[c(1:5, 8, 9)]  # Select values when the excel has more treatments than needed
l_names$v_names_trt_report <- v_names_trt
v_names_trt_report_full <- l_names$v_names_trt_report

l_names$v_names_trt_report_full <- as.vector(sapply(l_names$v_names_trt_report, remove_date_from_name))
#l_names$v_names_trt_report_full[[7]] <- substr(l_names$v_names_trt_report_full[[7]], start=1, stop = 11)
# Treatments were saved in the excel with specific dates to allow comparison of specific treatments as more evidence becomes available over time. In the current paper, we only demonstrate one result per treatment option.

save(l_names, file = "../output/l_names.rda") # save the list with all the treatment names
```


### 03.1.6  Load cohort data into environment 
Note, this is an in-between step, that will repeated after the hospitalization data is loaded, to correctly load this data into the list param treat for both the base case and the PSA
```{r}
# Get the median parameter values from the usual care/cohort into the R environment

l_param     <- split_df_to_lists_mean_param(df_param = param)
l_param_all <- split_df_to_lists_mean_param(df_param = param_trt) # run the function 

# Merge all the parameters from one specific treatment/to all the drug specific lists.
# For example some treatment specific values are relevant for all drugs. This is indicated by the # "All" meaning apply to all. 
l_param_trt <- combine_lists(list = l_param_all, combine = "All")

for (n in names(l_param_trt)){
l_param_trt[[n]] <- c(l_param_trt[[n]], l_param$usual_care)
}

``` 



### 03.1.8 Calculate number of hospitalizations - Retrospective 
```{r}
# Download latest file from http://www.healthdata.org/covid/data-downloads and save in data folder. 
# Download previous files from https://www.healthdata.org/node/8787

# Dataset for hospitalization: 
ihme_date_retrospective  <- "2021_12_21"
df_hosp_usa_retrospective <- ihme_2021_12_21
df_hosp_usa <- df_hosp_usa_retrospective

# Select the names in the list with the parameters
names(l_param_trt)
# These names contain the dates of the published studies
# For this dates we like to get the predicted number of hospitalizations from the full dataset 
# This means we are "looking back in history" about what have been the true cases


# Created a function to get the date from the name
subtract_date_from_name <- function(name, date = "01_01_2020"){
  # name: The name of the list 
  # date: This is an argument that indicates how the date is structured in the name. This is manly important for the number of characters. Specific order or low/high dashes are not considered.  

  n_char_name_trt <- nchar(name) # lenght of the full name
  n_char_data     <- nchar(date) # lenght of the date 
  
  # Substract only the last part from the name
  n_new_name_trt  <- substr(name,
                            start = (n_char_name_trt - n_char_data + 1), 
                            stop = n_char_name_trt)
  return(n_new_name_trt) # return the last part of the name, which is the date
  
}

# check if the function only gives names
subtract_date_from_name(names(l_param_trt))
# This will be added to the loop

# the structure param_trt is used a lot in the analysis
summary(param_trt) # Get a summary of the data 

for (n in names(l_param_trt)){
  
  n_date_study <- subtract_date_from_name(n)
  n_date_study
  
  # Specify start and end count
  # Some of the studies have a start_date that is not included in the dataset.
  # If that is the case we take the earliest value in the dataset min()
  startcount       <- if_else(as.Date(n_date_study) < as.Date(min(df_hosp_usa$date)), 
                              as.Date(min(df_hosp_usa$date)), 
                              as.Date(n_date_study))
  endcount         <- max(df_hosp_usa$date)  # The latest data with predictions 
  startcount_trial <- startcount       # The start count of the trial is the same as for the total
  endcount_trial   <- as.Date(mondate(startcount) + trial_duration)  # Date when the trial would end and # future patients starts counting #
  
  if(endcount_trial > max(df_hosp_usa$date)) {
    endcount_trial <- max(df_hosp_usa$date)
  }

  l_hosp_trial <- calculate_hospitalizations(df_hospitalisation = df_hosp_usa, 
                                                     startcount = startcount_trial, 
                                                       endcount = endcount_trial) # 3 months
  
  l_hosp       <- calculate_hospitalizations(df_hospitalisation = df_hosp_usa, 
                                                     startcount = endcount_trial, # continue from the end of trial
                                                     endcount   = endcount) 
 
  # Add the information from the list to the param_trt dataset
  param_trt <- param_trt %>% 
    add_row(Treatment = n, 
                        Param = "n_H_year",
                        Med =  l_hosp$pop_mean,
                        Lo_alpha = l_hosp$pop_lower,
                        Hi_beta = l_hosp$pop_upper,
                        Unit = "number",
                        Distribution = NA
                        )  %>% 
    add_row(Treatment = n, 
             Param = "n_H_trial",
             Med =  l_hosp_trial$pop_mean,
             Lo_alpha = l_hosp_trial$pop_lower,
             Hi_beta = l_hosp_trial$pop_upper,
             Unit = "number",
             Distribution = NA
  ) 
  
  
  
# return(param_trt) # when we write it as a function we might have to add this
}

# Print the values for the parameter number of hospitalizations for the trial
df_hosp_trial <-param_trt %>% 
  filter(Param == "n_H_trial") %>%
  select(Treatment, Med, Lo_alpha, Hi_beta)
df_hosp_trial

# Print the values for the number of hospitalizations of the year
df_hosp_year <-param_trt %>% 
  filter(Param == "n_H_year") %>%
  select(Treatment, Med, Lo_alpha, Hi_beta)
df_hosp_year

# Check that the number of hospitalizations is steadily declining in the retrospective sample
df_hosp_year$datestudy <- subtract_date_from_name(df_hosp_year$Treatment)
df_hosp_year$Med
plot_df_hosp_year <- ggplot(df_hosp_year, aes(x = as.Date(datestudy), y = Med)) +
  geom_line() +
  labs(title = "Hospitalizations calculated for retrospective analysis over time",
       x = "Publication date new study", y = "Sum of expected future hospital admissions after the trial")


df_hosp_trial$datestudy <- subtract_date_from_name(df_hosp_trial$Treatment)
plot_df_hosp_trial<- ggplot(df_hosp_trial,aes(x=as.Date(datestudy), y=Med))+geom_line() +
  geom_line() +
  labs(title = "Hospitalizations calculated for retrospective analysis over time",
       x = "Publication date new study", y = "Sum of expected future hospital admissions during trial")

plot_df_hosp_year
plot_df_hosp_trial

ggsave(filename = "../figures/plot_hosp_year_resp.png", plot = plot_df_hosp_year, width = 10, height = 10, units = "in")
```

#### 03.1.9.1 Calculate number of hospitalizations - Prospective - Create Peaks datasets - per date

#### 03.1.9.1 Calculate number of hospitalizations - Prospective - Create Peaks datasets - per date
```{r}

# Note: These datasets are selected based on the fact that they end in a peak of hospitalizations. We assume here that it is not realistic that policy makers at those timepoints would have assumed that the number of new hospitalizations would drop to zero. We therefore select those plots ending in a peak and "mirror" the number hospitalizations in the peak. Added new datasets? Then check whether any new datasets ending in peaks were added; this can be done in the chunk "Visualize Number of Hospitalizations" 
# Choose which datasets are peak dates; The generic code only works for those datasets where the correct peaks and valleys are recognized; this was not the case for "ihme_2021_09_10.RData", "ihme_2021_10_21.RData"; in ihme_2021 the last peak was not recognized as multiple very small peaks existed within the last peak, therefore we use a smoothing function (loess().) We specified in the code that the last valley must preceed the last peak; When downloading new datasets, verify that the code is working acurately. this can be done by choosing a specific dataset, running the full chunk, and specifically checking the plots:
  #plot(as.Date(your_data$date), your_data$admis_mean_smoothed, type = "l")
  #points(peak_dates, your_data$admis_mean_smoothed[peaks], pch = 16, col = "blue")
  #points(valley_dates, your_data$admis_mean_smoothed[valleys], pch = 16, col = "green")
# Use these plots to verify that the colored dots on the plot represent the actual peak and valley that should be mirrored

# One dataset, 2021_10_21 ends in an upwards slope 

# Create two copies of data_list so that one can decide to switch between peak/nopeak calculations in sensitivity analyses
data_list_nopeak <- data_list
data_list_peak <- data_list # In the following code, the data that concerns end-peaks will overwrite the existing datasets from the last valley onward

# Choose which datasets are peak dates
peak_ihme_dataset <- c("ihme_2020_09_11.RData", "ihme_2020_09_24.RData", "ihme_2020_10_15.RData", "ihme_2020_10_22.RData", "ihme_2020_11_19.RData", "ihme_2021_09_10.RData")
peak_ihme_dataset_exception_upslope <- c("ihme_2021_10_21.RData")
peak_ihme_dataset_all <- c(peak_ihme_dataset, peak_ihme_dataset_exception_upslope)


# Smoothing function using loess; The smoothing function smooth_loess uses a method called locally estimated scatterplot smoothing (loess). This method fits a smooth curve through a set of data points by iteratively calculating weighted linear regressions over a small window of neighboring points. The span parameter controls the size of the window and determines the amount of smoothing applied to the data. A smaller span value results in a smoother curve.
smooth_loess <- function(x, span = 0.2) {
  y <- loess(x ~ seq_along(x), span = span)$fitted
  return(y)
}

# Iterate over the datasets in peak_ihme_dataset
for (i in seq_along(peak_ihme_dataset_all)) {
# Select dataset
your_data <- data_list[[peak_ihme_dataset_all[i]]]

# Apply smoothing to admis_mean
your_data$admis_mean_smoothed <- smooth_loess(your_data$admis_mean)

# Identify peaks and valleys using derivatives; After applying the smoothing function to the admis_mean variable in the dataset, the code calculates the first derivative of the smoothed curve using the diff() function. The sign() function is then used to determine the direction of the slope at each point on the curve, and the diff() function is applied again to identify the locations where the direction of the slope changes (i.e., where the first derivative crosses zero). These locations correspond to peaks and valleys in the data.
diffs <- diff(your_data$admis_mean_smoothed)
peaks <- which(diff(sign(diffs)) == -2) + 1
valleys <- which(diff(sign(diffs)) == 2) + 1
peak_dates <- as.Date(your_data$date[peaks])
valley_dates <- as.Date(your_data$date[valleys])

# Check if the current dataset is in peak_ihme_dataset_exception_upslope. For the exception the last date in the upwardsslope is used as a mirroring point, otherwise the identified last peaks and valleys are used
if (peak_ihme_dataset_exception_upslope %in% peak_ihme_dataset_all[i]) {
  last_peak <- tail(your_data$date, 1) # Use last date in dataset as last peak
} else {
  last_peak <- tail(peak_dates,1) # Use last identified peak
}
# last_valley <- max(subset(valley_dates, valley_dates < last_peak)) # Select last valley that preceeds the last peak. # this selects the last valley prior to a peak. Note: doesn't work if ending in upward slope, as then the last part of the plot is ignored, therefore use the regular code tail in the following line that simply takes the last valley
last_valley <- tail(valley_dates,1)
plot(as.Date(your_data$date), your_data$admis_mean_smoothed, type = "l")                        # Use the current line and next two lines to visualize identified peaks
points(peak_dates, your_data$admis_mean_smoothed[peaks], pch = 16, col = color_print)           # Identify peaks: Is the last identified peak indeed the peak to be mirrored?
points(valley_dates, your_data$admis_mean_smoothed[valleys], pch = 16, col = my_green)          # Identify valleys: Is the last valley preceeding the last peak the valley to be mirrored?
subset_data <- subset(your_data, date >= as.Date(last_valley) & date <= as.Date(last_peak))
length(subset_data$date)
new_dates <- seq(as.Date(last_peak), length.out = length(subset_data$date), by = "day")
new_admis_mean <- rev(subset_data$admis_mean)
new_df <- data.frame(date = as.character(new_dates), admis_mean = new_admis_mean)
new_peak <- rbind(subset_data[,c("date","admis_mean")],new_df)
#plot(as.Date(new_peak$date), new_peak$admis_mean, type = "l") # plots just the new peak
your_data_peak <- your_data
new_peak$admis_upper <- NA
new_peak$admis_lower <- NA
new_peak$admis_mean_smoothed <- NA
your_data_peak <- your_data_peak[your_data_peak$date < last_valley, ] 
your_data_peak_new <- rbind(your_data_peak, new_peak)
# plot(as.Date(your_data$date), your_data$admis_mean_smoothed, type = "l") # plots the old data, print to compare to new and not re-running entire section
plot(as.Date(your_data_peak_new$date), your_data_peak_new$admis_mean, type = "l")

# Save the adjusted datasets to data_list_peak
data_list_peak[[peak_ihme_dataset_all[i]]] <- your_data_peak_new
}

# Check content of data_list_peak
# for (i in seq_along(data_list_peak)) {
#  print(tail(data_list_peak[[i]]))    }
```

#### 03.1.9.2 Save peak/nopeak dataset plots
```{r}

# Select names of IHME datafiles list that are in the peak list; only these should be adjusted
v_names_data_hosp_ihme <- names(data_list)
v_names_data_hosp_ihme_peak <- intersect(v_names_data_hosp_ihme, peak_ihme_dataset_all)
v_names_data_hosp_ihme_peak

data_list_peak_lim <- data_list_peak[names(data_list_peak) %in% v_names_data_hosp_ihme_peak]
data_list_nopeak_lim <- data_list_nopeak[names(data_list_nopeak) %in% v_names_data_hosp_ihme_peak]


# Create an empty list to store the plots
plots <- list()

# Iterate over the datasets in data_list_peak_lim
for (i in seq_along(data_list_peak_lim)) {
  
  # Select the current dataset
  peak_data <- data_list_peak_lim[[i]]
  nopeak_data <- data_list_nopeak_lim[[i]]
  
  # Create a ggplot object for the no-peak data
  nopeak_plot <- ggplot(data = nopeak_data, aes(x = as.Date(date), y = admis_mean)) +
    geom_line() +
    ggtitle(paste0("Dataset: ", names(data_list_nopeak_lim)[i], "\nOriginal, non-extended dataset")) +
  ylab("new hospitalizations / day") # Add y axis title
  
  # Create a ggplot object for the peak data
  peak_plot <- ggplot(data = peak_data, aes(x = as.Date(date), y = admis_mean)) +
    geom_line() +
    ggtitle(paste0("Dataset: ", names(data_list_nopeak_lim)[i], "\nExtended peak dataset"))+
  ylab("new hospitalizations / day") # Add y axis title
  
  # Add the two plots to the plots list
  plots[[i]] <- grid.arrange(nopeak_plot, peak_plot, ncol = 2)
}

# Combine the plots in the plots list into a grid plot
grid_plot <- do.call(grid.arrange, c(plots, ncol = 1))
ggsave("../figures/grid_extendedpeak.png", grid_plot, width = 10, height = 20, dpi = 300)


```




### 03.1.9 Calculate number of hospitalizations - Prospective [New style]
#### 03.1.9.1 Calculate number of hospitalizations - Prospective - per date

Note: Choose whether to use the peak or non-peak adjusted dataset
```{r}
#data_list <- data_list_nopeak
#data_list <- data_list_peak

if (extended_peak_analysis == "Yes") {
  data_list <- data_list_peak
} else if (extended_peak_analysis == "No") {
  data_list <- data_list_nopeak
} else {
  cat("Invalid input for extended_peak_analysis.\n")
}
```

```{r}
# Select names of IHME datafiles list
v_names_data_hosp_ihme <- names(data_list)

# Change to appropriate date format, example:"2020-09-18" 
v_date_data <- gsub("_", "-", substr(v_names_data_hosp_ihme, start = 6, stop = 15))

#v_date_data <- v_date_data[1:3] #debug
#v_date_data <- (v_date_data[-2])

# Create a dataset to store the values
df_hosp_est_prospective <- data.frame(IHME_date = character(),
                                      Param = character(), 
                                      Med = numeric(),
                                      Lo_alpha = numeric(),
                                      Hi_beta = numeric()
)

# Check whether all datasets are organized in the same structure
lapply(data_list[v_names_data_hosp_ihme], head)

# Start a loop for the different data sets
for (d in 1:length(v_names_data_hosp_ihme)) {
  name_date     <- v_names_data_hosp_ihme[d]
  df_hosp_usa   <- data_list[[name_date]]
  date_data     <- v_date_data[d]

  startcount      <- date_data
  endcount        <- max(data_list[[name_date]]$date)  # The latest data with predictions 
  startcount_trial <- startcount       # The start count of the trial is the same as for the total
  endcount_trial   <- as.Date(mondate(startcount) + trial_duration)  # Date when the trial would end and # future patients starts counting #
   
  if(endcount_trial > max(df_hosp_usa$date)) {
    endcount_trial <- max(df_hosp_usa$date)
  }
  
  l_hosp_trial <- calculate_hospitalizations(df_hospitalisation = data_list[[name_date]], 
                                              startcount = startcount_trial, 
                                              endcount = endcount_trial)
   
  l_hosp       <- calculate_hospitalizations(df_hospitalisation = data_list[[name_date]], 
                                              startcount = endcount_trial, 
                                              endcount = endcount) 

  
  df_hosp_est_prospective <- df_hosp_est_prospective %>% 
    add_row(IHME_date = date_data,
            Param = "n_H_year",
            Med =  l_hosp$pop_mean,
            Lo_alpha = l_hosp$pop_lower,
            Hi_beta = l_hosp$pop_upper) %>% 
    add_row(IHME_date = date_data,
            Param = "n_H_trial",
            Med =  l_hosp_trial$pop_mean,
            Lo_alpha = l_hosp_trial$pop_lower,
            Hi_beta = l_hosp_trial$pop_upper
    ) 

}
  print(df_hosp_est_prospective)
  
  

```

###03 Check whether the peak/nopeak datasets are correctly estimated
```{r, eval = FALSE}
  # To check whether peak calculation worked correctly, run the previous chunk once with peak dataset, save as copy: 
  df_hosp_est_prospective_copy <- df_hosp_est_prospective
  # run second time with nopeak dataset, compare the two dataframes, pay special attention to the dates in peak_ihme_dataset
   peak_ihme_dataset
   df_hosp_est_prospective_copy
   df_hosp_est_prospective
  # Note: Upper and lower bounds in peak dataset are intentionally left blank for the peak dataset, as these are not predictions
   
# Subset df_hosp_est_prospective_copy by Param
df_copy_year <- subset(df_hosp_est_prospective_copy, Param == "n_H_year")
df_copy_trial <- subset(df_hosp_est_prospective_copy, Param == "n_H_trial")

# Subset df_hosp_est_prospective by Param
df_year <- subset(df_hosp_est_prospective, Param == "n_H_year")
df_trial <- subset(df_hosp_est_prospective, Param == "n_H_trial")

# Set Y axis limit
y_max <- max(df_hosp_est_prospective_copy$Med)

# Change to as date
df_copy_year$IHME_date <- as.Date(df_copy_year$IHME_date)
df_copy_trial$IHME_date <- as.Date(df_copy_year$IHME_date)
df_year$IHME_date <- as.Date(df_copy_year$IHME_date)
df_trial$IHME_date <- as.Date(df_copy_year$IHME_date)


# Create top left panel
ggplot(df_copy_year, aes(x = as.Date(IHME_date), y = Med)) + 
  geom_line() + 
  ggtitle("df_hosp_est_prospective_copy: n_H_year") +
  ylim(0, y_max) +
  scale_x_date(limits=c(as.Date("2020-09-01"), as.Date("2022-01-01")), date_breaks="1 month") +
  theme(plot.title = element_text(hjust = 0.5))

# Create top right panel
ggplot(df_copy_trial, aes(x = IHME_date, y = Med)) + 
  geom_line() + 
  ggtitle("df_hosp_est_prospective_copy: n_H_trial") +
  ylim(0, y_max) +
  scale_x_date(limits=c(as.Date("2020-09-01"), as.Date("2022-01-01")), date_breaks="1 month") +
  theme(plot.title = element_text(hjust = 0.5))

# Create bottom left panel
ggplot(df_year, aes(x = IHME_date, y = Med)) + 
  geom_line() + 
  ggtitle("df_hosp_est_prospective: n_H_year") +
  ylim(0, y_max) +
  scale_x_date(limits=c(as.Date("2020-09-01"), as.Date("2022-01-01")), date_breaks="1 month") +
  theme(plot.title = element_text(hjust = 0.5))

# Create bottom right panel
ggplot(df_trial, aes(x = IHME_date, y = Med)) + 
  geom_line() + 
  ggtitle("df_hosp_est_prospective: n_H_trial") +
  ylim(0, y_max) +
  scale_x_date(limits=c(as.Date("2020-09-01"), as.Date("2022-01-01")), date_breaks="1 month") +
  theme(plot.title = element_text(hjust = 0.5))



# Rotate x axis labels
my_theme <- theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 90, hjust = 1))


# Create gridplot
grid.arrange(
  # Top left panel
  ggplot(df_copy_year, aes(x = as.Date(IHME_date), y = Med)) + 
    geom_line() + 
    ggtitle("df_hosp_est_prospective_copy: n_H_year") +
    ylim(0, y_max) +
    scale_x_date(limits=c(as.Date("2020-09-01"), as.Date("2022-01-01")), date_breaks="1 month") +
    my_theme,
    
  # Top right panel
  ggplot(df_copy_trial, aes(x = IHME_date, y = Med)) + 
    geom_line() + 
    ggtitle("df_hosp_est_prospective_copy: n_H_trial") +
    ylim(0, y_max) +
    scale_x_date(limits=c(as.Date("2020-09-01"), as.Date("2022-01-01")), date_breaks="1 month") +
    my_theme,
  
  # Bottom left panel
  ggplot(df_year, aes(x = IHME_date, y = Med)) + 
    geom_line() + 
    ggtitle("df_hosp_est_prospective: n_H_year") +
    ylim(0, y_max) +
    scale_x_date(limits=c(as.Date("2020-09-01"), as.Date("2022-01-01")), date_breaks="1 month") +
    my_theme,
  
  # Bottom right panel
  ggplot(df_trial, aes(x = IHME_date, y = Med)) + 
    geom_line() + 
    ggtitle("df_hosp_est_prospective: n_H_trial") +
    ylim(0, y_max) +
    scale_x_date(limits=c(as.Date("2020-09-01"), as.Date("2022-01-01")), date_breaks="1 month") +
    my_theme,
  
  # Layout settings
  ncol = 2,
  nrow = 2,
  top = "Comparing n_H_year and n_H_trial between df_hosp_est_prospective_copy and df_hosp_est_prospective"
)


```


#### 03.1.9.2 Calculate number of hospitalizations - Prospective - link date to param
```{r}
ihme_dates <- v_date_data[order(as.Date(v_date_data))]
papers_dates <- subtract_date_from_name(names(l_param_trt))

prior_dates_vec <- c()

for (i in 1:length(papers_dates)) {
  prior_dates <- ihme_dates[which(as.Date(ihme_dates, "%Y-%m-%d") < as.Date(papers_dates[i], "%Y-%m-%d"))]
  last_prior_date <- tail(prior_dates, 1)
  prior_dates_vec <- c(prior_dates_vec, last_prior_date)
}

prior_dates_vec

length(prior_dates_vec) # should be same as n treatments
length(l_param_trt)
 

# Check which prior date was used for each dataset
for (name in names(l_param_trt)) {
    cat("IHME dataset used in", name, ": ", l_param_trt[[i]]$ihme_dataset_before_publication, "\n")
}

# Add the prior date ( = used dataset) to the l_param_trt list
for (i in 1:length(l_param_trt)) {
  l_param_trt[[i]]$ihme_dataset_before_publication <- prior_dates_vec[i]
}

df_hosp_est_prospective

# create an empty dataframe with columns
param_ihme <- data.frame(Treatment = character(),
                         Country = character(),
                         Param = character(),
                         Unit = character(),
                         Unit_amount = numeric(),
                         Med = character(),
                         Lo_alpha = numeric(),
                         Hi_beta = numeric(),
                         Distribution = character(),
                         Assumption = character(),
                         source = character(),
                         description = character(),
                         remarks_and_questions = character(),
                         stringsAsFactors = FALSE)

# fill the dataframe by adding rows for each item in l_param_trt
for (i in seq_along(names_trt)) {
  param_ihme <- rbind(param_ihme, data.frame(
    Treatment = names_trt[i],
    Country = "All",
    Param = "IHME_date",
    Unit = NA,
    Unit_amount = NA,
    Med = NA,
    Lo_alpha = NA,
    Hi_beta = NA,
    Distribution = NA,
    Assumption = NA,
    source = "https://www.healthdata.org/node/8787",
    description = "Number of hospitalizations predicted in last published dataset before trial publication",
    remarks_and_questions = NA,
    stringsAsFactors = FALSE))
  
  # fill the "Med" column with prior_dates_vec
  param_ihme$Med[param_ihme$Treatment == names_trt[i]] <- prior_dates_vec[i]
  
  # add row with Param = "n_H_year"
  param_ihme <- rbind(param_ihme, data.frame(
    Treatment = names_trt[i],
    Country = "All",
    Param = "n_H_year",
    Unit = "number",
    Unit_amount = "number",
    Med = NA,
    Lo_alpha = NA,
    Hi_beta = NA,
    Distribution = NA,
    Assumption = NA,
    source = "https://www.healthdata.org/node/8787",
    description = "Number of hospitalizations predicted in last published dataset before trial publication",
    remarks_and_questions = NA,
    stringsAsFactors = FALSE))
  
  # add row with Param = "n_H_trial"
  param_ihme <- rbind(param_ihme, data.frame(
    Treatment = names_trt[i],
    Country = "All",
    Param = "n_H_trial",
    Unit = "number",
    Unit_amount = "number",
    Med = NA,
    Lo_alpha = NA,
    Hi_beta = NA,
    Distribution = NA,
    Assumption = NA,
    source = NA,
    description = NA,
    remarks_and_questions = NA,
    stringsAsFactors = FALSE))
}

 param_ihme


# For each treatment in param_ihme, fill out the n_H_year and n_H_trial rows with values from df_hosp_est_prospective
for (treatment in unique(param_ihme$Treatment)) {
  # Get the median IHME date for the current treatment
  med_ihme_date <- param_ihme$Med[param_ihme$Treatment == treatment & param_ihme$Param == "IHME_date"]
  
  # Fill out the n_H_year and n_H_trial rows for the current treatment with values from df_hosp_est_prospective
  param_ihme$Med[param_ihme$Treatment == treatment & param_ihme$Param == "n_H_year"] <- df_hosp_est_prospective$Med[df_hosp_est_prospective$IHME_date == med_ihme_date & df_hosp_est_prospective$Param == "n_H_year"]
  param_ihme$Lo_alpha[param_ihme$Treatment == treatment & param_ihme$Param == "n_H_year"] <- df_hosp_est_prospective$Lo_alpha[df_hosp_est_prospective$IHME_date == med_ihme_date & df_hosp_est_prospective$Param == "n_H_year"]
  param_ihme$Hi_beta[param_ihme$Treatment == treatment & param_ihme$Param == "n_H_year"] <- df_hosp_est_prospective$Hi_beta[df_hosp_est_prospective$IHME_date == med_ihme_date & df_hosp_est_prospective$Param == "n_H_year"]
  
  param_ihme$Med[param_ihme$Treatment == treatment & param_ihme$Param == "n_H_trial"] <- df_hosp_est_prospective$Med[df_hosp_est_prospective$IHME_date == med_ihme_date & df_hosp_est_prospective$Param == "n_H_trial"]
  param_ihme$Lo_alpha[param_ihme$Treatment == treatment & param_ihme$Param == "n_H_trial"] <- df_hosp_est_prospective$Lo_alpha[df_hosp_est_prospective$IHME_date == med_ihme_date & df_hosp_est_prospective$Param == "n_H_trial"]
  param_ihme$Hi_beta[param_ihme$Treatment == treatment & param_ihme$Param == "n_H_trial"] <- df_hosp_est_prospective$Hi_beta[df_hosp_est_prospective$IHME_date == med_ihme_date & df_hosp_est_prospective$Param == "n_H_trial"]
}

param_ihme$Country <- "All"
param_ihme$Unit <- "number"

# As we will need to distinguish both prospective and retrospective analysis, change the name of relevant parameters to include "_prosp"
param_ihme$Param[param_ihme$Param == "IHME_date"] <- "IHME_date_prosp"
param_ihme$Param[param_ihme$Param == "n_H_year"] <- "n_H_year_prosp"
param_ihme$Param[param_ihme$Param == "n_H_trial"] <- "n_H_trial_prosp"
param_ihme


param_ihme
```


#### 03.1.9.2.3 Combine IHME dataset with param trt
In this section we create a second version of n_H_trial_prosp for those IHME sets that end in a peak
```{r, eval = TRUE}
####
# Bind param ihme to param_trt
param_trt<- rbind(param_trt, param_ihme)

# Take out the date, since this is not relevant to the PSA
# create a subset dataframe containing rows where 'Param' contains 'IHME_date', then bind these with the qualitative dataset
df_IHME_date <- param_trt[grepl("IHME_date", param_trt$Param), ]
param_qual <- rbind(param_qual, df_IHME_date)


# remove the subset dataframe rows from the original dataset
param_trt <- param_trt[!grepl("IHME_date", param_trt$Param), ]
df_IHME_date
param_trt
```


```{r, eval = false}
# Compare datasets in data_list
for (i in 1:length(data_list)) {
  cat(paste0("Dataset ", i, ":\n"))
  str(data_list[[i]])
}
```

### 03.1.10  Visualize Number of hospitalizations
### 03.1.10.1  Retrospective Visualization Number of hospitalizations
```{r, eval = TRUE}
# Plot projected number of hospitalizations USA over time
df_hosp_usa <- df_hosp_usa_retrospective
df_hosp_usa$date <- as.Date(df_hosp_usa$date)

# Plot projected hospitalizations including upper and lower bound USA 
projected_hosp <- ggplot() + 
  geom_path(data = df_hosp_usa, aes(x = date, y = admis_mean), color = "black") +
  geom_path(data = df_hosp_usa, aes(x = date, y = admis_lower), color = "blue", linetype = "dotted") +
  geom_path(data = df_hosp_usa, aes(x = date, y = admis_upper), color = "blue", linetype = "dotted") +
  labs( x = "date", y = "Number of hospitalizations per day", title = "New hospitalizations per day")   + 
  scale_x_date(date_breaks = "1 month", labels = date_format("%m-%Y"))   + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 

ggsave(path = here("../figures"), filename = paste("Projected number of new hospitalizations per day IHME - Retrospective.png", sep =""))

# Print plot
projected_hosp

# Compare to calculated trial and future hospitalizations plots
plot_df_hosp_year
plot_df_hosp_trial
# Then, arrange them side-by-side using grid.arrange() function from the gridExtra package
grid_plot_proj_hosp <- grid.arrange(projected_hosp, plot_df_hosp_trial, plot_df_hosp_year, nrow = 3)
grid_plot_proj_hosp
ggsave(file.path(here(), "figures", "Projected number of new hospitalizations per day IHME - Retrospective - grid.png"), plot = grid_plot_proj_hosp, width = 10, height = 6, units = "in")

# Check from and  until which date the projections are carried out
head(df_hosp_usa$date) # From 2020-02-04 onward
tail(df_hosp_usa$date) # 
range(df_hosp_usa$date)

# Sum total hospitalizations
sum(df_hosp_usa$admis_mean) # Total hospitalizations as projected over total period


```

### 03.1.10.2 Prospective Visualization Number of hospitalizations
```{r, eval = TRUE}

# Select those datasets that are used for current treatment data
# Extract dates from prior_dates_vec
prior_dates <- gsub("-", "_", prior_dates_vec)

# Find indices of matching dates in names(data_list)
idx <- grep(paste(prior_dates, collapse="|"), names(data_list))

# Subset data_list using the indices
v_intersect <- data_list[idx]


# Set the number of columns and rows for the grid
n_cols <- 4
n_rows <- ceiling(length(names(v_intersect)) / n_cols)

# Create an empty list to store the plots
l_ihme_plots <- list()

# Loop over each dataset within data_list
for (i in seq_along(v_intersect)) {
  # Read the dataset
  df_hosp <- (v_intersect[[i]])
  
  # Convert date to a date object
  df_hosp$date <- as.Date(df_hosp$date)
  
  # Add the dataset name to the plot title
  plot_title <- paste("Dataset:", names(data_list[i]), sep = " ")
  
  # Create the plot
  projected_hosp <- ggplot() +
    geom_path(data = df_hosp, aes(x = date, y = admis_mean), color = "black") +
    geom_path(data = df_hosp, aes(x = date, y = admis_lower), color = "blue", linetype = "dotted") +
    geom_path(data = df_hosp, aes(x = date, y = admis_upper), color = "blue", linetype = "dotted") +
    labs(x = "date", y = "N hospitalizations / day", title = plot_title) +
    scale_x_date(date_breaks = "1 month", labels = date_format("%m-%Y")) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
  
  
  l_ihme_plots[[i]] <- projected_hosp
  
  
  # Save the plots seperately
  #ggsave(path = here("../figures"), filename = paste("Projected number of new hospitalizations per day", names(data_list[i]), ".png", sep = " - "))
  
  # Print the plot
  print(projected_hosp)
}

# Create the grid plot 
grid.arrange(grobs = l_ihme_plots, ncol = n_cols, nrow = n_rows)

# Create a final grid plot of all plots
all_plots <- do.call(grid.arrange, c(l_ihme_plots, ncol = n_cols))
#all_plots <- ggdraw(all_plots) + draw_label("Projected number of new hospitalizations / day - Prospective", size = 18, fontface = "bold", x = 0.5, hjust = 0.5, y = 0.98)

ggsave("../figures/all_prospective_ihme_plots.png", all_plots, width = 16, height = 14, units = "in")

all_plots

```


### 03.1.11  Load cohort data into environment 
Note, here the lists are re-created, after the hospitalization data has been added to param_trt
```{r}
# Adjust WTP if not 100000 (default in df_param)
# param_trt$Med[param_trt$Param == "wtp"]
param_trt$Med[param_trt$Param == "wtp"] <- wtp_level_main

# Ensure there are no more empty rows and all values are numeric
# Use the function to remove the values without a unit and change to numeric value
param     <- remove_param_without_unit(df_param = param)
param_trt <- remove_param_without_unit(df_param = param_trt)

# Get the median parameter values from the usual care/cohort into the R environment

l_param     <- split_df_to_lists_mean_param(df_param = param)
l_param_all <- split_df_to_lists_mean_param(df_param = param_trt) # run the function 

# Merge all the parameters from one specific treatment/to all the drug specific lists.
# For example some treatment specific values are relevant for all drugs. This is indicated by the # "All" meaning apply to all. 
l_param_trt <- combine_lists(list = l_param_all, combine = "All")

for (n in names(l_param_trt)){
l_param_trt[[n]] <- c(l_param_trt[[n]], l_param$usual_care)
}

``` 



### 03.1.12 Define treatment effect type 
```{r}
# The model allows for Relative Risk, Risk Difference, Odds Ratio or Hazard Ratio treatment effects on mortality, compared to usual care, to be investigated. This code chunk recognizes which treatment effect type should be applied for each of the treatment options as specified in the param excel sheet.
# Additionally, the code checks whether or not a distinction is made between treatment effect with and without ventilation in the ICU population. If no distinction is specified, treatment effect is applied the same for vent/novent groups

for(n in names(l_param_trt)){
  l_list_f <- c()
  l_list_f <- l_param_trt[[n]]
  
  # Code to select type of parameter
  v_names_param <- names(l_param_trt[[n]])
  
  v_trt_type_name <- c("rr_D_Trt_timespan1", 
                       "rd_D_Trt_timespan1", 
                       "or_D_Trt_timespan1", 
                       "hr_D_Trt_timespan1")
 
   v_trt_type <- c("RR",
                   "RD",
                   "OR",
                   "HR")
  
  # Make a dateframe
  df_trt_type <- as.data.frame(cbind(v_trt_type_name, v_trt_type))
  # select the full name of the treatment type
  name <- v_names_param[ which(v_names_param %in% v_trt_type_name)]
  # match it with the corresponding treatment type
  trt_effect <- df_trt_type$v_trt_type[df_trt_type$v_trt_type_name == name] #
  
    vent <- FALSE  # make a variable that by default is FALSE
    
    
    # Enable the following code if the code must distinguish between effectiveness for patients on and not on ventilator
  if(trt_effect == "RR" & !is.null(l_list_f$rr_D_Trt_timespan1_vent)){
    vent <- TRUE # if  we have information about ventilation, overwrite
  }
  if(trt_effect == "RD" & !is.null(l_list_f$rd_D_Trt_timespan1_vent)){
    vent <- TRUE
  }
  if(trt_effect == "OR" & !is.null(l_list_f$or_D_Trt_timespan1_vent)){
    vent <- TRUE
  }
  if(trt_effect == "HR" & !is.null(l_list_f$hr_D_Trt_timespan1_vent)){
    vent <- TRUE
  }
  
  
  l_param_trt[[n]]$trt_effect <- trt_effect
  l_param_trt[[n]]$vent       <- vent
  
} #close the loop
```


### 03.1.13  Input parameters copy for PSA
```{r}
# This copy is required as the base code edits param according to the required treatment, whether the PSA uses the original input data again.
param_psa_input <- param
param_trt_psa_input <- param_trt

# Adjust distributions for n_H_trial/year from NA to text NA
param_trt_psa_input$Distribution <- ifelse(
  grepl("n_H_year", param_trt_psa_input$Param) | grepl("n_H_trial", param_trt_psa_input$Param),
  "NA",
  param_trt_psa_input$Distribution
)

param_trt_psa_input$Country <- ifelse(
  grepl("n_H_year", param_trt_psa_input$Param) | grepl("n_H_trial", param_trt_psa_input$Param),
  "All",
  param_trt_psa_input$Country
)
```


# 04 Internal general model settings and input
```{r, message = FALSE, echo = FALSE}

l_input_general <- list(
# Strategy names
v_names_str      = c("notrt",      "trt"), 
v_names_str_full = c("Usual Care", "Treatment"), # Standard of care vs treatment


# Markov model parameters
n_age_max = 120  ,            # max. age for life time horizon analysis
n_DpC   = 73 ,                # days per cycle
n_DpY   = 365  ,              # days per year

v_names_states      = c("H", "R_H", "R_IC", "D"),  # the 4 states of the model: Hospitalized, Recovered from Hospital ward (R_H), Recovered from ICU (R_IC) Dead (D)
v_names_states_full = c("Hospitalized", "Recovered from Hospital ward", "Recovered from ICU", "Dead") ,

v_s_init = c("H" = 1, "R_H" = 0, "R_IC" = 0, "D" = 0), # Initial state distribution
# Effects (alive = 1, dead = 0)
e_H    = 1,
e_I    = 1,
e_R    = 1,
e_R_IC = 1,
e_R_H  = 1,
e_D    = 0,

# Discounting factor
# Equal discount of costs and QALYs of 3%
d_e = 0.03,
d_c = 0.03       
)

# Load the parameters from usual care to the environment
# Those treatment specific will we used in a loop
ls()
list2env(l_input_general, globalenv())     # cohort 
ls()


# Combine the list with general input with all the drug specific info
for (n in names(l_param_trt)){
  l_input_general$df_r_HD <- df_r_HD # Add the df with the mortality rate to the general input
  l_param_trt[[n]] <- c(l_param_trt[[n]], l_input_general)
}


l_param_trt_basecase <- l_param_trt
save(l_param_trt_basecase, file = "../output/l_param_trt_basecase.rda" )
save(l_input_general, file = "../output/l_input_general.rda")

# Settings for grid plots
n_cols_grid <- 3
n_rows_grid <- ceiling(length(v_names_trt) / n_cols_grid)
```


# 05 Markov model
##05.1 Run the markov model using the function

```{r, eval = TRUE, echo=FALSE, warning=FALSE, error=FALSE, results=FALSE}
# Create two lists to store the Cost-effectiveness results for the base case analysis
l_out_ce_base <- l_out_ce_base_return_all <- list()

for (n in names(l_param_trt)){
  # save all the items 
l_out_ce_base_return_all[[n]] <- calculate_cea_output_VOI_COVID(l_list = l_param_trt_basecase[[n]], n_wtp = l_param_trt[[n]]$wtp, return_all = TRUE,  verbose = FALSE)

l_out_ce_base[[n]] <- l_out_ce_base_return_all[[n]]$df_ce_combined

}

# Extract data to the global environment 
l_input_general <- estimate_input_general(l_param_trt[[1]])

ls()
invisible(list2env(l_input_general, globalenv())) # cohort 
ls()
```


## 05.2 Create a state-transition diagram of the cohort model
Model: 
H = Hospitalized in study 
R_H = Recovered from Hospital ward
R_IC = Recovered from ICU
D = Dead  

```{r}
# Make a matrix for the structure of the model
m_P_diag2 <- with(l_out_ce_base_return_all[[1]]$l_param_trt_f, matrix(0, nrow = n_states, ncol = n_states, dimnames = list(v_names_states, v_names_states)))

m_P_diag2["H","R_H"]  = "" 
m_P_diag2["H","R_IC"]  = "" 
m_P_diag2["H","D"]  = "" 
m_P_diag2["R_IC","R_IC"]  = ""
m_P_diag2["R_H","R_H"]  = ""
m_P_diag2["R_IC","D"]  = ""
m_P_diag2["R_H","D"]  = ""
m_P_diag2["D","D"]  = "" 

# The layout of the state-bubbles 
layout.fig2 <- c(1, 2, 1)

# plot the final graph
plotmat(t(m_P_diag2), t(layout.fig2), self.cex = 0.4, curve = 0, arr.pos = 0.7,  
        latex = T, arr.type = "curved", relsize = 0.9, box.prop = 0.7, 
        cex = 0.6, box.cex = 0.9, lwd = 1)


  # 1. Open pgn file
  png(paste("../figures/cohort_state_transition_diagram.png", sep =""))
  
  # plot the final graph
plotmat(t(m_P_diag2), t(layout.fig2), self.cex = 0.4, curve = 0, arr.pos = 0.7,  
        latex = T, arr.type = "curved", relsize = 0.9, box.prop = 0.7, 
        cex = 0.6, box.cex = 0.9, lwd = 1)

    # 3. Close the file
    dev.off()

```

# 06 Compute and Plot Epidemiological Outcomes

## 06.1 Cohort trace

```{r, eval = FALSE}

# This code is a loop to make the cohort trace plots and save them   
  for (n in names(l_param_trt)){
    # rename the names from the list
    l_trace_plot <- l_out_ce_base_return_all[[n]]$l_trace
    
    # No Treatment Treatment : names in the plot making
    M_trt   <- l_trace_plot$trt
    M_notrt <- l_trace_plot$notrt
  
    # give the columns full names
    colnames(M_trt)   <- v_names_states_full
    colnames(M_notrt) <- v_names_states_full

    ## NO TRT ##
    #create the plot
     PlotTrace2(trace = M_notrt, xlab = "Cycle", title = paste(paste("No Treatment", " ", remove_date_from_name(n), sep ="")))
     
     # Save the plot
   # ggsave(path = here("../figures"), filename = paste("Markov Trace", "_", "No Treatment", " ", remove_date_from_name(n), ".png", sep =""))
    
    
    ## TRT ##
     #create the plot
     PlotTrace2(trace = M_trt, xlab = "Cycle", title = paste(paste("Treatment", " ", remove_date_from_name(n), sep ="")))
     
     # Save the plot
    #ggsave(path = here("../figures"), filename = paste("Markov Trace", "_",  "Treatment", " ", remove_date_from_name(n), ".png", sep =""))
    
    
    ### Code to export the graph details to Rdata
    plot_markovtrace_no_trt <- PlotTrace2(trace = M_notrt, xlab = "Cycle", title = paste(paste("No Treatment", " ", remove_date_from_name(n), sep ="")))
    
    plot_markovtrace_trt   <- PlotTrace2(trace = M_trt, xlab = "Cycle", title = paste(paste("No Treatment", " ", remove_date_from_name(n), sep ="")))
    
    #save(plot_markovtrace_no_trt, file = paste("../output/", "Plot_Markov Trace", "_", "No Treatment", " ", remove_date_from_name(n), ".Rdata", sep =""))
    
    #save(plot_markovtrace_trt, file = paste("../output/", "Plot_Markov Trace", "_", "Treatment", " ", remove_date_from_name(n), ".Rdata", sep =""))
    
    
    # Combine the figures # 
    ggarrange(plot_markovtrace_no_trt, plot_markovtrace_trt, 
          labels = c("A", "B"),
          ncol = 2, nrow = 1,
          common.legend = TRUE,
          legend = "bottom")
    
        ggsave(path = here("../figures"), filename = paste("Markov Traces", "_", remove_date_from_name(n), ".png", sep =""))
    
    
    }

```


## 06.2 Overall Survival (OS)

```{r}

# Matrix for the overall survival  
m_os <- with(l_out_ce_base_return_all[[1]]$l_param_trt_f, 
             matrix(data = NA, 
                 nrow = n_t + 1, ncol = length(names(l_param_trt)),
                 dimnames = list(paste("cycle", 0:n_t, sep = " "),
                                 names(l_param_trt)))
             )


# Create a data frame 
df_survival <-  with(l_out_ce_base_return_all[[1]]$l_param_trt_f, 
                     data.frame(treatment = rep(names(l_param_trt), 
                                             each = (n_t + 1) * length(v_names_str)), 
                              strategy = rep(rep(c("trt", "notrt"), 
                                                each = (n_t + 1)), length(names(l_param_trt))),
                                 cycle = rep(rep(0:n_t), 
                                         times = length(names(l_param_trt)) * length(v_names_str)),
                                    OS = NA)  
)
  

l_trace <- c()
for(n in names(l_param_trt)){
  
  v_names_str <-l_out_ce_base_return_all[[1]]$l_param_trt_f$v_names_str
  
    for (k in v_names_str){ # loop for the number or strategies 
  
      l_trace <- l_out_ce_base_return_all[[n]]$l_trace
      l_M     <- l_trace[[k]]
  
      # calculate the overall survival (OS) probability 
      v_os <- 1 - l_M[, "D"]
      
      m_os[, n] <- v_os  # store the vector in the drug specific column 
      
      # create a dataframe with the overall survival
      # Run the function to generate a dataframe of the overall survival
      df_survival$OS[df_survival$treatment == n & df_survival$strategy == k] <- v_os
    }
}

# Create an empty list to store the plots
l_grid_plots_surv <- list()
l_grid_plots_surv_zoom <- list()

# Run the function plot_survival for all the treatments   
  for (n in unique(df_survival$treatment)){
    df_surv_loop <- filter(df_survival, treatment == n)
    
    plot_surv_full <- plot_survival(df_survival = df_surv_loop, cycle_zoom = FALSE)
    l_grid_plots_surv[[n]] <- plot_surv_full
    plot_surv_full
    
    # Save individual plots if desired
    # ggsave(path = here("../figures"), filename = paste("Overall_survival", "_", remove_date_from_name(n), ".png", sep =""))
    
    plot_surv_zoom <- plot_survival(df_survival = df_surv_loop, cycle_zoom = 5)
    
    # Add plot to list
   l_grid_plots_surv_zoom[[n]] <- plot_surv_zoom
    

   # Save individual plots if desired
   # plot_surv_zoom
   # ggsave(path = here("../figures"), filename = paste("Overall_survival_start", "_", remove_date_from_name(n), ".png", sep =""))

  }

## Full
# Create the grid plot 
grid.arrange(grobs = l_grid_plots_surv, ncol = n_cols_grid, nrow = n_rows_grid)

# Create a final grid plot of all plots
all_grid_plots_surv <- do.call(grid.arrange, c(l_grid_plots_surv, ncol = n_cols_grid))

ggsave("../figures/all_grid_plots_surv.png", all_grid_plots_surv, width = 16, height = 9, units = "in")

all_grid_plots_surv

## Zoom
# Create the grid plot 
grid.arrange(grobs = l_grid_plots_surv_zoom, ncol = n_cols_grid, nrow = n_rows_grid)

# Create a final grid plot of all plots
all_grid_plots_surv_zoom <- do.call(grid.arrange, c(l_grid_plots_surv_zoom, ncol = n_cols_grid))

ggsave("../figures/all_grid_plots_surv_zoom.png", all_grid_plots_surv_zoom, width = 16, height = 9, units = "in")

#Print result
all_grid_plots_surv
all_grid_plots_surv_zoom

```

## 06.2.1 Life Expectancy (LE)

```{r}
l_le <- generate_df_life_expectancy(df_survival = df_survival, v_names_str = v_names_str)
l_grid_plots_LE <- list()

# Make figures of the LE
for(n in names(l_param_trt)){
  
      df_le_plot <- l_le$df_le %>% #filter the dataframe
      filter(treatment == n) 
  
  plot <- plot_life_expectancy(df_le_plot)+
        scale_color_manual(values = c(my_red, my_darkgreen, my_black)) + 
    scale_fill_manual(values = c(my_red, my_darkgreen, my_black))# make the plot
  
  l_grid_plots_LE[[n]] <- plot
  
  # Save individual plot
  # ggsave(path = here("../figures"), filename = paste("LE", "_", remove_date_from_name(n), ".png", sep ="")) 
       
}


plot <- ggplot(data = l_le$df_le, aes(x = strategy, y = LE, group = strategy, fill = strategy)) + 
          scale_color_manual(values = c(my_red, my_darkgreen, my_black)) + 
    scale_fill_manual(values = c(my_red, my_darkgreen, my_black)) + # make the plot
    geom_col() +
 facet_wrap(~ treatment) +
    ggtitle(paste("Life expectancy overview")) 

  ggsave(path = here("../figures"), 
         filename = paste("LE_summary.png")) #save plot
      
  
# Subset the report data
df_le_plot_report <- l_le$df_le[l_le$df_le$treatment %in% l_names$v_names_trt_report, ]

# Remove the date from the treatment names 
df_le_plot_report$treatment <- sapply( df_le_plot_report$treatment, remove_date_from_name)
  
plot <- ggplot(data = df_le_plot_report, aes(x = strategy, y = LE, group = strategy, fill = strategy)) + 
          scale_color_manual(values = c(my_red, my_darkgreen, my_black)) + 
    scale_fill_manual(values = c(my_red, my_darkgreen, my_black)) + # make the plot
    geom_col() +
 facet_wrap(~ treatment) +
    ggtitle(paste("Life expectancy overview")) 

  ggsave(path = here("../figures"), 
         filename = paste("LE_summary_report.png")) #save plot
```

# 07 Compute Cost-Effectiveness Outcomes

```{r}
### Cost effectiveness analysis for lifeyears ###
# Our effects are life years and therefore the ICER gives the incremental cost per life year gained.  ICER = $/LY

l_df_results <- l_out_ce_base


l_df_cea <- l_df_cea_QALY <- list()

for (n in names(l_param_trt)){
  
  df_cea <- calculate_icers(cost     = l_df_results[[n]]$Cost,
                          effect     = l_df_results[[n]]$LY,
                          strategies = l_df_results[[n]]$Strategy)
 
  l_df_cea[[n]] <- df_cea
  
### Cost effectiveness analysis for quality of life ###
  # Effects of df_cu is utility, and therefore the ICER gives the incremental cost per utility gained. ICER = $/QALY
  df_cea_QALY <- calculate_icers(cost       = l_df_results[[n]]$Cost,
                                 effect     = l_df_results[[n]]$Effect,
                                 strategies = l_df_results[[n]]$Strategy)
  l_df_cea_QALY[[n]] <- df_cea_QALY
}

### Print and save results LY and QALY ###
# Print all CEA dataframes lifeyears
 l_df_cea_LY <- l_df_cea
 
# Print all CEA dataframes QOL
l_df_cea_QALY

# save the data
save(l_df_cea_QALY, file = "../output/l_df_cea_QALY.rda") 
save(l_df_cea, file = "../output/l_df_cea_LY.rda") 

```


## 07.1 Summary table base case - QALY
```{r}
# Create summary report for manuscript/annex
v_names_column <- c("Cost-effective", 
                     "Incr cost Rx", "Incr effect Rx",
                    "ICER", 
                    "Incr NMB", "Incr NHB")
m_summary_cea_QALY <- matrix(data = NA, 
                             ncol = length(v_names_column) ,
                             nrow = length(names(l_param_trt)),
                             dimnames = list(names(l_param_trt), v_names_column))


# NOTE:
# Yes*  = Trt is dominant
# No*   = Trt is dominated by noTrt
# Yes** = Trt is cost-saving ICER > WTP
# No**  = Trt is cost-saving, but not enough that ICER > WTP

for(n in names(l_param_trt)){
  
  df_summary_f    <- l_df_cea_QALY[[n]]
  df_combined_f   <- l_out_ce_base_return_all[[n]]$df_ce_combined
  
    # Values to always store 
  m_summary_cea_QALY[n, "Incr NMB"] <- df_combined_f$NMB[df_combined_f$Strategy == "trt"] - df_combined_f$NMB[df_combined_f$Strategy == "notrt"]
  m_summary_cea_QALY[n, "Incr NHB"] <- df_combined_f$NHB[df_combined_f$Strategy == "trt"] - df_combined_f$NHB[df_combined_f$Strategy == "notrt"]
  
  # Check if treatment is not dominated or dominant
  if(df_summary_f$Status[df_summary_f$Strategy == "trt"] == "D"){
    m_summary_cea_QALY[n, "Cost-effective"] <- "No*"
    m_summary_cea_QALY[n, "Incr effect Rx"] <- df_summary_f$Effect[df_summary_f$Strategy == "trt"] - df_summary_f$Effect[df_summary_f$Strategy == "notrt"]
    m_summary_cea_QALY[n, "Incr cost Rx"] <- df_summary_f$Cost[df_summary_f$Strategy == "trt"] - df_summary_f$Cost[df_summary_f$Strategy == "notrt"]
    
  } else if (df_summary_f$Status[df_summary_f$Strategy == "notrt"] == "D"){
    m_summary_cea_QALY[n, "Cost-effective"] <- "Yes*"
        m_summary_cea_QALY[n,"Incr effect Rx"] <- df_summary_f$Effect[df_summary_f$Strategy == "trt"] - df_summary_f$Effect[df_summary_f$Strategy == "notrt"]
    m_summary_cea_QALY[n, "Incr cost Rx"]     <- df_summary_f$Cost[df_summary_f$Strategy == "trt"] - df_summary_f$Cost[df_summary_f$Strategy == "notrt"]
    
  } else if(!is.na(df_summary_f$ICER[df_summary_f$Strategy == "trt"]) & df_summary_f$ICER[df_summary_f$Strategy == "trt"] > l_param_trt[[n]]$wtp){
    m_summary_cea_QALY[n, "Cost-effective"] <- "No"
    m_summary_cea_QALY[n, "ICER"         ] <- df_summary_f$ICER[df_summary_f$Strategy       == "trt"]
    m_summary_cea_QALY[n, "Incr effect Rx"] <- round(df_summary_f$Inc_Effect[df_summary_f$Strategy == "trt"], 3)
    m_summary_cea_QALY[n, "Incr cost Rx" ] <- round(df_summary_f$Inc_Cost[df_summary_f$Strategy   == "trt"])
  } else if(!is.na(df_summary_f$ICER[df_summary_f$Strategy == "trt"]) & df_summary_f$ICER[df_summary_f$Strategy == "trt"] <= l_param_trt[[n]]$wtp){
    m_summary_cea_QALY[n, "Cost-effective"] <- "Yes"
    m_summary_cea_QALY[n, "ICER"] <- df_summary_f$ICER[df_summary_f$Strategy == "trt"]
    m_summary_cea_QALY[n,"Incr effect Rx"] <- df_summary_f$Inc_Effect[df_summary_f$Strategy == "trt"]
    m_summary_cea_QALY[n,"Incr cost Rx"] <- df_summary_f$Inc_Cost[df_summary_f$Strategy == "trt"]
  } else{
    m_summary_cea_QALY[n, "Incr effect Rx"] <- -1 * df_summary_f$Inc_Effect[df_summary_f$Strategy == "notrt"]
    m_summary_cea_QALY[n, "Incr cost Rx"] <- -1 * df_summary_f$Inc_Cost[df_summary_f$Strategy   == "notrt"]
        m_summary_cea_QALY[n, "ICER"] <- df_summary_f$ICER[df_summary_f$Strategy == "notrt"]
    
        if (round(df_summary_f$ICER[df_summary_f$Strategy       == "notrt"]) > l_param_trt[[n]]$wtp) {
    m_summary_cea_QALY[n, "Cost-effective"] <- "Yes**"
        } else { m_summary_cea_QALY[n, "Cost-effective"] <- "No**"}
    
  }
  df_summary_cea_QALY <- as.data.frame(m_summary_cea_QALY)
}


# Create columns that are numeric 
df_summary_cea_QALY[, -1] <- data.frame(lapply(df_summary_cea_QALY[, -1], as.numeric))
# Save the df in the output folder

save(df_summary_cea_QALY, file = "../output/df_summary_cea_QALY.rda")  


# Format the table 
## Full table
df_summary_cea_QALY_plot_order <- format_table_summary(df_summary_cea_QALY)
df_summary_cea_QALY_plot_order[is.na(df_summary_cea_QALY_plot_order)] <- "n/a"

# Save table summary
png("../figures/table_summary_cea_QALY_all.png", width = 2000, height = 1000, bg = "white", pointsize = 22)
grid.table(df_summary_cea_QALY_plot_order)
dev.off()


## Subset
df_summary_cea_QALY_report <- format_table_summary(df_summary_cea_QALY, v_names_subset = l_names$v_names_trt_report)


format(df_summary_cea_QALY_report, digits = 3, big.mark   = ",")

#df_summary_cea_QALY_report[is.na(df_summary_cea_QALY_report)] <- "-"

df_summary_cea_QALY_report[is.na(df_summary_cea_QALY_report)] <- "n/a"

png("../figures/table_summary_cea_QALY.png", width = 2000, height = 380, bg = "white", pointsize = 22)
grid.table(format(df_summary_cea_QALY_report, digits = 3, big.mark   =","))
dev.off()



```


## 07.2 Summary table base case - LY
```{r}

v_names_column <- c("Cost-effective", 
                     "Incr cost Rx", "Incr effect Rx",
                    "ICER", 
                    "Incr NMB", "Incr NHB")
m_summary_cea_LY <- matrix(data = NA, 
                             ncol = length(v_names_column) ,
                             nrow = length(names(l_param_trt)),
                             dimnames = list(names(l_param_trt), v_names_column))


# NOTE:
# Yes*  = Trt is dominant
# No*   = Trt is dominated by noTrt
# Yes** = Trt is cost-saving ICER > WTP
# No**  = Trt is cost-saving, but not enough that ICER > WTP

for(n in names(l_param_trt)){
  
  df_summary_f    <- l_df_cea_LY[[n]]
  df_combined_f   <- l_out_ce_base_return_all[[n]]$df_ce_combined
  
    # Values to store always 
  m_summary_cea_LY[n, "Incr NMB"] <- df_combined_f$NMB_LY[df_combined_f$Strategy == "trt"] - df_combined_f$NMB_LY[df_combined_f$Strategy == "notrt"]
  m_summary_cea_LY[n, "Incr NHB"] <- df_combined_f$NHB_LY[df_combined_f$Strategy == "trt"] - df_combined_f$NHB_LY[df_combined_f$Strategy == "notrt"]
  
  # check if treatment is not dominated or dominant
  if(df_summary_f$Status[df_summary_f$Strategy == "trt"] == "D"){
    m_summary_cea_LY[n, "Cost-effective"] <- "No*"
    m_summary_cea_LY[n, "Incr effect Rx"] <- df_summary_f$Effect[df_summary_f$Strategy == "trt"] - df_summary_f$Effect[df_summary_f$Strategy == "notrt"]
    m_summary_cea_LY[n, "Incr cost Rx"] <- df_summary_f$Cost[df_summary_f$Strategy == "trt"] - df_summary_f$Cost[df_summary_f$Strategy == "notrt"]
    
  } else if (df_summary_f$Status[df_summary_f$Strategy == "notrt"] == "D"){
    m_summary_cea_LY[n, "Cost-effective"] <- "Yes*"
        m_summary_cea_LY[n,"Incr effect Rx"] <- df_summary_f$Effect[df_summary_f$Strategy == "trt"] - df_summary_f$Effect[df_summary_f$Strategy == "notrt"]
    m_summary_cea_LY[n, "Incr cost Rx"]     <- df_summary_f$Cost[df_summary_f$Strategy == "trt"] - df_summary_f$Cost[df_summary_f$Strategy == "notrt"]
    
  } else if(!is.na(df_summary_f$ICER[df_summary_f$Strategy == "trt"]) & df_summary_f$ICER[df_summary_f$Strategy == "trt"] > l_param_trt[[n]]$wtp){
    m_summary_cea_LY[n, "Cost-effective"] <- "No"
    m_summary_cea_LY[n, "ICER"         ] <- df_summary_f$ICER[df_summary_f$Strategy       == "trt"]
    m_summary_cea_LY[n, "Incr effect Rx"] <- round(df_summary_f$Inc_Effect[df_summary_f$Strategy == "trt"], 3)
    m_summary_cea_LY[n, "Incr cost Rx" ] <- round(df_summary_f$Inc_Cost[df_summary_f$Strategy   == "trt"])
  } else if(!is.na(df_summary_f$ICER[df_summary_f$Strategy == "trt"]) & df_summary_f$ICER[df_summary_f$Strategy == "trt"] <= l_param_trt[[n]]$wtp){
    m_summary_cea_LY[n, "Cost-effective"] <- "Yes"
    m_summary_cea_LY[n, "ICER"] <- df_summary_f$ICER[df_summary_f$Strategy == "trt"]
    m_summary_cea_LY[n,"Incr effect Rx"] <- df_summary_f$Inc_Effect[df_summary_f$Strategy == "trt"]
    m_summary_cea_LY[n,"Incr cost Rx"] <- df_summary_f$Inc_Cost[df_summary_f$Strategy == "trt"]
  } else{
    m_summary_cea_LY[n, "Incr effect Rx"] <- -1 * df_summary_f$Inc_Effect[df_summary_f$Strategy == "notrt"]
    m_summary_cea_LY[n, "Incr cost Rx"] <- -1 * df_summary_f$Inc_Cost[df_summary_f$Strategy   == "notrt"]
        m_summary_cea_LY[n, "ICER"] <- df_summary_f$ICER[df_summary_f$Strategy == "notrt"]
    
        if (round(df_summary_f$ICER[df_summary_f$Strategy       == "notrt"]) > l_param_trt[[n]]$wtp) {
    m_summary_cea_LY[n, "Cost-effective"] <- "Yes**"
        } else { m_summary_cea_LY[n, "Cost-effective"] <- "No**"}
    
  }
  df_summary_cea_LY <- as.data.frame(m_summary_cea_LY)
}


# make all columns that are numbers numeric 
df_summary_cea_LY[, -1] <- data.frame(lapply(df_summary_cea_LY[, -1], as.numeric))
# Save the df in the output folder

save(df_summary_cea_LY, file = "../output/df_summary_cea_LY.rda")  


# Format the table 
## Full tabel
df_summary_cea_LY_plot_order <- format_table_LY_summary(df_summary_cea_LY)

df_summary_cea_LY_plot_order[is.na(df_summary_cea_LY_plot_order)] <- "n/a"
png("../figures/table_summary_cea_LY_all.png", width = 2000, height = 1000, bg = "white", pointsize = 22)
grid.table(df_summary_cea_LY_plot_order)
dev.off()


## Subset
df_summary_cea_LY_report <- format_table_summary(df_summary_cea_LY, v_names_subset = l_names$v_names_trt_report)


format(df_summary_cea_LY_report, digits = 3, big.mark   = ",")

#df_summary_cea_QALY_report[is.na(df_summary_cea_QALY_report)] <- "-"

df_summary_cea_LY_plot_order[is.na(df_summary_cea_LY_plot_order)] <- "n/a"
png("../figures/table_summary_cea_LY.png", width = 2000, height = 1000, bg = "white", pointsize = 22)
grid.table(format(df_summary_cea_LY_report, digits = 3, big.mark   =","))
dev.off()



```


# 9 PA
## 9.1 General PA settings
```{r}
seed <- 2020
set.seed(seed)       # set the seed to allow reproduction of results
```


## 9.2 Generate the PA dataset
```{r}
# Print the copy of input parameters as defined earlier in the code
param_psa_input    # the original data for the usual care arm
param_trt <- param_trt_psa_input  # the original data for the treatment arms, including parameters that are relevant for all strategies

# Create lists to store the data frames with PSA data for the different treatments
l_df_param_psa <- l_df_psa <- l_m_Parameters <- list()

# Check loop row by row
# n = names_treatment[1] # use this line to select a specific treatment to check code below

# Create loops to select treatments, create datafame and list for PSA parameters
# This way we split the data for treatments
for (n in names_treatment){
  sub_param_psa <- filter(param_trt, Treatment == n) # Select the values corresponding to each treatment
  assign(paste("df_param_psa_", n, sep = ""), sub_param_psa) # Same in the list name of the treatment
  l_df_param_psa[[n]] <- sub_param_psa
  remove(sub_param_psa) # remove the temporary files 
}

# Create dataframe with parameters values of each run of the PSA 
# This loop makes use of the make_psa_df functions
for (n in names_treatment){ # loop where also "ALL" is included
  df_temporary            <- l_df_param_psa[[n]] # Save df in temp
  param_psa_trt_temporary <- make_psa_df(param = df_temporary, n_iter = n_iter, seed = seed)
  l_df_psa[[n]]           <- param_psa_trt_temporary
  remove(df_temporary)
}

# For general / cohort parameters
#  This code makes use of the make_psa_df function
df_psa_notrt <- make_psa_df(param = param_psa_input, n_iter = n_iter, seed = seed)
# as this is the usual care arm, we will refer to this as 'no treatment' or notrt

for (n in v_names_trt){
  df_temporary     <- l_df_psa[[n]]     # select the parameters for trt
  df_temporary_all <- l_df_psa[["All"]] # select those that belong to all
  df_psa_notrt     <- df_psa_notrt      # this is no trt/cohort parameters
  
  param_psa_total_temporary <- rbind(df_temporary, df_psa_notrt, df_temporary_all) # combine all the parameters
  l_m_Parameters[[n]] <- gen_psa(df_param_psa = param_psa_total_temporary) # make a list with the matrix of parameters for each iteration for the multiple drugs.
}

# Save the PA data
save(l_m_Parameters, file = "../output/l_m_Parameters.rda")  

# Check if there are different "treatment" groups
tail(param_psa_total_temporary$Treatment)
unique(param_psa_total_temporary$Treatment)

# Transform the data into DARTH style using the function gen_psa
m_Parameters <- df_param_psa <- gen_psa(df_param_psa = param_psa_total_temporary)
```

### 9.2.2 Create histograms of the PA parameters for a specific list
The selected list is split for treatment specific and parameters that are for all treatments 
```{r, eval = FALSE}
# This section can be used to investigate specific parameters of a specific treatment
# The next section however will be saved, which gives all parameters except an exclude list for all treatments

# Histogram of parameters for a treatment 
df_psa_input <- l_m_Parameters[[1]]

# Adjust the numbers of which parameters we would like to plot
length(colnames(df_psa_input))
head(df_psa_input)
dput(names(df_psa_input))

# Use this code to only plot those values that contain distribution (are not all the same)
cols <- apply(df_psa_input, 2, function(x) length(unique(x)) > 1)
distr_cols <- dput(names(df_psa_input)[cols])

df_psa_input_plot_hist_keyparam <- df_psa_input[, distr_cols]

# Use this code to manually select those columns of interest 
# df_psa_input_plot_hist_keyparam <- df_psa_input[, c(
#  "rr_D_Trt_timespan1", "n_age", "c_D", "c_Hospital", "c_I_noVent", 
#   "c_I_vent", "c_Healthcare", "c_recovery", "p_H", "p_IC_notrt", 
#   "p_R_IC_D", "p_R_H_D", "p_R_IC_D_vent", "p_R_IC_D_novent", "p_men", 
#   "p_vent", "u_D", "u_H", "u_I", "u_R_H", "u_R_IC", "e_H", "e_R_IC", 
#   "e_R_H", "e_D", "c_LY_2020", "p_Private_insurance", "c_RCT_fixed", 
#   "c_RCT_ppo", "wtp", "t_Die_mj", "p_Die_1", "p_Die_2", "p_IC", 
#   "c_Trt_private", "c_Trt_public", "n_Trt", "n_days_timespan1", 
#   "rr_D_Trt_timespan2", "n_days_timespan2", "t_hr_D_Trt", "LOS_noTrt", 
#   "LOS_Trt"
#   )]
count(df_psa_input_plot_hist_keyparam)

#head(df_psa_input[, df_psa_input_plot_hist_keyparam])
  
plot <- ggplot(melt(df_psa_input_plot_hist_keyparam, variable.name = "Parameter"), aes(x = value)) +
       facet_wrap(~Parameter, scales = "free") +
       geom_histogram(aes(y = ..density..)) +
       theme_bw(base_size = 16) + 
       theme(axis.text = element_text(size = 8))
plot

# Extra code to store the PA histograms if of interest 
 ggsave(plot, path = here("../figures"), filename = paste("PSA_parameter_histogram", "_", n, ".png", sep =""))  # save the plot

 
```

### 9.2.3 Initial data frames
```{r}
# Initialize dataframes with PA output 
# Dataframe of costs and effectiveness 
df_c_psa <- df_e_psa <- df_e_LY_psa <- as.data.frame(matrix(0, 
                                                            nrow = n_iter,
                                                            ncol = n_str))
colnames(df_c_psa) <- colnames(df_e_psa) <- colnames (df_e_LY_psa) <- v_names_str

# Matrix for the output of the PA 
v_output <- c("LY", "QALY", "Costs")            # Vector of output names
m_output <- matrix(NA, 
                   ncol = as.numeric(length(v_output)) * as.numeric(n_str), 
                   nrow = n_iter, 
                   dimnames = list(paste("Iteration", 1:n_iter, sep = " "), 
                                   (paste(rep(v_output, n_str), rep(c("notrt", "trt"), 
                                  each = length(v_output)), sep = " "))))

l_m_output <- list()

```

##9.2 Run PA 
```{r, eval = TRUE, echo = FALSE, warning=FALSE, error=FALSE, results=FALSE, message = FALSE}

# select the treatment of interest
m_Parameters <- l_m_Parameters[[1]] 


# Run Markov model on each parameter set of PSA input dataset
for(n in names(l_param_trt)){  
  
  # select the treatment of interest
  m_Parameters <- l_m_Parameters[[n]] 
  
  for(g in 1:n_iter){
    l_param_psa <- as.list(m_Parameters[g, ]) # select the items for this iteration
    
    l_param_psa <- c(l_param_psa, l_input_general) # Combine with the general input
    l_param_psa$df_r_HD <- df_r_HD # Add the df with the mortality rate to the general input
    
    l_out_temp  <- calculate_cea_output_VOI_COVID(l_param_psa, n_wtp = l_param_psa$wtp, verbose = FALSE)
    
    # store key parameters
    df_c_psa[g, ]    <- l_out_temp$Cost
    df_e_psa[g, ]    <- l_out_temp$Effect
    df_e_LY_psa[g, ] <- l_out_temp$LY
  
    # Display simulation progress
    if(g/(n_iter/10) == round(g/(n_iter/10), 0)) { # display progress every 10%
      cat('\r', paste(g/n_iter * 100, "% PSA of treatment", n, "done & ", round(which(names(l_param_trt) == n)/length(names(l_param_trt)) * 100, 0), "% total PSA", sep = " "))
    
  }
    
    #Store the treatment specific values 
    m_output[, "Costs notrt"] <- df_c_psa$notrt
    m_output[, "Costs trt"]   <- df_c_psa$trt
  
    m_output[, "QALY notrt"]  <- df_e_psa$notrt
    m_output[, "QALY trt"]    <- df_e_psa$trt
  
    m_output[, "LY notrt"]    <- df_e_LY_psa$notrt
    m_output[, "LY trt"]      <- df_e_LY_psa$trt
    
    l_m_output[[n]] <- m_output

    }
  }

save(l_m_output, file = "../output/l_m_output.rda")   # save the PSA data
```



An alternative option is to run the smulation with paralel cores (9.2). For laptops with multiple cores this may be the quicker option to run our code

### 9.2.2 Run PSA in parallel on MacOS
```{r, eval = FALSE}

# Inititate list
l_df_par <- l_m_output_par <-  list()

m_output_par <- matrix(NA, 
                   ncol = as.numeric(length(v_output)) * as.numeric(n_str), 
                   nrow = n_iter, 
                   dimnames = list(paste("Iteration", 1:n_iter, sep = " "), 
                                   (paste(rep(v_output, n_str), rep(c("notrt", "trt"), 
                                  each = length(v_output)), sep = " "))))

os <- get_os()
print(paste0("Parallelized PSA on ", os))
no_cores <- parallel::detectCores() - 2 # This line of code detects how many cores are available on a computer, and how many cores can be used to run the code. Running the code with more cores at the same time can help to decrease the running time. For example, if 4 cores are detected, the model will be run on 2 cores, while the user can (depending on their computer settings and options) continue to use their computer. This can also be adjusted to a cutom number of cores by uncommenting and adjusting the line below.
# no_cores <- 3
n_time_init_psa <- Sys.time()

# Run Markov model on each parameter set of PSA input dataset
for(n in names(l_param_trt)){  
  
  # select the treatment of interest
  m_Parameters <- l_m_Parameters[[n]] 

# ## Run parallelized PSA based on OS
 if(os == "macosx"){
   # Initialize cluster object
   cl <- parallel::makeForkCluster(no_cores)
   # Register clusters
   doParallel::registerDoParallel(cl)
   # Run parallelized PSA
   
   df_ce <- foreach::foreach(g = 1:n_iter, .combine = rbind) %dopar% {
     
     l_param_psa <- as.list(m_Parameters[g, ])
     l_param_psa <- c(l_param_psa, l_input_general) # Combine with the general input
     l_param_psa$df_r_HD <- df_r_HD                 # Add the df with the mortality rate to the general input
   
     
     l_out_temp <- calculate_cea_output_VOI_COVID(l_param_psa, n_wtp = l_param_psa$wtp, verbose = FALSE)
     df_ce <- c(l_out_temp$Cost, 
                l_out_temp$Effect, 
                l_out_temp$LY,
                l_out_temp$NMB,
                l_out_temp$NHB)
    
   }

    # Save the output
     m_output_par[, "Costs notrt"]   <- df_ce[, 1]
     m_output_par[, "Costs trt"]     <- df_ce[, 2]
     
     m_output_par[, "QALY notrt"] <- df_ce[, 3]
     m_output_par[, "QALY trt"]   <- df_ce[, 4]
     
     m_output_par[, "LY notrt"]   <- df_ce[, 5]
     m_output_par[, "LY trt"]     <- df_ce[, 6]
  
   }
 l_df_par[[n]] <- df_ce
 l_m_output_par[[n]] <- m_output_par
 
  }

n_time_end_psa <- Sys.time()
stopCluster(cl)

n_time_init_psa 
n_time_end_psa - n_time_init_psa 

save(l_m_output_par, file = "../output/l_m_output_par.rda")    #  save the parallel data from the PSA

save(l_df_par, file = "../output/l_df_par.rda")    #  save the parallel data from the PSA
```


### 9.2.3 Test whether running the analyss with parallel processing gives the same results
```{r, eval = FALSE}
# Test if parallel gives the same results as non-parallel processing

l_check_par <- list()
for (n in names(l_param_trt) ){

l_m_output_par[[n]] == l_m_output[[n]]

l_check_par[[n]] <- summary(l_m_output_par[[n]] == l_m_output[[n]])

}
# Check if we get identical results
l_check_par

for(n in names(l_param_trt)){
  
    # store key parameters
    df_c_psa[, 1:2]    <- l_df_par[[n]][, 1:2]
    df_e_psa[, 1:2]    <- l_df_par[[n]][, 3:4]
    df_e_LY_psa[, 1:2] <- l_df_par[[n]][, 5:6]

    
    #Store the treatment specific values 
    m_output_par[, "Costs notrt"] <- df_c_psa$notrt
    m_output_par[, "Costs trt"]   <- df_c_psa$trt
  
    m_output_par[, "QALY notrt"]  <- df_e_psa$notrt
    m_output_par[, "QALY trt"]    <- df_e_psa$trt
  
    m_output_par[, "LY notrt"]    <- df_e_LY_psa$notrt
    m_output_par[, "LY trt"]      <- df_e_LY_psa$trt
    
    l_m_output[[n]] <- m_output_par
}



save(l_m_output, file = "../output/l_m_output.rda") 
```


### 9.3.1 Choose correct list (parallel or not)
```{r, eval = FALSE}
# Conditional on having run the PA with or without parallel processing, save the correct list for the upcoming analyses
# By default, l_param_output is used.
# Alternatively if l_param_par should be used, overwrite this list

if(exists("l_param_output_par", envir = .GlobalEnv)) {
  l_param_output <- l_param_output_par
}

load(file = "../output/l_m_output.rda")
# NB: this chunk is set to eval = FALSE, however, when not wanting to run the entire PA but simply load the previously generated PA output set, run this line
```


## 9.3 Matrices for PA run and final output
```{r, eval = TRUE}
# Matrix for the output of the PSA 
v_Output <- c("LY", "QALY", "Costs")            # Vector of output names
m_output <- matrix(NA, 
                   ncol = as.numeric(length(v_Output)) * as.numeric(n_str), 
                   nrow = n_iter, 
                   dimnames = list(paste("Iteration", 1:n_iter, sep = " "), 
                                   (paste(rep(v_Output, n_str), rep(1:n_str, 
                                  each = length(v_Output)), sep = " "))))



# Fills in transition matrix for each iteration with values from the distribution matrices
m_P_notrt_PSA <- m_P_trt_PSA <- m_R_costs_notrt_PSA <- m_R_costs_trt_PSA <- matrix(NA, nrow = n_states, ncol = n_states, 
                                      dimnames = list(v_names_states, v_names_states))
  
m_M_notrt_PSA <- m_M_trt_PSA <- matrix(NA, 
                                nrow     = n_t + 1, ncol = n_states,
                                dimnames = list(paste("cycle", 0:n_t, sep = " "), v_names_states))
 

# initialize multidimensional array for both strategies
a_A_notrt_PSA <- a_A_trt_PSA <- a_Y_costs_notrt_PSA <- a_Y_costs_trt_PSA <- array(0, 
                              dim = c(n_states, n_states, n_t + 1), 
                              dimnames = list(v_names_states, v_names_states, 0:n_t)) 
```

## 9.4 Incremental effects
```{r}

# Create lists
l_df_PSA_QALY               <- l_df_PSA_LY <- l_df_PSA_Costs <- list()
l_df_cea_PSA_LY             <- l_df_cea_PSA_QALY             <- list()

l_v_IncrLY_PSA   <- l_v_IncrQALY_PSA <- l_v_IncrCosts_PSA <- list()
l_df_output_incr <- list()

for(n in names(l_param_trt)){  
  m_output  <- l_m_output[[n]] # Select on output frame
  df_output <- as.data.frame(l_m_output[[n]])

  # Incremental effects between intervention and control in lifeyears 
  # 1 = no Treatment 
  # 2 = Treatment
 l_v_IncrLY_PSA[[n]]    <- m_output[, "LY trt"]    - m_output[, "LY notrt"] 
 l_v_IncrQALY_PSA[[n]]  <- m_output[, "QALY trt"]  - m_output[, "QALY notrt"] 
 l_v_IncrCosts_PSA[[n]] <- m_output[, "Costs trt"] - m_output[, "Costs notrt"]

 
 df_output$iLY    <- m_output[, "LY trt"]    - m_output[, "LY notrt"] 
 df_output$iQALY  <- m_output[, "QALY trt"]  - m_output[, "QALY notrt"] 
 df_output$iCosts <- m_output[, "Costs trt"] - m_output[, "Costs notrt"]
 
 
l_df_PSA_LY[[n]] <- df_PSA_LY<- data.frame(Strategy = v_names_str,
                     Cost = c(mean(m_output[, "Costs notrt"]), mean(m_output[, "Costs trt"])),
                     LY = c(mean(m_output[, "LY notrt"]), mean(m_output[, "LY trt"])),
                     Inc_Cost =   c(NA, mean(l_v_IncrCosts_PSA[[n]])),
                     Inc_Effect = c(NA, mean(l_v_IncrLY_PSA[[n]])))
                     

l_df_cea_PSA_LY[[n]] <- calculate_icers(cost   = df_PSA_LY$Cost,
                                      effect   = df_PSA_LY$LY,
                                    strategies = df_PSA_LY$Strategy)



l_df_PSA_QALY[[n]] <- df_PSA_QALY <- data.frame(Strategy = v_names_str,
                     Cost = c(mean(m_output[, "Costs notrt"]), mean(m_output[, "Costs trt"])),
                     QALY = c(mean(m_output[, "QALY notrt"]),  mean(m_output[, "QALY trt"])),
                     Inc_Cost = c(NA, mean(l_v_IncrCosts_PSA[[n]])),
                     Inc_Effect = c(NA, mean(l_v_IncrQALY_PSA[[n]])))
                     
l_df_cea_PSA_QALY[[n]] <- calculate_icers(cost   = df_PSA_QALY$Cost,
                                        effect   = df_PSA_QALY$QALY,
                                      strategies = df_PSA_LY$Strategy)


l_df_output_incr[[n]] <- df_output

### QALY ####
# Calculate net monetary benefit
   NMB  <- (df_PSA_QALY$QALY * l_param_trt[[n]]$wtp) - df_PSA_QALY$Cost
   iNMB <-  mean(df_output$iQALY) * l_param_trt[[n]]$wtp  - mean(df_output$iCosts)
   l_df_PSA_QALY[[n]]$NMB <- NMB
   l_df_PSA_QALY[[n]]$iNMB[l_df_PSA_QALY[[n]]$Strategy == "trt"] <- iNMB


 # Calculate Net Health benefit 
   NHB <-  df_PSA_QALY$QALY - (df_PSA_QALY$Cost / l_param_trt[[n]]$wtp)
   l_df_PSA_QALY[[n]]$NHB <- NHB
  
   iNHB <-   mean(df_output$iQALY) - (mean(df_output$iCosts) / l_param_trt[[n]]$wtp  )
    
   l_df_PSA_QALY[[n]]$iNHB[l_df_PSA_QALY[[n]]$Strategy == "trt"] <- iNHB
   
   
   
   ### LY ####
# Calculate net monetary benefit
   l_df_PSA_LY[[n]]$NMB <- (df_PSA_LY$LY * l_param_trt[[n]]$wtp) - df_PSA_LY$Cost
    
    iNMB <-  mean(df_output$iLY) * l_param_trt[[n]]$wtp  - mean(df_output$iCosts)
    l_df_PSA_LY[[n]]$iNMB[l_df_PSA_LY[[n]]$Strategy == "trt"] <- iNMB

 # Calculate Net Health benefit
   l_df_PSA_LY[[n]]$NHB <- df_PSA_LY$LY - (df_PSA_LY$Cost / l_param_trt[[n]]$wtp)
   
   iNHB <-   mean(df_output$iLY) - (mean(df_output$iCosts) / l_param_trt[[n]]$wtp  )
   l_df_PSA_LY[[n]]$iNHB[l_df_PSA_LY[[n]]$Strategy == "trt"] <- iNHB
 
   
}


save(l_df_PSA_QALY,     file = "../output/l_df_PSA_QALY.rda")
save(l_df_PSA_LY,     file = "../output/l_df_PSA_LY.rda")
save(l_df_cea_PSA_QALY, file = "../output/l_df_cea_PSA_QALY.rda")
save(l_df_cea_PSA_LY,   file = "../output/l_df_cea_PSA_LY.rda")
save(l_df_output_incr,  file = "../output/l_df_output_incr.rda")
```



## 9.5 CE plane
```{r}
# create a list with uncertainty for presenting the 95% lower and upper bound
# This is used for reporting in the manuscript
l_grid_plots_CE_plane_QALY<- l_grid_plots_CE_plane_LY<-l_df_cea_PSA_QALY_uncertainty<- l_df_cea_PSA_LY_uncertainty <- list()

for (n in names(l_param_trt)){
# Create PSA object for `dampack`
## Life Years ##
l_psa_plot_LY <- make_psa_obj(cost  = as.data.frame(l_m_output[[n]][, c("Costs notrt", "Costs trt")]), 
                      effectiveness = as.data.frame(l_m_output[[n]][, c("LY notrt", "LY trt")]), 
                      parameters    = l_m_Parameters[[n]], 
                      strategies    = v_names_str)

l_df_cea_PSA_LY_uncertainty[[n]] <- calculate_icers_psa(l_psa_plot_LY, uncertainty = TRUE)

plot_psa_LY<- plot(l_psa_plot_LY) + 
        geom_vline(xintercept = 0, color = my_darkgray, size = 0.6) +
  geom_hline(yintercept = 0, color = my_darkgray, size = 0.6) +
  labs(title = paste("Cost-effectiveness plane", n, sep = " "), 
       subtitle = "Effectiveness are life years (LY)") +
  scale_color_manual(values = c(my_lightred, my_green, my_black)) + 
  scale_fill_manual( values = c(my_lightred, my_green, my_black))

# Add plot to list
l_grid_plots_CE_plane_LY[[n]] <- plot_psa_LY

#ggsave(path = here("../figures"), filename = paste("CE-plane_LY", "_", remove_date_from_name(n), ".png", sep =""))  # save the plot


## QALY ##

l_psa_plot_QALY <- make_psa_obj(cost  = as.data.frame(l_m_output[[n]][, c("Costs notrt", "Costs trt")]), 
                      effectiveness = as.data.frame(l_m_output[[n]][, c("QALY notrt", "QALY trt")]), 
                      parameters    = l_m_Parameters[[n]], 
                      strategies    = v_names_str)

plot_psa_QALY<-   plot(l_psa_plot_QALY) + 
    labs(title = paste("Cost-effectiveness plane", remove_date_from_name(n), sep=" "), subtitle = "Effectiveness are QALYs") +
    geom_vline(xintercept = 0, color = my_darkgray, size = 0.6) +
    geom_hline(yintercept = 0, color = my_darkgray, size = 0.6) +
    scale_color_manual(values = c(my_red, my_darkgreen, my_black)) + 
    scale_fill_manual(values = c(my_red, my_darkgreen, my_black))

  l_df_cea_PSA_QALY_uncertainty[[n]] <- calculate_icers_psa(l_psa_plot_QALY, uncertainty = TRUE)

  # Add plot to list
l_grid_plots_CE_plane_QALY[[n]] <- plot_psa_QALY
  
#ggsave(path = here("../figures"), filename = paste("CE-plane_QALY", "_", remove_date_from_name(n), ".png", sep =""))  # save the plot

}

# Save summary figures
## Create the grid plot 
grid.arrange(grobs = l_grid_plots_CE_plane_LY, ncol = n_cols_grid, nrow = n_rows_grid)
# Create a final grid plot of all plots
all_grid_plots_CE_plane_LY <- do.call(grid.arrange, c(l_grid_plots_CE_plane_LY, ncol = n_cols_grid))
ggsave("../figures/all_grid_plots_CE_plane_LY.png", all_grid_plots_CE_plane_LY, width = 30, height = 30, units = "in")
all_grid_plots_CE_plane_LY


# Create the grid plot 
grid.arrange(grobs = l_grid_plots_CE_plane_QALY, ncol = n_cols_grid, nrow = n_rows_grid)
# Create a final grid plot of all plots
all_grid_plots_CE_plane_QALY <- do.call(grid.arrange, c(l_grid_plots_CE_plane_QALY, ncol = n_cols_grid))
ggsave("../figures/all_grid_plots_CE_plane_QALY.png", all_grid_plots_CE_plane_QALY, width = 30, height = 30, units = "in")

all_grid_plots_CE_plane_QALY

```


### 9.5.1 CE-plane Incremental 
```{r}

# Create an empty list to store the plots
l_grid_plots_CE_plane_QALY_inc <- l_grid_plots_CE_plane_LY_inc <- list()

for (n in names(l_param_trt)){
  
  plot_inc_CE_plane_LY <- make_psa_obj(cost  = as.data.frame(l_df_output_incr[[n]]$iCosts), 
                               effectiveness = as.data.frame(l_df_output_incr[[n]]$iLY), 
                                parameters   = l_m_Parameters[[n]], 
                               strategies    = "Incremental")
  
  plot <- plot(plot_inc_CE_plane_LY) + 
      geom_vline(xintercept = 0, color = my_darkgray, size = 0.6) +
      geom_hline(yintercept = 0, color = my_darkgray, size = 0.6) +
    labs(title     = paste("Incremental Cost-effectiveness plane"), 
        subtitle   = paste(n, ": intervention vs control", sep = " ")) + 
          xlab("Incremental Effectiveness (LY)") +
      ylab("Incremental Costs (USD)") +
    scale_color_manual(values = c(my_darkgray, my_black)) + 
    scale_fill_manual(values = c(my_darkgray, my_black))
  
  # Add plot to list
l_grid_plots_CE_plane_LY_inc[[n]] <- plot

#  ggsave(path = here("../figures"),          filename = paste("CE-plane_incr_LY", "_", remove_date_from_name(n), ".png", sep = ""))  # save the plot


    plot_inc_CE_plane_QALY <- make_psa_obj(cost  = as.data.frame(l_df_output_incr[[n]]$iCosts), 
                               effectiveness = as.data.frame(l_df_output_incr[[n]]$iQALY), 
                                parameters   = l_m_Parameters[[n]], 
                               strategies    = "Incremental")
  
  plot <- plot(plot_inc_CE_plane_QALY) + 
    labs(title     = paste("Incremental Cost-effectiveness plane"), 
         subtitle =   paste(n, ": intervention vs control", sep = " ")) +
      xlab("Incremental Effectiveness (QALY)") +
      ylab("Incremental Costs (USD)") +  
    geom_vline(xintercept = 0, color = my_darkgray, size = 0.6) +
  geom_hline(yintercept = 0, color = my_darkgray, size = 0.6) +
        scale_color_manual(values = c(my_yellow, my_black)) + 
    scale_fill_manual(values = c(my_yellow, my_black))
  
  # Add plot to list
l_grid_plots_CE_plane_QALY_inc[[n]] <- plot
  
 # ggsave(path = here("../figures"),   filename = paste("CE-plane_incr_QALY", "_", remove_date_from_name(n), ".png", sep = ""))  # save the plot

}

# Create the grid plot 
grid.arrange(grobs = l_grid_plots_CE_plane_LY_inc, ncol = n_cols_grid, nrow = n_rows_grid)

# Create a final grid plot of all plots
all_grid_plots_CE_plane_LY_inc <- do.call(grid.arrange, c(l_grid_plots_CE_plane_LY_inc, ncol = n_cols_grid))
ggsave("../figures/all_grid_plots_CE_plane_LY_inc.png", all_grid_plots_CE_plane_LY_inc, width = 30, height = 30, units = "in")

# Create the grid plot 
grid.arrange(grobs = l_grid_plots_CE_plane_QALY_inc, ncol = n_cols_grid, nrow = n_rows_grid)

# Create a final grid plot of all plots
all_grid_plots_CE_plane_QALY_inc <- do.call(grid.arrange, c(l_grid_plots_CE_plane_QALY_inc, ncol = n_cols_grid))
ggsave("../figures/all_grid_plots_CE_plane_QALY_inc.png", all_grid_plots_CE_plane_QALY_inc, width = 30, height = 30, units = "in")


```


### 9.5.2 Incremental CE-plane - all treatments

```{r, echo=FALSE, warning=FALSE, error=FALSE, results=FALSE}
load(file = "../output/l_df_output_incr.rda")
#load(file = "../output/l_param_trt.rda")
load(file = "../output/l_param_trt_basecase.rda")

m_CE_summary <- matrix(NA, nrow = 2, ncol = length(names(l_param_trt)))
colnames(m_CE_summary) <- names(l_param_trt)
rownames(m_CE_summary) <- c("iCosts", "iEffects")


# Add WTP threshold to plot
# NB: it is possible too add other WTP ratio's by adjusting the slope number
# https://stackoverflow.com/questions/49418545/what-is-the-best-way-to-add-ratio-lines-to-plot-in-ggplot2
ratios <- data.frame(intercept = 0, 
                     slope = c(wtp_level_main),  # Adjust slope for different WTP
                     Ratio = paste("WTP"))


for (n in names(l_param_trt)){
  m_CE_summary["iCosts", n]   <- mean(l_df_output_incr[[n]]$iCosts)
  m_CE_summary["iEffects", n] <- mean(l_df_output_incr[[n]]$iQALY)
}


    df_m_CE_summary <- as.data.frame(m_CE_summary)
    plot_inc_CE_summary <- make_psa_obj(cost  = df_m_CE_summary["iCosts", ] , 
                               effectiveness  = df_m_CE_summary["iEffects", ], 
                                parameters    = df_m_CE_summary["iCosts", ], 
                                strategies    = colnames(df_m_CE_summary))
    
  plot(plot_inc_CE_summary) + 
    labs(title     = paste("Incremental Cost-effectiveness plane"), 
         subtitle =   paste("Mean estimates of intervention vs control PA ")) +
      xlab("Incremental Effectiveness (QALY)") +
      ylab("Incremental Costs (USD)") +  
    geom_vline(xintercept = 0, color = my_darkgray, size = 0.6) +
  geom_hline(yintercept = 0, color = my_darkgray, size = 0.6) +
    geom_abline(aes(intercept = 0, slope = 100000),
              show.legend = FALSE, size = 1,colour = my_lightred) +
    guides(colour = guide_legend(override.aes = list(size = 4))) +     theme(legend.text = element_text(size = 15), legend.title = element_blank())
  
  
ggsave(path = here("../figures"), filename = paste("CE-plot_inc_CE_summary.png"),  width = 30, height = 15, units = "in")
  
```




### 9.5.3 Incremental CE-plane - all treatments with uncertainty elliplse

```{r, echo=FALSE, warning=FALSE, error=FALSE, results=FALSE}
load(file = "../output/l_df_output_incr.rda")

df_test         <- do.call(cbind.data.frame, l_df_output_incr)
df_test_iQALY   <- df_test[str_detect(colnames(df_test), c("iQALY"))]
colnames(df_test_iQALY) <-  gsub(".iQALY", "", colnames(df_test_iQALY))
df_test_iCosts  <- df_test[str_detect(colnames(df_test), c("iCosts"))]
colnames(df_test_iCosts) <-  gsub(".iCosts", "", colnames(df_test_iCosts))

# make psa object  
plot_inc_CE_summary <- make_psa_obj(cost  = df_test_iCosts, 
                               effectiveness  = df_test_iQALY, 
                                parameters    = df_test_iCosts, 
                                strategies    = colnames(df_test_iCosts))
  # plot psa object  
  plot(plot_inc_CE_summary, ellipse = TRUE, alpha = 0) + 
    labs(title     = paste("Incremental Cost-effectiveness plane"), 
         subtitle =   paste("Mean estimates of intervention vs control PA")) +
      xlab("Incremental Effectiveness (QALY)") +
      ylab("Incremental Costs (USD)") +  
    geom_vline(xintercept = 0, color = "darkgray", size = 0.6) +
  geom_hline(yintercept = 0, color = "darkgray", size = 0.6)+
     guides(colour = guide_legend(override.aes = list(size = 4))) +     theme(legend.text = element_text(size = 15), legend.title = element_blank())
  
  ggsave(path = here("../figures"), 
         filename = paste("CE-plot_inc_CE_summary_ellipse.png"),  width = 30, height = 15, units = "in")  # save the plot
  
  
  
  
  
```



### 9.5.4 CE-plane Incr LY and QALY
```{r, echo=FALSE, warning=FALSE, error=FALSE, results=FALSE}

# Create an empty list to store the plots
l_grid_plots_CE_plane_incr_combined <- list()

for (n in v_names_trt){
  
  plot_incr_both <- make_psa_obj(cost  = as.data.frame(l_df_output_incr[[n]][, c("iCosts", "iCosts")]), 
                         effectiveness = as.data.frame(l_df_output_incr[[n]][, c("iLY", "iQALY")]), 
                         parameters    = l_m_Parameters[[n]], 
                         strategies    = c("LY", "QALY"))


 plot <- plot(plot_incr_both) + 
    labs(title = paste("Incremental Cost-Effectiveness plane"),
         subtitle =   paste(n, ": intervention vs control", sep = " ")) +
    xlab("Incremental Effectiveness") +
    ylab("Incremental Costs (USD)") +
    geom_vline(xintercept = 0, color = my_darkgray, size = 0.6) +
    geom_hline(yintercept = 0, color = my_darkgray, size = 0.6) +
    scale_color_manual(values = c(my_darkgray, my_yellow,  my_black)) +  
    scale_fill_manual(values  = c(my_darkgray, my_yellow,  my_black)) + 
    theme(legend.title = element_blank())+
     guides(colour = guide_legend(override.aes = list(size = 4))) +     theme(legend.text = element_text(size = 15), legend.title = element_blank())
  
   l_grid_plots_CE_plane_incr_combined[[n]] <- plot
   
  

 
  # ggsave(path = here("../figures"),filename = paste("CE-plane_incr_combined", "_", remove_date_from_name(n), ".png", sep = ""))  # save the plot

}

# Create the grid plot 
grid.arrange(grobs = l_grid_plots_CE_plane_incr_combined, ncol = n_cols_grid, nrow = n_rows_grid)

# Create a final grid plot of all plots
all_grid_plots_CE_plane_incr_combined <- do.call(grid.arrange, c(l_grid_plots_CE_plane_incr_combined, ncol = n_cols_grid))
ggsave("../figures/all_grid_plots_CE_plane_incr_combined.png", all_grid_plots_CE_plane_incr_combined, width = 30, height = 30, units = "in")

```

```{r, echo=FALSE, warning=FALSE, error=FALSE, results=FALSE}
# Create an empty list to store the plots with default axis limits
l_grid_plots_CE_plane_incr_combined <- list()

# Create an empty list to store the plots with adjusted axis limits
l_grid_plots_CE_plane_incr_combined_xylim <- list()

# Define the x and y limits for the adjusted plot
xlim <- c(-8.5, 8.5)
ylim <- c(-150000, 150000)

# Loop through each item in v_names_trt
for (n in v_names_trt){
  
  # Create the plot with default axis limits
  plot_incr_both <- make_psa_obj(cost  = as.data.frame(l_df_output_incr[[n]][, c("iCosts", "iCosts")]), 
                                 effectiveness = as.data.frame(l_df_output_incr[[n]][, c("iLY", "iQALY")]), 
                                 parameters    = l_m_Parameters[[n]], 
                                 strategies    = c("LY", "QALY"))
  
  plot_default <- plot(plot_incr_both) + 
    labs(title = paste("Incremental Cost-Effectiveness plane"),
         subtitle =   paste(n, ": intervention vs control", sep = " ")) +
    xlab("Incremental Effectiveness") +
    ylab("Incremental Costs (USD)") +
    geom_vline(xintercept = 0, color = my_darkgray, size = 0.6) +
    geom_hline(yintercept = 0, color = my_darkgray, size = 0.6) +
    scale_color_manual(values = c(my_darkgray, my_yellow,  my_black)) +  
    scale_fill_manual(values  = c(my_darkgray, my_yellow,  my_black)) + 
    theme(legend.title = element_blank())+
    guides(colour = guide_legend(override.aes = list(size = 4))) +     
    theme(legend.text = element_text(size = 15), legend.title = element_blank())
  
  # Add the default plot to the list
  l_grid_plots_CE_plane_incr_combined[[n]] <- plot_default
  
  # Create the plot with adjusted axis limits
  plot_adjusted <- plot_default + 
    coord_cartesian(xlim = xlim, ylim = ylim)
  
  # Add the adjusted plot to the list
  l_grid_plots_CE_plane_incr_combined_xylim[[n]] <- plot_adjusted
  
}

## Create grid plot with no xlim
# Create the grid plot 
grid.arrange(grobs = l_grid_plots_CE_plane_incr_combined, ncol = n_cols_grid, nrow = n_rows_grid)

# Create a final grid plot of all plots
all_grid_plots_CE_plane_incr_combined <- do.call(grid.arrange, c(l_grid_plots_CE_plane_incr_combined, ncol = n_cols_grid))
ggsave("../figures/all_grid_plots_CE_plane_incr_combined.png", all_grid_plots_CE_plane_incr_combined, width = 30, height = 30, units = "in")

## Create grid plot with  xlim
# Create the grid plot 
grid.arrange(grobs = l_grid_plots_CE_plane_incr_combined_xylim, ncol = n_cols_grid, nrow = n_rows_grid)

# Create a final grid plot of all plots
all_grid_plots_CE_plane_incr_combined_xylim <- do.call(grid.arrange, c(l_grid_plots_CE_plane_incr_combined_xylim, ncol = n_cols_grid))
ggsave("../figures/all_grid_plots_CE_plane_incr_combined_xylim.png", all_grid_plots_CE_plane_incr_combined_xylim, width = 30, height = 30, units = "in")


# Create the grid plot 
grid.arrange(grobs = l_grid_plots_CE_plane_incr_combined, ncol = n_cols_grid, nrow = n_rows_grid)

# Create a final grid plot of all plots
all_grid_plots_CE_plane_incr_combined <- do.call(grid.arrange, c(l_grid_plots_CE_plane_incr_combined, ncol = n_cols_grid))
all_grid_plots_CE_plane_incr_combined
ggsave("../figures/all_grid_plots_CE_plane_incr_combined.png", all_grid_plots_CE_plane_incr_combined, width = 30, height = 30, units = "in")

## Create grid plot with  xlim
# Create the grid plot 
grid.arrange(grobs = l_grid_plots_CE_plane_incr_combined_xylim, ncol = 4, nrow = ceiling(22/4))

# Create a final grid plot of all plots
all_grid_plots_CE_plane_incr_combined_xylim <- do.call(grid.arrange, c(l_grid_plots_CE_plane_incr_combined_xylim, ncol = n_cols_grid))
all_grid_plots_CE_plane_incr_combined_xylim
ggsave("../figures/all_grid_plots_CE_plane_incr_combined_xylim.png", all_grid_plots_CE_plane_incr_combined_xylim, width = 30, height = 30, units = "in")
```

```{r, echo = FALSE, out.width="30%", }
# These functions produce a character vector of the names of files or directories in the named directory. With a pattern similar to what you specify in pattern
myimages <- list.files("../figures/", pattern = "CE-plane_incr_QALY", full.names = FALSE)


```

## 9.6 VOI
### 9.6.1 VOI Retrospective
```{r}
### 2020/08/31 ###
# VOI analysis
# Based on:
# Jalal H, Alarid-Escudero F. A Gaussian Approximation Approach for Value of Information Analysis. Med. Decis. Making. 2017:116

# make a list with the population size

l_pop_resp <- l_pop_trial_resp <-  l_pop_all_resp <- list()

for (n in names(l_param_trt)){
 if(l_param_trt[[n]]$p_IC == 1){
   # if this drug is only given to IC patients, we should only consider the IC patients in the calculation of patients that can benefit. We therefore, multiply the total population with the probability of being admitted to the IC
   
    pop       <- l_param_trt[[n]]$n_H_year * l_param_trt[[n]]$p_IC_notrt
    pop_trial <- l_param_trt[[n]]$n_H_trial * l_param_trt[[n]]$p_IC_notrt
   # In this case the population is slightly different as this drug is only given the IC patients
    l_pop_resp[[n]] <- pop  # The total population in a year 
    l_pop_trial_resp[[n]] <- pop_trial
    
    l_pop_all_resp[[n]]$n_patients_current <- pop_trial
    l_pop_all_resp[[n]]$n_patients_future  <- pop
    } else{
 pop       <- l_param_trt[[n]]$n_H_year 
 pop_trial <- l_param_trt[[n]]$n_H_trial 
 
 l_pop_resp[[n]] <- pop # The total population in a year  
 l_pop_trial_resp[[n]] <- pop_trial
     l_pop_all_resp[[n]]$n_patients_current <- pop_trial
    l_pop_all_resp[[n]]$n_patients_future  <- pop
}
}

save(l_pop_resp, file = "../output/l_pop.rda")

```

### 9.6.1 VOI Prospective
```{r}
### 2020/08/31 ###
# VOI analysis
# Based on:
# Jalal H, Alarid-Escudero F. A Gaussian Approximation Approach for Value of Information Analysis. Med. Decis. Making. 2017:116

# make a list with the population size

l_pop_prosp <- l_pop_trial_prosp <-  l_pop_all_prosp <- list()

for (n in names(l_param_trt)){
 if(l_param_trt[[n]]$p_IC == 1){
   # if this drug is only given to IC patients, we should only consider the IC patients in the calculation of patients that can benefit. We therefore, multiply the total population with the probability of being admitted to the IC
   
    pop_prosp       <- l_param_trt[[n]]$n_H_year_prosp * l_param_trt[[n]]$p_IC_notrt
    pop_trial_prosp <- l_param_trt[[n]]$n_H_trial_prosp * l_param_trt[[n]]$p_IC_notrt
   # In this case the population is slightly different as this drug is only given the IC patients
    l_pop_prosp[[n]] <- pop_prosp  # The total population in a year 
    l_pop_trial_prosp[[n]] <- pop_trial_prosp
    
    l_pop_all_prosp[[n]]$n_patients_current <- pop_trial_prosp
    l_pop_all_prosp[[n]]$n_patients_future  <- pop_prosp
    } else{
 pop_prosp       <- l_param_trt[[n]]$n_H_year_prosp
 pop_trial_prosp <- l_param_trt[[n]]$n_H_trial_prosp 
 
 l_pop_prosp[[n]] <- pop_prosp # The total population in a year  
 l_pop_trial_prosp[[n]] <- pop_trial_prosp
     l_pop_all_prosp[[n]]$n_patients_current <- pop_trial_prosp
    l_pop_all_prosp[[n]]$n_patients_future  <- pop_prosp
}
}

save(l_pop_prosp, file = "../output/l_pop_prosp.rda")
```


### 9.6.1 Specify costs and effects
```{r}
l_res <- list()
for (n in v_names_trt){
  m_output <- l_m_output[[n]]
  ly_s1     <- as.vector(m_output[, "LY notrt"]) # Select the LY for the first strategy
  ly_s2     <- as.vector(m_output[, "LY trt"]) # Select the LY for the first strategy

  qaly_s1   <- as.vector(m_output[, "QALY notrt"]) # Select the QALYs for the first   strategy
  qaly_s2   <- as.vector(m_output[, "QALY trt"]) # Select the QALYs for the first   strategy

  cost_s1   <- as.vector(m_output[, "Costs notrt"])
  cost_s2   <- as.vector(m_output[, "Costs trt"])

# results of the analysis 
  res_ly   <- data.frame(as.vector(m_output[, "LY notrt"]), 
                         as.vector(m_output[, "LY trt"]))
  colnames(res_ly) <- c("LY notrt", "LY trt")
  l_res[[n]]$res_ly <- res_ly

  res_qaly <- data.frame(as.vector(m_output[, "QALY notrt"]), 
                         as.vector(m_output[, "QALY trt"]))
  colnames(res_qaly) <- c("QALY notrt", "QALY trt")
  l_res[[n]]$res_qaly<- res_qaly

  res_cost <- data.frame(as.vector(m_output[, "Costs notrt"]), 
                         as.vector(m_output[, "Costs trt"]))
  colnames(res_cost) <- c("Costs notrt", "Costs trt")
  l_res[[n]]$res_cost<- res_cost
}

```

### 9.6.2 CEACs and CEAF
```{r}
## CEACs and CEAF and EVPI

v_wtp <- seq(0, 200000, by = 10000)

l_out_ceaf_LY <- l_out_ceaf_QALY <- list() #initiate lists

for (n in v_names_trt){
  
# Cost effectiveness acceptability curve for Life Years
l_out_ceaf_LY[[n]] <- ceaf_changed(v.wtp      = v_wtp, 
                                   strategies = v_names_str, 
                                   m.e        = l_res[[n]]$res_ly, 
                                   m.c        = l_res[[n]]$res_cost, 
                                   effectunit = "LY",  
                                   ceaf.out   = TRUE )
# ggsave(path = here("../figures"), filename = paste("CEAF_LY", "_", remove_date_from_name(n), ".png", sep = ""))

# Cost effectiveness acceptability curve for QALY
l_out_ceaf_QALY[[n]] <- ceaf_changed(v.wtp      = v_wtp, 
                                     strategies = v_names_str, 
                                     m.e        = l_res[[n]]$res_qaly, 
                                     m.c        = l_res[[n]]$res_cost, 
                                     effectunit = "QALY", 
                                     ceaf.out   = TRUE) 

# ggsave(path = here("../figures"), filename = paste("CEAF_QALY", "_", remove_date_from_name(n), ".png", sep = ""))

#ggarrange(l_out_ceaf_LY[[n]]$gg.ceaf, l_out_ceaf_QALY[[n]]$gg.ceaf, 
#          ncol = 1, nrow = 2,
#          legend = "bottom",
#          common.legend = TRUE)

# ggsave(path = here("../figures"), filename = paste("CEAF_combined", "_", remove_date_from_name(n), ".png", sep = ""))


}


#save the output 
# This can be used in the markdown to make the figures
save(l_out_ceaf_LY, file = "../output/l_out_ceaf_LY.RData")
save(l_out_ceaf_QALY, file = "../output/l_out_ceaf_QALY.RData" )


# For LY
# Create a list of plots for each name in the list
plot_list <- lapply(l_out_ceaf_LY, function(x) x$gg.ceaf)

# Use ggarrange to arrange the plots in a grid
grid_plot <- ggarrange(plotlist = plot_list, ncol = n_cols_grid, nrow = n_rows_grid)
grid_plot
ggsave("../figures/CEAF_LY_grid.png", grid_plot, width = 30, height = 30, units = "in")

# For QALY
# Create a list of plots for each name in the list
plot_list <- lapply(l_out_ceaf_QALY, function(x) x$gg.ceaf)

# Use ggarrange to arrange the plots in a grid
grid_plot <- ggarrange(plotlist = plot_list, ncol = n_cols_grid, nrow = n_rows_grid)
ggsave("../figures/CEAF_QALY_grid.png", grid_plot, width = 30, height = 30, units = "in")


```

### 9.6.3.1 Calculate EVPI
#### 9.6.3.1 Calculate EVPI per person and population EVPI Retrospective and Prospective
```{r}
l_pop_pp <- lapply(l_pop_resp, function(x) 1) # Create per person population list = population of 1

run_evpi <- function(perspective) {
  
  # Initialize output lists
  l_out_evpi <- l_out_evpi_LY <- l_out_evpi_QALY <- l_evpi_value <- list()
  
  # Determine population and output lists based on perspective
  if (perspective == "prosp") {
    l_pop <- l_pop_prosp
    suffix <- "_prosp"
  } else if (perspective == "resp") {
    l_pop <- l_pop_resp
    suffix <- "_resp"
  } else if (perspective == "per_person") {
    l_pop <- l_pop_pp
    suffix <- "_pp"
  } else {
    stop("Invalid perspective specified")
  }
  
  # Loop through treatment parameter lists
  for (n in names(l_param_trt)) {
    
    # Calculate EVPI for LY
    l_out_evpi_LY[[n]] <- l_out_evpi[[n]] <- evpi(v.wtp = v_wtp,
                                                  m.e   = l_m_output[[n]][, c("LY notrt", "LY trt")], 
                                                  m.c   = l_m_output[[n]][, c("Costs notrt", "Costs trt")], 
                                                  pop   = l_pop[[n]])
    
    # Calculate EVPI for QALY
    l_out_evpi_QALY[[n]] <- evpi(v.wtp = v_wtp,
                                m.e   = l_m_output[[n]][, c("QALY notrt", "QALY trt")], 
                                m.c   = l_m_output[[n]][, c("Costs notrt", "Costs trt")], 
                                pop   = l_pop[[n]])
    
    # Store EVPI values in output list
    l_evpi_value[[n]] <- cbind(WTP       = l_out_evpi[[n]]$WTP, 
                               EVPI_LY   = l_out_evpi_LY[[n]]$EVPI, 
                               EVPI_QALY = l_out_evpi_QALY[[n]]$EVPI) 
  }
  
  # Save output lists
  save(l_out_evpi, l_out_evpi_LY, l_out_evpi_QALY, l_evpi_value, file = paste0("../output/l_evpi_value", suffix, ".rda"))
  
  # Save other output lists
  save(l_res,        file = "../output/l_res.rda")
  save(l_param_trt,  file = "../output/l_param_trt.rda")
  
  # Assign created lists to global environment variables
  assign(paste0("l_out_evpi", suffix), l_out_evpi, envir = .GlobalEnv)
  assign(paste0("l_out_evpi_LY", suffix), l_out_evpi_LY, envir = .GlobalEnv)
  assign(paste0("l_out_evpi_QALY", suffix), l_out_evpi_QALY, envir = .GlobalEnv)
  assign(paste0("l_evpi_value", suffix), l_evpi_value, envir = .GlobalEnv)
}

run_evpi(perspective = "resp")
run_evpi(perspective = "prosp")
run_evpi(perspective = "per_person")


```





### 9.6.3.1.1 Plot EVPI
```{r}
plot_evpi <- function(perspective) {
  if (perspective == "prosp") {
    suffix <- "_prosp"
  } else if (perspective == "resp") {
    suffix <- "_resp"
  } else if (perspective == "per_person") {
    suffix <- "_pp"
  } else {
    stop("Invalid perspective specified")
  }
  
  # Load the required l_evpi_value list based on the specified perspective
  load(paste0("../output/l_evpi_value", suffix, ".rda"))

  # Set xy limits; find maximum EVPI_LY value in all objects; LY will always be higher than QALY
  max_EVPI_LY <- max(sapply(l_evpi_value, function(x) max(x[, "EVPI_LY"])))
  xlim <- c(0, max(v_wtp))
  ylim <- c(0, max_EVPI_LY)
  
  # Create empty lists to store plots
  plot_list_QALY <- list()
  plot_list_LY <- list()

  plot_list_QALY_xylim <- list()
  plot_list_LY_xylim  <- list()

  l_evpi_obj_QALY <- list()
  l_evpi_obj_LY <- list()

for(n in names(l_param_trt)){
  ### QALY
  evpi_obj <- l_evpi_value[[n]][, c(1, 3)]
  evpi_obj <- as.data.frame(evpi_obj)
  
  l_evpi_obj_QALY[[n]] <- evpi_obj
  
  # Create the plot using ggplot2
  p <- ggplot(data = evpi_obj,aes(x=WTP,y=EVPI_QALY)) +
    geom_line() +
    labs(x = "Sample size",
         y = "EVPI (QALY)",
         title = paste("EVPI (QALY) for", n)) +
    theme_bw()
  
  p_xylim <- ggplot(data = evpi_obj,aes(x=WTP,y=EVPI_QALY)) +
    geom_line() +
    labs(x = "Sample size",
         y = "EVPI (QALY)",
         title = paste("EVPI (QALY) for", n)) +
    theme_bw()+ xlim(xlim) + ylim(ylim)
  
  # Add plot to plot_list_QALY
  plot_list_QALY[[n]] <- p
  plot_list_QALY_xylim[[n]] <- p_xylim

  ### LY    
  evpi_obj <- l_evpi_value[[n]][, c(1, 2)]
  evpi_obj <- as.data.frame(evpi_obj)
  
  l_evpi_obj_LY[[n]] <- evpi_obj
  
  # Create the plot using ggplot2
  p <- ggplot(data = evpi_obj, aes(x=WTP,y=EVPI_LY)) +
    geom_line() +
    labs(x = "Sample size",
         y = "EVPI (LY)",
         title = paste("EVPI (LY) for", n)) +
    theme_bw()
  
  p_xylim <- ggplot(data = evpi_obj, aes(x=WTP,y=EVPI_LY)) +
    geom_line() +
    labs(x = "Sample size",
         y = "EVPI (LY)",
         title = paste("EVPI (LY) for", n)) +
    theme_bw()+
    xlim(xlim) +
    ylim(ylim)
  
  # Add plot to plot_list_LY
  plot_list_LY[[n]] <- p
  plot_list_LY_xylim[[n]] <- p_xylim
}

  # Use ggpubr to arrange plots in a grid
  grid_plot_QALY <- ggarrange(plotlist = plot_list_QALY, ncol = n_cols_grid, nrow = n_rows_grid) + labs(title = paste0("EVPI - QALY - ", perspective)) + theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))
  ggsave(filename = paste0("../figures/EVPI_QALY_grid", suffix, ".png"), plot = grid_plot_QALY, width = 16,height = 24, units = "in")

  grid_plot_QALY_xylim <- ggarrange(plotlist = plot_list_QALY_xylim, ncol = n_cols_grid, nrow = n_rows_grid) + labs(title = paste0("EVPI - QALY - ", perspective)) + theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))
  ggsave(filename = paste0("../figures/EVPI_QALY_grid_xylim", suffix, ".png"), plot = grid_plot_QALY_xylim, width = 16,height = 24, units = "in")

  grid_plot_LY <- ggarrange(plotlist = plot_list_LY, ncol = n_cols_grid, nrow = n_rows_grid) + labs(title = paste0("EVPI - LY - ", perspective)) + theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))
  ggsave(filename = paste0("../figures/EVPI_LY_grid", suffix, ".png"), plot = grid_plot_LY, width = 16,height = 24, units = "in")

  grid_plot_LY_xylim <- ggarrange(plotlist = plot_list_LY_xylim, ncol = n_cols_grid, nrow = n_rows_grid) + labs(title = paste0("EVPI - LY - ", perspective)) + theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))
  ggsave(filename = paste0("../figures/EVPI_LY_grid_xylim", suffix, ".png"), plot = grid_plot_LY_xylim, width = 16,height = 24, units = "in")
}

plot_evpi(perspective = "prosp")
plot_evpi(perspective = "resp")
plot_evpi(perspective = "per_person")
```


### 9.6.3.2 Calculate EVPPI
```{r, messasge = FALSE}
run_evppi <- function(perspective) {
  # Determine population and output lists based on perspective
  if (perspective == "prosp") {
    l_pop <- l_pop_prosp
    suffix <- "_prosp"
  } else if (perspective == "resp") {
    l_pop <- l_pop_resp
    suffix <- "_resp"
  } else if (perspective == "per_person") {
    l_pop <- l_pop_pp
    suffix <- "_pp"
  } else {
    stop("Invalid perspective specified")
  }
  
  # Initialize output lists
  l_df_evppi <- l_df_evppi_pop <- l_df_param_nmb_LY <- l_df_param_nmb_QALY  <- l_m_param <- list()
  v_evppi_LY <-  v_evppi_QALY <- length(v_wtp)
  
  
  for (n in names(l_param_trt)){
         l_df_evppi[[n]]     <- as.data.frame(array(0, dim = c(length(v_wtp), 2)))
colnames(l_df_evppi[[n]])    <- c("WTP", "EVPPI")
         l_df_evppi[[n]]$WTP <- v_wtp

  m_Parameters <- l_m_Parameters[[n]]

# Code to select parameters of interest for EVPPI
  v_names_param <- names(m_Parameters)
  
  v_trt_type_name <- c("rr_D_Trt_timespan1", 
                       "rd_D_Trt_timespan1", 
                       "or_D_Trt_timespan1", 
                       "hr_D_Trt_timespan1")
  v_trt_type <- c("RR",
                  "RD",
                  "OR",
                  "HR")
  # Make a dateframe
  m_trt_type <- as.data.frame(cbind(v_trt_type_name, v_trt_type))
  # select the full name of the treatment type
  name <- v_names_param[ which(v_names_param %in% v_trt_type_name)]
  # match it with the corresponding treatment type
  trt_effect <- m_trt_type$v_trt_type[m_trt_type$v_trt_type_name == name] #
  
    vent <- FALSE  # make a variable that by default is FALSE
  if(trt_effect == "RR" & !is.null(m_Parameters$rr_D_Trt_timespan1_vent)){
    vent <- TRUE # if  we have information about ventilation, overwrite
  }
  if(trt_effect == "RD" & !is.null(m_Parameters$rd_D_Trt_timespan1_vent)){
    vent <- TRUE
  }
  if(trt_effect == "OR" & !is.null(m_Parameters$or_D_Trt_timespan1_vent)){
    vent <- TRUE
  }
  if(trt_effect == "HR" & !is.null(m_Parameters$hr_D_Trt_timespan1_vent)){
    vent <- TRUE
  }
      if(vent == FALSE){
      if (trt_effect == "RR"){
          l_m_param[[n]] <- m_param <- m_Parameters[, c("rr_D_Trt_timespan1")] 
      }
        if (trt_effect == "RD"){
          l_m_param[[n]] <- m_param <- m_Parameters[, c("rd_D_Trt_timespan1")] 
        }
           if (trt_effect == "OR"){
          l_m_param[[n]] <- m_param <- m_Parameters[, c("or_D_Trt_timespan1")] 
           }
         if (trt_effect == "HR"){
          l_m_param[[n]] <- m_param <- m_Parameters[, c("hr_D_Trt_timespan1")] 
      }
    } else if (vent == TRUE){
            if (trt_effect == "RR"){
          l_m_param[[n]] <- m_param <- m_Parameters[, c("rr_D_Trt_timespan1_vent",
                                                        "rr_D_Trt_timespan1_novent")] 
      }
        if (trt_effect == "RD"){
          l_m_param[[n]] <- m_param <- m_Parameters[, c("rd_D_Trt_timespan1_vent",
                                                        "rd_D_Trt_timespan1_novent")] 
        }
           if (trt_effect == "OR"){
          l_m_param[[n]] <- m_param <- m_Parameters[, c("or_D_Trt_timespan1_vent",
                                                        "or_D_Trt_timespan1_novent")] 
           }
         if (trt_effect == "HR"){
          l_m_param[[n]] <- m_param <- m_Parameters[, c("hr_D_Trt_timespan1_vent",
                                                        "hr_D_Trt_timespan1_novent")] 
      }
    }

  }# close the loop for treatment

for (n in names(l_param_trt)){
# Function - run the function to calculate EVVPI for different v_wtp
for(i in 1:length(v_wtp)){  
  
  ## Create a new data frame for the chosen WTP ##
  WTP <- v_wtp[i]
  m_nmb_LY <- NMB_function(wtp    = WTP,
                        effect = l_res[[n]]$res_ly, 
                        costs  = l_res[[n]]$res_cost) #for NMB
  #m.nmb <- NMB_function2(wtp=WTP,effect=res.ly, costs=res.cost) #for NHB (here WTP cannot be 0)
  l_df_param_nmb_LY[[n]] <- data.frame(l_m_param[[n]], m_nmb_LY)  # columns are m_param, nmbs_s1 and nmb_s2 
  
  
    m_nmb_QALY <- NMB_function(wtp    = WTP,
                               effect = l_res[[n]]$res_qaly, 
                               costs  = l_res[[n]]$res_cost) #for NMB
  #m.nmb <- NMB_function2(wtp=WTP,effect=res.ly, costs=res.cost) #for NHB (here WTP cannot be 0)
  l_df_param_nmb_QALY[[n]] <- data.frame(l_m_param[[n]], m_nmb_QALY)  # columns are m_param, nmbs_s1 and nmb_s2 
  
  #Specify strategies 
  nmb_LY   <- data.frame(m_nmb_LY)
  nmb_QALY <- data.frame(m_nmb_QALY)
  
   # Specify parameters 
  theta <- data.frame(m_param)
  
   # sel.params = is indicating the number of parameters 1:1
  n_params_EVPPI <- ncol(theta)
  
 #Calculate population EVPPI
    v_evppi_LY[i] <- evppi_lrmm_pop(nmb = nmb_LY, 
                                      params = as.matrix(theta),  
                                      sel.params = (1 : n_params_EVPPI), 
                                      verbose = TRUE, 
                                      sel.gam = T, 
                                      pop = l_pop[[n]]) 
  
    v_evppi_QALY[i] <- evppi_lrmm_pop(nmb = nmb_QALY, 
                                      params = as.matrix(theta),  
                                      sel.params = (1 : n_params_EVPPI), 
                                      verbose = TRUE, 
                                      sel.gam = T, 
                                      pop = l_pop[[n]]) 

}
  l_df_evppi_pop[[n]] <- cbind(WTP = v_wtp,      # store the willingness to pay values
                                LY = v_evppi_LY,  # store evppi LY
                             QALY = v_evppi_QALY) # store the population evppi
}

    # Save the results
  save(l_df_evppi_pop, file = paste0("../output/l_df_evppi_pop", suffix, ".rda"))

  # Assign created lists to global variables
  assign(paste0("l_df_evppi_pop", suffix), l_df_evppi_pop, envir = .GlobalEnv)
}

# Run EVPPI for all perspectives
run_evppi(perspective = "resp")
run_evppi(perspective = "prosp")
run_evppi(perspective = "per_person")

# Check accurate output
#l_df_evppi_pop_pp$`k01_COVACTA_2020-09-12`
#l_df_evppi_pop_prosp$`k01_COVACTA_2020-09-12`

```

### 9.6.3.2.1 Plot EVPPI
```{r}
max_EVPPI_LY <- max(sapply(l_df_evppi_pop_resp, function(x) max(x[, "LY"]))) # Set XY Lim as the highest LY value for retrospective analysis, as this is the highest value for all objects

run_evppi_plots <- function(perspective) {
  
  # Determine the suffix based on perspective
  if (perspective == "prosp") {
    suffix <- "_prosp"
  } else if (perspective == "resp") {
    suffix <- "_resp"
  } else if (perspective == "per_person") {
    suffix <- "_pp"
  } else {
    stop("Invalid perspective specified")
  }
  
  # Load the appropriate data based on perspective
  load(paste0("../output/l_evpi_value", suffix, ".rda"))
  load(paste0("../output/l_df_evppi_pop", suffix, ".rda"))
  
  # Set xy limits; 
  xlim <- c(0, max(v_wtp))
  ylim <- c(0, max_EVPPI_LY)
  
  # Create empty lists to store plots
  plot_list_QALY <- list()
  plot_list_LY <- list()
  
  plot_list_QALY_xylim <- list()
  plot_list_LY_xylim  <- list()
  
  l_evppi_obj_QALY <- list()
  l_evppi_obj_LY <- list()
  
  for(n in names(l_param_trt)){
    ### QALY
    evppi_obj <- l_df_evppi_pop[[n]][, c(1, 3)]
    evppi_obj <- as.data.frame(evppi_obj)
    
    l_evppi_obj_QALY[[n]] <- evppi_obj
    
    # Create the plot using ggplot2
    p <- ggplot(data = evppi_obj,aes(x=WTP,y=QALY)) +
      geom_line() +
      labs(x = "Sample size",
           y = "EVPPI (QALY)",
           title = paste("EVPPI (QALY) for", n)) +
      theme_bw()
    
    p_xylim <- ggplot(data = evppi_obj,aes(x=WTP,y=QALY)) +
      geom_line() +
      labs(x = "Sample size",
           y = "EVPPI (QALY)",
           title = paste("EVPPI (QALY) for", n)) +
      theme_bw()+ xlim(xlim) + ylim(ylim)
    
    # Add plot to plot_list_QALY
    plot_list_QALY[[n]] <- p
    plot_list_QALY_xylim[[n]] <- p_xylim
    
    ### LY    
    evppi_obj <- l_df_evppi_pop[[n]][, c(1, 2)]
    evppi_obj <- as.data.frame(evppi_obj)
    
    l_evppi_obj_LY[[n]] <- evppi_obj
    
    # Create the plot using ggplot2
    p <- ggplot(data = evppi_obj, aes(x=WTP,y=LY)) +
      geom_line() +
      labs(x = "Sample size",
           y = "EVPPI (LY)",
           title = paste("EVPPI (LY) for", n)) +
      theme_bw()
    
  p_xylim <- ggplot(data = evppi_obj, aes(x=WTP,y=LY)) +
    geom_line() +
    labs(x = "Sample size",
         y = "EVPPI (LY)",
         title = paste("EVPPI (LY) for", n)) +
    theme_bw()+
    xlim(xlim) +
    ylim(ylim)
  
  # Add plot to plot_list_LY
  plot_list_LY[[n]] <- p
  plot_list_LY_xylim[[n]] <- p_xylim
  }
  
    # Use ggpubr to arrange plots in a grid
  grid_plot_QALY <- ggarrange(plotlist = plot_list_QALY, ncol = n_cols_grid, nrow = n_rows_grid) + labs(title = paste0("EVPPI - QALY - ", perspective)) + theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))
  ggsave(filename = paste0("../figures/EVPPI_QALY_grid", suffix, ".png"), plot = grid_plot_QALY, width = 16,height = 24, units = "in")

  grid_plot_QALY_xylim <- ggarrange(plotlist = plot_list_QALY_xylim, ncol = n_cols_grid, nrow = n_rows_grid) + labs(title = paste0("EVPPI - QALY - ", perspective)) + theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))
  ggsave(filename = paste0("../figures/EVPPI_QALY_grid_xylim", suffix, ".png"), plot = grid_plot_QALY_xylim, width = 16,height = 24, units = "in")

  grid_plot_LY <- ggarrange(plotlist = plot_list_LY, ncol = n_cols_grid, nrow = n_rows_grid) + labs(title = paste0("EVPPI - LY - ", perspective)) + theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))
  ggsave(filename = paste0("../figures/EVPPI_LY_grid", suffix, ".png"), plot = grid_plot_LY, width = 16,height = 24, units = "in")

  grid_plot_LY_xylim <- ggarrange(plotlist = plot_list_LY_xylim, ncol = n_cols_grid, nrow = n_rows_grid) + labs(title = paste0("EVPPI - LY - ", perspective)) + theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))
  ggsave(filename = paste0("../figures/EVPPI_LY_grid_xylim", suffix, ".png"), plot = grid_plot_LY_xylim, width = 16,height = 24, units = "in")
}
  
run_evppi_plots(perspective = "resp")
run_evppi_plots(perspective = "prosp")
run_evppi_plots(perspective = "per_person")
```

### 9.6.3.2.2 Table EVPPI 

```{r}
# Function to generate and save EVPPI tables and plots
generate_evppi_summary <- function(perspective) {
  if (perspective == "prosp") {
    suffix <- "_prosp"
    l_df_evppi_pop <- l_df_evppi_pop_prosp
  } else if (perspective == "resp") {
    suffix <- "_resp"
    l_df_evppi_pop <- l_df_evppi_pop_resp
  } else if (perspective == "per_person") {
    suffix <- "_pp"
    l_df_evppi_pop <- l_df_evppi_pop_pp
  } else {
    stop("Invalid perspective specified")
  }
  
  m_summary_pop_EVPPI_LY <- m_summary_pop_EVPPI_QALY <- matrix(data = NA, 
                                                              nrow = length(v_wtp), 
                                                              ncol = length(names(l_param_trt)),
                                                              dimnames = list(v_wtp, names(l_param_trt)))

  for (n in v_names_trt) {
    m_summary_pop_EVPPI_LY[, n] <- round(l_df_evppi_pop[[n]][, "LY"])
    m_summary_pop_EVPPI_QALY[, n] <- round(l_df_evppi_pop[[n]][, "QALY"])
  }

  df_summary_pop_EVPPI_LY <- as.data.frame(m_summary_pop_EVPPI_LY)
  df_summary_pop_EVPPI_QALY <- as.data.frame(m_summary_pop_EVPPI_QALY)

 # Save tables in the global environment
  assign(paste0("df_summary_pop_EVPPI_LY", suffix), df_summary_pop_EVPPI_LY, envir = .GlobalEnv)
  assign(paste0("df_summary_pop_EVPPI_QALY", suffix), df_summary_pop_EVPPI_QALY, envir = .GlobalEnv)

  # Save tables in the output folder
  save(df_summary_pop_EVPPI_LY, file = paste0("../output/df_summary_pop_EVPPI_LY", suffix, ".rda"))
  save(df_summary_pop_EVPPI_QALY, file = paste0("../output/df_summary_pop_EVPPI_QALY", suffix, ".rda"))


  ### LY ####
  
  ### Report version ## LIFE YEARS
  df_summary_pop_EVPPI_million <- round(df_summary_pop_EVPPI_LY / 1e6, 0)
  df_summary_pop_EVPPI_million_plot <- df_summary_pop_EVPPI_million[, v_names_trt_report_full]
  colnames(df_summary_pop_EVPPI_million_plot) <- remove_date_from_name(colnames(df_summary_pop_EVPPI_million_plot))

  png(paste0("../figures/table_summary_pop_EVPPI_LY_million", suffix, ".png"), width = 3000, height = 600, bg = "white", pointsize = 30)
  grid.table(df_summary_pop_EVPPI_million_plot)
  dev.off()

  ### QALY ####
  
  ### Report version ## QALY
  df_summary_pop_EVPPI_million <- round(df_summary_pop_EVPPI_QALY / 1e6, 0)

  df_summary_pop_EVPPI_million_plot <- df_summary_pop_EVPPI_million[, v_names_trt_report_full]
  colnames(df_summary_pop_EVPPI_million_plot) <- remove_date_from_name(colnames(df_summary_pop_EVPPI_million_plot))

  png(paste0("../figures/table_summary_pop_EVPPI_QALY_million", suffix, ".png"), width = 3000, height = 600, bg = "white", pointsize = 30)
  grid.table(df_summary_pop_EVPPI_million_plot)
  dev.off()
}

generate_evppi_summary(perspective = "resp")
generate_evppi_summary(perspective = "prosp")
generate_evppi_summary(perspective = "per_person")
```



### 9.6.3.2.3.1 Summary table with PSA and EVPPI for QALY

```{r}
#load(file = "../output/l_df_cea_PSA_QALY.rda")
#load(file = "../output/l_df_PSA_QALY.rda")

run_summary_cea_qaly <- function(perspective) {
  if (perspective == "prosp") {
    l_pop <- l_pop_prosp
    l_pop_trial <- l_pop_trial_prosp
    suffix <- "_prosp"
    l_df_evppi_pop <- l_df_evppi_pop_prosp
  } else if (perspective == "resp") {
    l_pop <- l_pop_resp
    l_pop_trial <- l_pop_trial_resp
    suffix <- "_resp"
    l_df_evppi_pop <- l_df_evppi_pop_resp
  } else {
    stop("Invalid perspective specified")
  }

 
  options(scipen = 999)
  #df_summary_cea_QALY
  v_names_col_PSA   <- c(colnames(df_summary_cea_QALY), "EVPPI", "Future patients", "Current patients")

  m_summary_cea_QALY_PSA <- matrix(data = NA, 
                                 ncol = length(v_names_col_PSA), 
                                 nrow = length(names(l_param_trt)),
                                 dimnames = list(names(l_param_trt), v_names_col_PSA))

# NOTE:
# Yes*  = Trt is dominant
# No*   = Trt is dominated by noTrt
# Yes** = Trt is cost-saving ICER > WTP
# No**  = Trt is cost-saving, but not enough that ICER > WTP


for(n in names(l_param_trt)){
  
  df_summary_f    <- l_df_cea_PSA_QALY[[n]]  
  df_evppi_pop_f  <- l_df_evppi_pop[[n]][, "QALY"]  # select the wtp and QALY columns
  names(df_evppi_pop_f) <- l_df_evppi_pop[[n]][, "WTP"] 
  
  m_summary_cea_QALY_PSA[n, "EVPPI"]    <- df_evppi_pop_f[as.numeric(names(df_evppi_pop_f)) == (l_param_trt[[n]]$wtp)] # select EVPPI with for wtp
  m_summary_cea_QALY_PSA[n, "Incr NMB"] <- l_df_PSA_QALY[[n]]$iNMB[l_df_PSA_QALY[[n]]$Strategy == "trt"]
  m_summary_cea_QALY_PSA[n, "Incr NHB"] <- l_df_PSA_QALY[[n]]$iNHB[l_df_PSA_QALY[[n]]$Strategy == "trt"]
  
  m_summary_cea_QALY_PSA[n, "Future patients"]  <- l_pop[[n]]
  m_summary_cea_QALY_PSA[n, "Current patients"] <- l_pop_trial[[n]]
  
  # check if treatment is not dominated or dominant
  if(df_summary_f$Status[df_summary_f$Strategy == "trt"] == "D"){
    m_summary_cea_QALY_PSA[n, "Cost-effective"] <- "No*"
    m_summary_cea_QALY_PSA[n, "Incr effect Rx"] <- df_summary_f$Effect[df_summary_f$Strategy == "trt"] - df_summary_f$Effect[df_summary_f$Strategy == "notrt"]
    m_summary_cea_QALY_PSA[n, "Incr cost Rx"] <- df_summary_f$Cost[df_summary_f$Strategy   == "trt"] - df_summary_f$Cost[df_summary_f$Strategy   == "notrt"]
    
  } else if (df_summary_f$Status[df_summary_f$Strategy == "notrt"] == "D"){
    m_summary_cea_QALY_PSA[n, "Cost-effective"] <- "Yes*"
    m_summary_cea_QALY_PSA[n, "Incr effect Rx"] <- df_summary_f$Effect[df_summary_f$Strategy == "trt"] - df_summary_f$Effect[df_summary_f$Strategy == "notrt"]
    m_summary_cea_QALY_PSA[n, "Incr cost Rx"] <- df_summary_f$Cost[df_summary_f$Strategy   == "trt"] - df_summary_f$Cost[df_summary_f$Strategy   == "notrt"]
  } else if(!is.na(df_summary_f$ICER[df_summary_f$Strategy == "trt"]) & df_summary_f$ICER[df_summary_f$Strategy == "trt"] > l_param_trt[[n]]$wtp){
    m_summary_cea_QALY_PSA[n, "Cost-effective"] <- "No"
    m_summary_cea_QALY_PSA[n, "ICER"          ] <- df_summary_f$ICER[df_summary_f$Strategy == "trt"]
    m_summary_cea_QALY_PSA[n, "Incr effect Rx"] <- df_summary_f$Inc_Effect[df_summary_f$Strategy == "trt"] 
    m_summary_cea_QALY_PSA[n, "Incr cost Rx"] <- df_summary_f$Inc_Cost[df_summary_f$Strategy   == "trt"]
  } else if(!is.na(df_summary_f$ICER[df_summary_f$Strategy == "trt"]) & df_summary_f$ICER[df_summary_f$Strategy == "trt"] <= l_param_trt[[n]]$wtp){
    m_summary_cea_QALY_PSA[n, "Cost-effective"] <- "Yes"
    m_summary_cea_QALY_PSA[n, "ICER"       ] <- df_summary_f$ICER[df_summary_f$Strategy       == "trt"]
    m_summary_cea_QALY_PSA[n, "Incr effect Rx"] <- df_summary_f$Inc_Effect[df_summary_f$Strategy == "trt"]
    m_summary_cea_QALY_PSA[n, "Incr cost Rx"] <- df_summary_f$Inc_Cost[df_summary_f$Strategy   == "trt"]
  } else{
    m_summary_cea_QALY_PSA[n, "Cost-effective"] <- "Trt both lower costs & effects"
    m_summary_cea_QALY_PSA[n, "Incr effect Rx"] <- -1 * df_summary_f$Inc_Effect[df_summary_f$Strategy == "notrt"]
    m_summary_cea_QALY_PSA[n, "Incr cost Rx"] <- -1 * df_summary_f$Inc_Cost[df_summary_f$Strategy   == "notrt"]
    m_summary_cea_QALY_PSA[n, "ICER"] <-  df_summary_f$ICER[df_summary_f$Strategy  == "notrt"]
    
    if (round(df_summary_f$ICER[df_summary_f$Strategy       == "notrt"]) > l_param_trt[[n]]$wtp) {
    m_summary_cea_QALY_PSA[n, "Cost-effective"] <- "Yes**"
    } else { m_summary_cea_QALY_PSA[n, "Cost-effective"] <- "No**"}
  }
  df_summary_cea_QALY_PSA <- as.data.frame(m_summary_cea_QALY_PSA)
  # make all columns that are numbers numeric 
  df_summary_cea_QALY_PSA[, -1] <- data.frame(lapply(df_summary_cea_QALY_PSA[, -1], as.numeric))

}

  # Save the df in the output folder
  save(df_summary_cea_QALY_PSA, file = paste0("../output/df_summary_cea_QALY_PSA", suffix, ".rda"))

  # Format the table
  df_summary_cea_QALY_PSA_plot <- format_table_summary(df_summary_cea_QALY_PSA, EVPPI = TRUE)
  
  # Save the table figures
  png(paste0("../figures/table_summary_cea_PSA_QALY", suffix, ".png"), width = 2000, height = 1500, bg = "white", pointsize = 22)
  grid.table(df_summary_cea_QALY_PSA_plot)
  dev.off()

  # Assign the created data frame to global variables
  assign(paste0("df_summary_cea_QALY_PSA", suffix), df_summary_cea_QALY_PSA, envir = .GlobalEnv)
}

run_summary_cea_qaly(perspective = "resp")
run_summary_cea_qaly(perspective = "prosp")

```


### 9.6.3.2.3.1 Summary table with PSA and EVPPI for LY
```{r}
#load(file = "../output/l_df_cea_PSA_LY.rda")
#load(file = "../output/l_df_PSA_LY.rda")

run_summary_cea_ly <- function(perspective) {
  if (perspective == "prosp") {
    l_pop <- l_pop_prosp
    l_pop_trial <- l_pop_trial_prosp
    suffix <- "_prosp"
    l_df_evppi_pop <- l_df_evppi_pop_prosp
  } else if (perspective == "resp") {
    l_pop <- l_pop_resp
    l_pop_trial <- l_pop_trial_resp
    suffix <- "_resp"
    l_df_evppi_pop <- l_df_evppi_pop_resp
  } else {
    stop("Invalid perspective specified")
  }

 
  options(scipen = 999)
  #df_summary_cea_LY
  v_names_col_PSA   <- c(colnames(df_summary_cea_LY), "EVPPI", "Future patients", "Current patients")

  m_summary_cea_LY_PSA <- matrix(data = NA, 
                                 ncol = length(v_names_col_PSA), 
                                 nrow = length(names(l_param_trt)),
                                 dimnames = list(names(l_param_trt), v_names_col_PSA))

# NOTE:
# Yes*  = Trt is dominant
# No*   = Trt is dominated by noTrt
# Yes** = Trt is cost-saving ICER > WTP
# No**  = Trt is cost-saving, but not enough that ICER > WTP


for(n in names(l_param_trt)){
  
  df_summary_f    <- l_df_cea_PSA_LY[[n]]  
  df_evppi_pop_f  <- l_df_evppi_pop[[n]][, "LY"]  # select the wtp and LY columns
  names(df_evppi_pop_f) <- l_df_evppi_pop[[n]][, "WTP"] 
  
  m_summary_cea_LY_PSA[n, "EVPPI"]    <- df_evppi_pop_f[as.numeric(names(df_evppi_pop_f)) == (l_param_trt[[n]]$wtp)] # select EVPPI with for wtp
  m_summary_cea_LY_PSA[n, "Incr NMB"] <- l_df_PSA_LY[[n]]$iNMB[l_df_PSA_LY[[n]]$Strategy == "trt"]
  m_summary_cea_LY_PSA[n, "Incr NHB"] <- l_df_PSA_LY[[n]]$iNHB[l_df_PSA_LY[[n]]$Strategy == "trt"]
  
  m_summary_cea_LY_PSA[n, "Future patients"]  <- l_pop[[n]]
  m_summary_cea_LY_PSA[n, "Current patients"] <- l_pop_trial[[n]]
  
  # check if treatment is not dominated or dominant
  if(df_summary_f$Status[df_summary_f$Strategy == "trt"] == "D"){
    m_summary_cea_LY_PSA[n, "Cost-effective"] <- "No*"
    m_summary_cea_LY_PSA[n, "Incr effect Rx"] <- df_summary_f$Effect[df_summary_f$Strategy == "trt"] - df_summary_f$Effect[df_summary_f$Strategy == "notrt"]
    m_summary_cea_LY_PSA[n, "Incr cost Rx"] <- df_summary_f$Cost[df_summary_f$Strategy   == "trt"] - df_summary_f$Cost[df_summary_f$Strategy   == "notrt"]
    
  } else if (df_summary_f$Status[df_summary_f$Strategy == "notrt"] == "D"){
    m_summary_cea_LY_PSA[n, "Cost-effective"] <- "Yes*"
    m_summary_cea_LY_PSA[n, "Incr effect Rx"] <- df_summary_f$Effect[df_summary_f$Strategy == "trt"] - df_summary_f$Effect[df_summary_f$Strategy == "notrt"]
    m_summary_cea_LY_PSA[n, "Incr cost Rx"] <- df_summary_f$Cost[df_summary_f$Strategy   == "trt"] - df_summary_f$Cost[df_summary_f$Strategy   == "notrt"]
  } else if(!is.na(df_summary_f$ICER[df_summary_f$Strategy == "trt"]) & df_summary_f$ICER[df_summary_f$Strategy == "trt"] > l_param_trt[[n]]$wtp){
    m_summary_cea_LY_PSA[n, "Cost-effective"] <- "No"
    m_summary_cea_LY_PSA[n, "ICER"          ] <- df_summary_f$ICER[df_summary_f$Strategy == "trt"]
    m_summary_cea_LY_PSA[n, "Incr effect Rx"] <- df_summary_f$Inc_Effect[df_summary_f$Strategy == "trt"] 
    m_summary_cea_LY_PSA[n, "Incr cost Rx"] <- df_summary_f$Inc_Cost[df_summary_f$Strategy   == "trt"]
  } else if(!is.na(df_summary_f$ICER[df_summary_f$Strategy == "trt"]) & df_summary_f$ICER[df_summary_f$Strategy == "trt"] <= l_param_trt[[n]]$wtp){
    m_summary_cea_LY_PSA[n, "Cost-effective"] <- "Yes"
    m_summary_cea_LY_PSA[n, "ICER"       ] <- df_summary_f$ICER[df_summary_f$Strategy       == "trt"]
    m_summary_cea_LY_PSA[n, "Incr effect Rx"] <- df_summary_f$Inc_Effect[df_summary_f$Strategy == "trt"]
    m_summary_cea_LY_PSA[n, "Incr cost Rx"] <- df_summary_f$Inc_Cost[df_summary_f$Strategy   == "trt"]
  } else{
    m_summary_cea_LY_PSA[n, "Cost-effective"] <- "Trt both lower costs & effects"
    m_summary_cea_LY_PSA[n, "Incr effect Rx"] <- -1 * df_summary_f$Inc_Effect[df_summary_f$Strategy == "notrt"]
    m_summary_cea_LY_PSA[n, "Incr cost Rx"] <- -1 * df_summary_f$Inc_Cost[df_summary_f$Strategy   == "notrt"]
    m_summary_cea_LY_PSA[n, "ICER"] <-  df_summary_f$ICER[df_summary_f$Strategy  == "notrt"]
    
    if (round(df_summary_f$ICER[df_summary_f$Strategy       == "notrt"]) > l_param_trt[[n]]$wtp) {
    m_summary_cea_LY_PSA[n, "Cost-effective"] <- "Yes**"
    } else { m_summary_cea_LY_PSA[n, "Cost-effective"] <- "No**"}
  }
  df_summary_cea_LY_PSA <- as.data.frame(m_summary_cea_LY_PSA)
  # make all columns that are numbers numeric 
  df_summary_cea_LY_PSA[, -1] <- data.frame(lapply(df_summary_cea_LY_PSA[, -1], as.numeric))

}

  # Save the df in the output folder
  save(df_summary_cea_LY_PSA, file = paste0("../output/df_summary_cea_LY_PSA", suffix, ".rda"))

  # Format the table
  df_summary_cea_LY_PSA_plot <- format_table_summary(df_summary_cea_LY_PSA, EVPPI = TRUE)
  
  # Save the table figures
  png(paste0("../figures/table_summary_cea_PSA_LY", suffix, ".png"), width = 2000, height = 1500, bg = "white", pointsize = 22)
  grid.table(df_summary_cea_LY_PSA_plot)
  dev.off()

  # Assign the created data frame to global variables
  assign(paste0("df_summary_cea_LY_PSA", suffix), df_summary_cea_LY_PSA, envir = .GlobalEnv)
}

run_summary_cea_ly(perspective = "resp")
run_summary_cea_ly(perspective = "prosp")

```

## 9.6.4.1 Calculate EVSI for QALY 
```{r, message = FALSE}
# EVSI for groups of parameters for one WTP threshold
options(scipen = 999)

## Assuming an RCT ##

##QALY###
df_summary_pop_EVPPI <- df_summary_pop_EVPPI_QALY_pp # Note: Only used for table structure, either _pp or _resp or _prosp can be used, this choice does not influence the numbers in the remainder of this chunk

# Select the strategies with EVPPI > 0 at the wtp threshold of use
rownames(df_summary_pop_EVPPI) <- as.numeric(rownames(df_summary_pop_EVPPI))

v_names_EVSI <- v_names_EVSI_QALY <- colnames(df_summary_pop_EVPPI)[which(df_summary_pop_EVPPI[rownames(df_summary_pop_EVPPI) == l_param_trt[[1]]$wtp, ] > 0)]

n_strategies <- n_str
l_m_nmb <- l_m_nmb2 <- l_evpsi_rct_r_one_QALY <- l_EVSI_retr_rct_QALY <- list()
l_theta <- list()

for (i in seq_along(v_names_EVSI)){
  n <- v_names_EVSI[i]
  trt_effect <- l_param_trt[[n]]$trt_effect
  vent       <- l_param_trt[[n]]$vent
 
  m_Parameters <- l_m_Parameters[[n]]
  
  l_m_nmb[[n]] <- NMB_function(wtp = l_param_trt[[n]]$wtp, 
                            effect = l_res[[n]]$res_qaly,   ##QALY###
                             costs =  l_res[[n]]$res_cost)
  
#m.nmb <- NMB_function2(wtp=WTP,effect=res.ly, costs=res.cost) #for NHB (here WTP cannot be 0)
   df_param_nmb <- data.frame(l_m_nmb[[n]])

   n_sim <- nrow(l_m_nmb[[n]])

#### Loss Matrix ####  
# Find optimal strategy (d*) based on the highest expected net value
m_nmb2 <- l_m_nmb[[n]][, c(1:2)]
d_star <- which.max(colMeans(m_nmb2))
d_star

## Compute Loss matrix iterating over all strategies
loss <- as.matrix(m_nmb2 - m_nmb2[, d_star])
head(loss)

# Specify parameters
  
    if(vent == FALSE){
      if (trt_effect == "RR"){
          theta <- data.frame(m_Parameters[, c("rr_D_Trt_timespan1")]) 
      }
        if (trt_effect == "RD"){
          theta <- data.frame(m_Parameters[, c("rd_D_Trt_timespan1")]) 
        }
           if (trt_effect == "OR"){
             theta <- data.frame(m_Parameters[, c("or_D_Trt_timespan1")]) 
           }
         if (trt_effect == "HR"){
           theta <- data.frame(m_Parameters[, c("hr_D_Trt_timespan1")]) 
      }
    } else if (vent == TRUE){
            if (trt_effect == "RR"){
              theta <- data.frame(m_Parameters[, c("rr_D_Trt_timespan1_vent",
                                                        "rr_D_Trt_timespan1_novent")]) 
      }
        if (trt_effect == "RD"){
          theta <- data.frame(m_Parameters[, c("rd_D_Trt_timespan1_vent",
                                                        "rd_D_Trt_timespan1_novent")]) 
        }
           if (trt_effect == "OR"){
             theta <- data.frame(m_Parameters[, c("or_D_Trt_timespan1_vent",
                                                        "or_D_Trt_timespan1_novent")]) 
           }
         if (trt_effect == "HR"){
           theta <- data.frame(m_Parameters[, c("hr_D_Trt_timespan1_vent",
                                                        "hr_D_Trt_timespan1_novent")] )
      }
    }

l_theta[[n]] <- as.list(theta)

# Select parameters from theta

sel_params_rct <- length(colnames(theta))  


### Estimate linear metamodel of two strategies
lmm1 <- gam(as.formula(paste("loss[, 1] ~ s(", colnames(theta)[sel_params_rct], ")")),
            data = theta)
lmm2 <- gam(as.formula(paste("loss[, 2] ~ s(", colnames(theta)[sel_params_rct], ")")),
            data = theta)


#### Compute EVSI on the chosen parameter ####
## Initial Sample size of the parameter
n0 <- v_enrolled_cumsum[i] # Use the cumilative number of people enrolled

# Vector with samples to evaluate EVPSI for an RCT
n_rct <- seq(0, 10000, by = 100)
n_rct_samples <- length(n_rct)

# Initialize EVPSI matrix for a combination of parameters
evpsi_rct_r_one <- data.frame(Study = "RCT", 
                              N     = n_rct, 
                              EVPSI = matrix(0, nrow = n_rct_samples, ncol = 1))

for (n_Samp in 1:n_rct_samples){
  
  ### Compute expected conditional loss for each strategy
  Ltilde1 <- predict.ga(lmm1, n = n_rct[n_Samp], n0 = n0)
  Ltilde2 <- predict.ga(lmm2, n = n_rct[n_Samp], n0 = n0)
  
  ## Combine losses into one matrix
  loss_tilde <- cbind(Ltilde1, Ltilde2)
  
  ### Apply EVSI equation
  evsi <- mean(rowMaxs(loss_tilde))
  
  evpsi_rct_r_one$EVPSI[n_Samp] <- evsi
 } # close loop for nSamp

 l_evpsi_rct_r_one_QALY[[n]] <-  evpsi_rct_r_one #  save the results or all n_Samp stored 
 
#Save the results for EVSI per person
l_EVSI_retr_rct_QALY[[n]] <- data.frame(l_evpsi_rct_r_one_QALY[[n]]$N, l_evpsi_rct_r_one_QALY[[n]]$EVPSI)

} #close loop for treatments 

# save the file
save(l_evpsi_rct_r_one_QALY, file = "../output/l_evpsi_rct_r_one_QALY.rda")

# Make a dataframe
df_evspi <- l_evpsi_rct_r_one_QALY %>% reduce(inner_join, by = c("N", "Study"))  
df_evspi[, -c(1, 2)] <- round(df_evspi[, -c(1, 2)])  # round the values
colnames(df_evspi) <- c("Study", "N", names(l_evpsi_rct_r_one_QALY))
df_evspi_plot <- df_evspi
colnames(df_evspi_plot) <- c("Study", "N", remove_date_from_name(colnames(df_evspi_plot[, -c(1, 2)])))


save(df_evspi_plot, file = "../output/df_evspi_plot_QALY.rda")

png("../figures/table_df_evspi_plot_QALY.png", width = 3000, height = 2600, bg = "white", pointsize = 30)
grid.table(df_evspi_plot)
dev.off()

```

## 9.6.4.1 Calculate EVSI for LY 
```{r}
# EVSI for groups of parameters for one WTP threshold
options(scipen = 999)

## Assuming an RCT ##

##LY###
df_summary_pop_EVPPI <- df_summary_pop_EVPPI_LY_pp # Note: Only used for table structure, either _pp or _resp or _prosp can be used

# Select the strategies with EVPPI > 0 at the wtp threshold of use
rownames(df_summary_pop_EVPPI) <- as.numeric(rownames(df_summary_pop_EVPPI))

v_names_EVSI <- v_names_EVSI_LY <- colnames(df_summary_pop_EVPPI)[which(df_summary_pop_EVPPI[rownames(df_summary_pop_EVPPI) == l_param_trt[[1]]$wtp, ] > 0)]

n_strategies <- n_str
l_m_nmb <- l_m_nmb2 <- l_evpsi_rct_r_one_LY <- l_EVSI_retr_rct_LY <- list()
l_theta <- list()

for (n in v_names_EVSI){
  
  trt_effect <- l_param_trt[[n]]$trt_effect
  vent       <- l_param_trt[[n]]$vent
 
  m_Parameters <- l_m_Parameters[[n]]
  
  l_m_nmb[[n]] <- NMB_function(wtp = l_param_trt[[n]]$wtp, 
                            effect = l_res[[n]]$res_ly,   ##LY###
                             costs =  l_res[[n]]$res_cost)
  
#m.nmb <- NMB_function2(wtp=WTP,effect=res.ly, costs=res.cost) #for NHB (here WTP cannot be 0)
   df_param_nmb <- data.frame(l_m_nmb[[n]])

   n_sim <- nrow(l_m_nmb[[n]])

#### Loss Matrix ####  
# Find optimal strategy (d*) based on the highest expected net value
m_nmb2 <- l_m_nmb[[n]][, c(1:2)]
d_star <- which.max(colMeans(m_nmb2))
d_star

## Compute Loss matrix iterating over all strategies
loss <- as.matrix(m_nmb2 - m_nmb2[, d_star])
head(loss)

# Specify parameters
  
    if(vent == FALSE){
      if (trt_effect == "RR"){
          theta <- data.frame(m_Parameters[, c("rr_D_Trt_timespan1")]) 
      }
        if (trt_effect == "RD"){
          theta <- data.frame(m_Parameters[, c("rd_D_Trt_timespan1")]) 
        }
           if (trt_effect == "OR"){
             theta <- data.frame(m_Parameters[, c("or_D_Trt_timespan1")]) 
           }
         if (trt_effect == "HR"){
           theta <- data.frame(m_Parameters[, c("hr_D_Trt_timespan1")]) 
      }
    } else if (vent == TRUE){
            if (trt_effect == "RR"){
              theta <- data.frame(m_Parameters[, c("rr_D_Trt_timespan1_vent",
                                                        "rr_D_Trt_timespan1_novent")]) 
      }
        if (trt_effect == "RD"){
          theta <- data.frame(m_Parameters[, c("rd_D_Trt_timespan1_vent",
                                                        "rd_D_Trt_timespan1_novent")]) 
        }
           if (trt_effect == "OR"){
             theta <- data.frame(m_Parameters[, c("or_D_Trt_timespan1_vent",
                                                        "or_D_Trt_timespan1_novent")]) 
           }
         if (trt_effect == "HR"){
           theta <- data.frame(m_Parameters[, c("hr_D_Trt_timespan1_vent",
                                                        "hr_D_Trt_timespan1_novent")] )
      }
    }

l_theta[[n]] <- as.list(theta)

# Select parameters from theta

sel_params_rct <- length(colnames(theta))  


### Estimate linear metamodel of two strategies
lmm1 <- gam(as.formula(paste("loss[, 1] ~ s(", colnames(theta)[sel_params_rct], ")")),
            data = theta)
lmm2 <- gam(as.formula(paste("loss[, 2] ~ s(", colnames(theta)[sel_params_rct], ")")),
            data = theta)


#### Compute EVSI on the chosen parameter ####
## Initial Sample size of the parameter
n0 <- v_enrolled_cumsum[i] 

# Vector with samples to evaluate EVPSI for an RCT
n_rct <- seq(0, 10000, by = 100)
n_rct_samples <- length(n_rct)

# Initialize EVPSI matrix for a combination of parameters
evpsi_rct_r_one <- data.frame(Study = "RCT", 
                              N     = n_rct, 
                              EVPSI = matrix(0, nrow = n_rct_samples, ncol = 1))

for (n_Samp in 1:n_rct_samples){
  
  ### Compute expected conditional loss for each strategy
  Ltilde1 <- predict.ga(lmm1, n = n_rct[n_Samp], n0 = n0)
  Ltilde2 <- predict.ga(lmm2, n = n_rct[n_Samp], n0 = n0)
  
  ## Combine losses into one matrix
  loss_tilde <- cbind(Ltilde1, Ltilde2)
  
  ### Apply EVSI equation
  evsi <- mean(rowMaxs(loss_tilde))
  
  evpsi_rct_r_one$EVPSI[n_Samp] <- evsi
 } # close loop for nSamp

 l_evpsi_rct_r_one_LY[[n]] <-  evpsi_rct_r_one #  save the results or all n_Samp stored 
 
#Save the results for EVSI per person
l_EVSI_retr_rct_LY[[n]] <- data.frame(l_evpsi_rct_r_one_LY[[n]]$N, l_evpsi_rct_r_one_LY[[n]]$EVPSI)

} #close loop for treatments 

# save the file
save(l_evpsi_rct_r_one_LY, file = "../output/l_evpsi_rct_r_one_LY.rda")

# Make a dataframe
df_evspi <- l_evpsi_rct_r_one_LY %>% reduce(inner_join, by = c("N", "Study"))  
df_evspi[, -c(1, 2)] <- round(df_evspi[, -c(1, 2)])  # round the values
colnames(df_evspi) <- c("Study", "N", names(l_evpsi_rct_r_one_LY))
df_evspi_plot <- df_evspi
colnames(df_evspi_plot) <- c("Study", "N", remove_date_from_name(colnames(df_evspi_plot[, -c(1, 2)])))


save(df_evspi_plot, file = "../output/df_evspi_plot_LY.rda")

png("../figures/table_df_evspi_plot_LY.png", width = 3000, height = 2600, bg = "white", pointsize = 30)
grid.table(df_evspi_plot)
dev.off()

```


###  9.6.5.1  Plot EVPSI per person for RCT - one grid plot - no xy lim
```{r, eval = TRUE}
#load(file = "../output/l_pop_evpsi_rct_r.rda")

# Create an empty list to store plots
plot_list <- list()

# Loop through the v_names_EVSI_LY and create a plot for each n
for (n in v_names_EVSI){

  # Create plot for EVSI by study design for RCT
  p <- ggplot(l_evpsi_rct_r_one_LY[[n]], aes(x = N, y = EVPSI)) + 
    geom_line() +
    geom_point() +
    facet_wrap(~ Study, scales = "free_x") +
    ggtitle("EVSI per person for RCT") +
    xlab("Sample size (n)") +
    ylab("$") +
    scale_x_continuous(breaks = number_ticks(5)) + 
    scale_y_continuous(breaks = number_ticks(6), labels = dollar) + 
    theme_bw(base_size = 14)

  # Add plot to plot_list
  plot_list[[n]] <- p
}

# Use ggarrange to combine plots in a grid
grid_plot <- ggarrange(plotlist = plot_list, ncol = n_cols_grid, nrow = n_rows_grid)+labs(title = "EVPSI - LY") +theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))

# Save the grid plot
ggsave(filename = "../figures/EVPSI_RCT_LY_grid.png", plot = grid_plot, width = 16, height = 24, units = "in")

# Create an empty list to store plots
plot_list <- list()

# Loop through the v_names_EVSI_QALY and create a plot for each n
for (n in v_names_EVSI){

  # Create plot for EVSI by study design for RCT
  p <- ggplot(l_evpsi_rct_r_one_QALY[[n]], aes(x = N, y = EVPSI)) + 
    geom_line() +
    geom_point() +
    facet_wrap(~ Study, scales = "free_x") +
    ggtitle("EVSI per person for RCT") +
    xlab("Sample size (n)") +
    ylab("$") +
    scale_x_continuous(breaks = number_ticks(5)) + 
    scale_y_continuous(breaks = number_ticks(6), labels = dollar) + 
    theme_bw(base_size = 14)

  # Add plot to plot_list
  plot_list[[n]] <- p
}

# Use ggarrange to combine plots in a grid
grid_plot <- ggarrange(plotlist = plot_list, ncol = n_cols_grid, nrow = n_rows_grid)+labs(title = "EVPSI - QALY") +theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))

# Save the grid plot
ggsave(filename = "../figures/EVPSI_RCT_QALY_grid.png", plot = grid_plot, width = 16, height = 24, units = "in")


```

###  9.6.5.2  Plot EVPSI per person for RCT - one grid plot - xy lim
```{r, eval = TRUE}
#load(file = "../output/l_evpsi_rct_r_one.rda")
#load(file = "../output/l_pop_evpsi_rct_r.rda")
# Set xy limits; find maximum value in all objects; 
max_EVPSI_LY <- max(sapply(l_evpsi_rct_r_one_LY, function(x) max(x[, "EVPSI"])))
xlim <- c(0, max(sapply(l_evpsi_rct_r_one_LY, function(x) max(x[, "N"]))))
ylim <- c(0, max_EVPSI_LY)

# Create an empty list to store plots
plot_list <- list()

# Loop through the v_names_EVSI_LY and create a plot for each n
for (n in v_names_EVSI_LY){

  # Create plot for EVSI by study design for RCT
  p <- ggplot(l_evpsi_rct_r_one_LY[[n]], aes(x = N, y = EVPSI)) + 
    geom_line() +
    geom_point() +
    facet_wrap(~ Study, scales = "free_x") +
    ggtitle("EVSI per person for RCT") +
    xlab("Sample size (n)") +
    ylab("$") +
    scale_x_continuous(breaks = number_ticks(5),  limits = xlim) + 
    scale_y_continuous(breaks = number_ticks(6), labels = dollar,  limits = ylim) + 
    theme_bw(base_size = 14)

  # Add plot to plot_list
  plot_list[[n]] <- p
}

# Use ggarrange to combine plots in a grid
grid_plot <- ggarrange(plotlist = plot_list, ncol = n_cols_grid, nrow = n_rows_grid)+labs(title = "EVPSI - LY") +theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))

# Save the grid plot
ggsave(filename = "../figures/EVPSI_RCT_LY_grid_xylim.png", plot = grid_plot, width = 16, height = 24, units = "in")

# Create an empty list to store plots
plot_list <- list()

# Loop through the v_names_EVSI_QALY and create a plot for each n
for (n in v_names_EVSI_QALY){

  # Create plot for EVSI by study design for RCT
  p <- ggplot(l_evpsi_rct_r_one_QALY[[n]], aes(x = N, y = EVPSI)) + 
    geom_line() +
    geom_point() +
    facet_wrap(~ Study, scales = "free_x") +
    ggtitle("EVSI per person for RCT") +
    xlab("Sample size (n)") +
    ylab("$") +
    scale_x_continuous(breaks = number_ticks(5), limits = xlim) + 
    scale_y_continuous(breaks = number_ticks(6), labels = dollar, limits = ylim) + 
    theme_bw(base_size = 14)

  # Add plot to plot_list
  plot_list[[n]] <- p
}

# Use ggarrange to combine plots in a grid
grid_plot <- ggarrange(plotlist = plot_list, ncol = n_cols_grid, nrow = n_rows_grid)+labs(title = "EVPSI - QALY") +theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))

# Save the grid plot
ggsave(filename = "../figures/EVPSI_RCT_QALY_grid_xylim.png", plot = grid_plot, width = 16, height = 24, units = "in")
```

### 9.6.4.2 Calculate pop EVSI

```{r}
## 9.6.4.2 Calculate pop EVSI
calculate_pop_evsi <- function(perspective) {
  if (perspective == "prosp") {
    l_pop <- l_pop_prosp
    suffix <- "_prosp"
  } else if (perspective == "resp") {
    l_pop <- l_pop_resp
    suffix <- "_resp"
  } else {
    stop("Invalid perspective specified")
  }
  
  l_pop_evpsi_rct_r_LY <- l_pop_evpsi_rct_r_QALY <- list()
  
  for (n in v_names_EVSI_LY) {
    ### Population Values
    ## Total population (can be presented in Millions)
    tot_pop <- l_pop[[n]]

    ## Population EVPSI

    # RCT
    pop_evpsi_rct_r             <- l_evpsi_rct_r_one_LY[[n]]
    pop_evpsi_rct_r$popEVPSI    <- pop_evpsi_rct_r$EVPSI * tot_pop
    l_pop_evpsi_rct_r_LY[[n]]   <- pop_evpsi_rct_r
  }
  
  save(l_pop_evpsi_rct_r_LY, file = paste0("../output/l_pop_evpsi_rct_r_LY", suffix, ".rda"))
  
  for (n in v_names_EVSI_QALY) {
    ### Population Values
    ## Total population (can be presented in Millions)
    tot_pop <- l_pop[[n]]
    
    ## Population EVPSI

    # RCT
    pop_evpsi_rct_r               <- l_evpsi_rct_r_one_QALY[[n]]
    pop_evpsi_rct_r$popEVPSI      <- pop_evpsi_rct_r$EVPSI * tot_pop
    l_pop_evpsi_rct_r_QALY[[n]]   <- pop_evpsi_rct_r
  }
  
  save(l_pop_evpsi_rct_r_QALY, file = paste0("../output/l_pop_evpsi_rct_r_QALY", suffix, ".rda"))
  
  # Assign created lists to global variables
  assign(paste0("l_pop_evpsi_rct_r_LY", suffix), l_pop_evpsi_rct_r_LY, envir = .GlobalEnv)
  assign(paste0("l_pop_evpsi_rct_r_QALY", suffix), l_pop_evpsi_rct_r_QALY, envir = .GlobalEnv)
}

# Run the function for different perspectives
calculate_pop_evsi(perspective = "resp")
calculate_pop_evsi(perspective = "prosp")

```

## 09.7 Calculate net benefit value of overall strategy of new therapies 

The code below calculates the expected net benefits (ENB) for four decision alternatives: Approve, Reject, Only in Research (OIR), and Approve with Research (AWR). It goes through each therapy and, based on the Incremental Net Monetary Benefit (iNMB) and Expected Value of Perfect Partial Information (EVPPI), determines the optimal strategy and calculates the ENB for each decision alternative.

A brief explanation of what the code does in each scenario:

If iNMB <= 0 & EVPPI <= 0: The optimal strategy is to "Reject" the therapy. The code calculates the ENB for Approve, OIR, and AWR.
If iNMB > 0 & EVPPI <= 0: The optimal strategy is to "Approve" the therapy. The code calculates the ENB for Approve, OIR, and AWR.
If iNMB <= 0 & EVPPI > 0: The code calculates the ENB for OIR, AWR, and Approve. If the optimal sample size (OSS) is greater than 0, the optimal strategy is OIR. If the OSS is greater than 2500, the code calculates the ENB for OIR and AWR at the sample size of 2500.
If iNMB > 0 & EVPPI > 0: The code calculates the ENB for AWR, OIR, and Approve. If the ENB for AWR is greater than the ENB for Approve, the optimal strategy is AWR. Otherwise, the optimal strategy is Approve. If the OSS is greater than 2500, the code calculates the ENB for AWR at the sample size of 2500.
The final output is a data frame (df_enb) containing the optimal strategy, optimal sample size, ENBs for different decision alternatives, and other relevant information for each therapy.

#####  9.7.1 QALY
```{r}
#Specify cost per person RCT, assuming they are the same for all 
#lapply(l_param_trt, function(x) x$c_RCT_ppo)
c_RCT_ppo <-l_param_trt[[1]]$c_RCT_ppo

calculate_net_value_QALY <- function(perspective = c("prosp", "resp")){
  perspective <- match.arg(perspective)
  
  # Use different inputs based on the perspective
  if (perspective == "prosp") {
    l_df_evppi_pop <- l_df_evppi_pop_prosp
    l_pop_evpsi_rct_r_QALY <- l_pop_evpsi_rct_r_QALY_prosp
    l_df_evppi_pop <- l_df_evppi_pop_prosp
    l_pop_all <- l_pop_all_prosp
  } else if (perspective == "resp"){
    l_df_evppi_pop <- l_df_evppi_pop_resp
    l_pop_evpsi_rct_r_QALY <- l_pop_evpsi_rct_r_QALY_resp
    l_df_evppi_pop <- l_df_evppi_pop_resp
    l_pop_all <- l_pop_all_resp
  }
  
  ##################### Original function
  
  l_enb <- l_oss <- list()


v_names_rows_enb <- c("Optimal strategy", 
                      "Optimal sample size (N*)", 
                      "Net value for:", 
                        "OIR", 
                        "AWR", 
                        "Approve", 
                        "Reject",
                      "Equation parameters:",
                      "Costs RCT",
                      "EVSI N*",
                      "Below values for sample size of N = 2500", 
                      "Costs RCT N=2500",
                      "EVSI N=2500",
                        "AWR N=2500", 
                        "OIR N=2500")

m_enb <- matrix(data = NA,
                nrow = length(v_names_rows_enb),
                ncol = length(v_names_trt_report_full),
                dimnames = list(v_names_rows_enb, v_names_trt_report_full))

df_enb <- as.data.frame(m_enb)

#The optimal sample size (OSS) is determined by maximizing the function in the quadrant with respect to n. 

for (n in v_names_trt_report_full){
options(scipen = 999)
  
# select the values needed in the equations 
iNMB               <- l_df_PSA_QALY[[n]]$iNMB[2] 
wtp                <- l_param_trt[[n]]$wtp
EVPPI              <- l_df_evppi_pop[[n]][, "QALY"][l_df_evppi_pop[[n]][, "WTP"] == wtp]

l_pop_evpsi_rct_r <- l_pop_evpsi_rct_r_QALY


n_patients_current <- l_pop_all[[n]]$n_patients_current
n_patients_future  <- l_pop_all[[n]]$n_patients_future   
n_p_rct_ratio      <- 0.5  # proportion of the RCT participants in the treatment arm
c_RCT_fixed        <- l_param_trt[[n]]$c_RCT_fixed
#c_RCT_ppo          <- l_param_trt[[n]]$c_RCT_ppo # same for all groups, specified at start of chunk
n_samp_size        <- n_rct  # vector of sample size values
n_samp_size_real   <- 2500   # The most realistic sample size - used to report if optimal sample size > 2500

  df_enb["Reject", n] <- 0

  if(iNMB <= 0 & EVPPI <= 0){ # Reject
  df_enb["Optimal strategy", n] <- "Reject"   # store the strategy
  
  #### Calculations for the OIR and AWR and approve
  EVPSI <- 0  # Set EVPSI on zero
  
  ## Approve ##
  df_enb["Approve", n] <- calc_enb_approve(iNB = iNMB,
                            n_patients_current = n_patients_current,
                             n_patients_future = n_patients_future)
 ## Only in research ##
  v_enb_OIR             <- calc_enb_OIR(iNB = iNMB,
                                  rct_ratio = n_p_rct_ratio,
                                sample_size = n_samp_size,
                                      EVPSI = EVPSI,
                         n_patients_future = n_patients_future,
                               c_RCT_fixed = c_RCT_fixed,
                                  c_RCT_pp = c_RCT_ppo)
  df_enb["OIR", n] <- v_enb_OIR[which.max(v_enb_OIR)] # select the maximum value. Note in negative values this is the least negative. 
  # this can result in a sample size of zero if that is the least 
 
  ## Approve with research ##
  v_enb_AWR <-  calc_enb_AWR(iNB = iNMB,
                             rct_ratio = n_p_rct_ratio,
                             sample_size = n_samp_size,
                             EVPSI = EVPSI,
                             n_patients_future = n_patients_future,
                             n_patients_current = n_patients_current,
                             c_RCT_fixed = c_RCT_fixed,
                             c_RCT_pp = c_RCT_ppo)
  
  df_enb["AWR", n] <- v_enb_AWR[which.max(v_enb_AWR)]
  
  
  
} else if (iNMB > 0 & EVPPI <= 0){
   # Store the strategy 
  df_enb["Optimal strategy", n] <- "Approve"   
  
  # Calculate the expected net value for approve
  df_enb["Approve", n] <- calc_enb_approve(iNB = iNMB,
                          n_patients_current = n_patients_current,
                          n_patients_future = n_patients_future)
  
  #### Calculations for the OIR and AWR 
  EVPSI <- 0
 
  v_enb_OIR <- calc_enb_OIR(iNB = iNMB,
                            rct_ratio = n_p_rct_ratio,
                            sample_size = n_samp_size,
                            EVPSI = EVPSI,
                            n_patients_future = n_patients_future,
                            c_RCT_fixed = c_RCT_fixed,
                            c_RCT_pp = c_RCT_ppo)
  
  df_enb["OIR", n] <- v_enb_OIR[which.max(v_enb_OIR)]
  
  v_enb_AWR <-  calc_enb_AWR(iNB = iNMB,
                             rct_ratio = n_p_rct_ratio,
                             sample_size = n_samp_size,
                             EVPSI = EVPSI,
                             n_patients_current = n_patients_current,
                             n_patients_future = n_patients_future,
                             c_RCT_fixed = c_RCT_fixed,
                             c_RCT_pp = c_RCT_ppo)

  df_enb["AWR", n] <- v_enb_AWR[which.max(v_enb_AWR)]
  
  
} else if(iNMB <= 0 & EVPPI > 0){ 
  EVPSI        <- l_pop_evpsi_rct_r[[n]]$EVPSI # select EVPSI per person for each sample size
  names(EVPSI) <- l_pop_evpsi_rct_r[[n]]$N

    # Calculate only in research 
    v_enb_OIR <- calc_enb_OIR(iNB = iNMB, 
                              rct_ratio = n_p_rct_ratio, 
                              sample_size = n_samp_size, 
                              EVPSI = EVPSI, 
                              n_patients_future = n_patients_future, 
                              c_RCT_fixed = c_RCT_fixed, 
                              c_RCT_pp = c_RCT_ppo)
    oss <- n_samp_size[which.max(v_enb_OIR)]    
    
    df_enb["OIR", n] <- v_enb_OIR[which.max(v_enb_OIR)]
    
  ## Approve ##
  df_enb["Approve", n] <- calc_enb_approve(iNB = iNMB,
                          n_patients_current = n_patients_current,
                          n_patients_future = n_patients_future)
  
  v_enb_AWR<- calc_enb_AWR(iNB = iNMB,
                                    rct_ratio = n_p_rct_ratio,
                                    sample_size = n_samp_size,
                                    EVPSI = EVPSI,
                                    n_patients_current = n_patients_current,
                                    n_patients_future = n_patients_future,
                                    c_RCT_fixed = c_RCT_fixed,
                                    c_RCT_pp = c_RCT_ppo)
   df_enb["AWR",   n] <- v_enb_AWR[which.max(v_enb_AWR)]
    

  if(oss > 0){ 
    df_enb["Optimal strategy", n]         <- "OIR"   # store the strategy       
    #df_enb["OIR", n]                      <- v_enb_OIR[which.max(v_enb_OIR)]
    df_enb["Optimal sample size (N*)", n] <- oss
    df_enb["Costs RCT", n]                <- round((c_RCT_fixed + oss  * c_RCT_ppo)) 
    df_enb["EVSI N*", n]                  <- round(EVPSI[which(names(EVPSI) == oss)])
    
}  else {
      df_enb["Optimal strategy", n] <- "Reject"   # store the strategy 
      df_enb["Reject", n] <- 0
      #df_enb["OIR", n]                      <- v_enb_OIR[which.max(v_enb_OIR)]
      
      #df_enb["OIR", n]    <- "Worse than Reject" # If you decided OIR, it costs you a lot of money
}
  
  if(oss > 2500){
        df_enb["EVSI N=2500", n]   <- round(EVPSI[which(names(EVPSI) == n_samp_size_real)])
    df_enb["Costs RCT N=2500", n]   <- round((c_RCT_fixed + n_samp_size_real * c_RCT_ppo)) 
  
    df_enb["OIR N=2500",   n]  <- calc_enb_OIR(iNB = iNMB, 
                                    rct_ratio = n_p_rct_ratio, 
                              sample_size = n_samp_size_real, 
                              EVPSI =  EVPSI[which(names(EVPSI) == n_samp_size_real)], 
                              n_patients_future = n_patients_future, 
                              c_RCT_fixed = c_RCT_fixed, 
                              c_RCT_pp = c_RCT_ppo)
    
    df_enb["AWR N=2500",   n] <- calc_enb_AWR(iNB = iNMB,
                                    rct_ratio = n_p_rct_ratio,
                                    sample_size = n_samp_size_real,
                                    EVPSI = EVPSI[which(names(EVPSI) == n_samp_size_real)],
                                    n_patients_current = n_patients_current,
                                    n_patients_future = n_patients_future,
                                    c_RCT_fixed = c_RCT_fixed,
                                    c_RCT_pp = c_RCT_ppo)

  }
    
      
  l_enb[[n]] <- data.frame(N     = n_samp_size, 
                           Study = "RCT",
                            cRCT = round((c_RCT_fixed + n_samp_size * c_RCT_ppo)),
                            EVPSI = round(EVPSI),
                  Implementation = "OIR",
                           ENB   = v_enb_OIR,
                           nstar = oss,
                        ENBnstar = v_enb_OIR[which.max(v_enb_OIR)]) 

  
  
  
} else if(iNMB > 0 & EVPPI > 0){
  
    EVPSI        <- l_pop_evpsi_rct_r[[n]]$EVPSI # select EVPSI per person
    names(EVPSI) <- l_pop_evpsi_rct_r[[n]]$N
  
    v_enb_AWR <-  calc_enb_AWR(iNB = iNMB,
                                    rct_ratio = n_p_rct_ratio,
                                    sample_size = n_samp_size,
                                    EVPSI = EVPSI,
                                    n_patients_current = n_patients_current,
                                    n_patients_future = n_patients_future,
                                    c_RCT_fixed = c_RCT_fixed,
                                    c_RCT_pp = c_RCT_ppo)
    oss <- n_samp_size[which.max(v_enb_AWR)] 
    
    df_enb["AWR", n]  <- round(v_enb_AWR[which.max(v_enb_AWR)]) 
    
    # Calculate only in research 
    v_enb_OIR <- calc_enb_OIR(iNB = iNMB, 
                              rct_ratio = n_p_rct_ratio, 
                              sample_size = n_samp_size, 
                              EVPSI = EVPSI, 
                              n_patients_future = n_patients_future, 
                              c_RCT_fixed = c_RCT_fixed, 
                              c_RCT_pp = c_RCT_ppo)
  
    df_enb["OIR", n] <- v_enb_OIR[which.max(v_enb_OIR)]

    l_enb[[n]] <- data.frame(N   = n_samp_size, 
                             Study = "RCT",
                             cRCT = round((c_RCT_fixed + n_samp_size * c_RCT_ppo)),
                             EVPSI = EVPSI,
                             Implementation = "OIR",
                             ENB = v_enb_OIR,
                             nstar = oss)


  # Calculate the expected net value for approve
  df_enb["Approve", n] <- calc_enb_approve(iNB = iNMB,
                                           n_patients_current = n_patients_current,
                                           n_patients_future = n_patients_future)
      
    if(df_enb["AWR", n] > df_enb["Approve", n]){ 
      df_enb["Optimal strategy", n]    <- "AWR"   # store the strategy     
      df_enb["AWR", n]                 <- round(v_enb_AWR[which.max(v_enb_AWR)]) 
      df_enb["Optimal sample size (N*)", n] <- oss
      df_enb["Costs RCT", n]           <- round((c_RCT_fixed + oss * c_RCT_ppo))     
      df_enb["EVSI N*", n]            <- round(EVPSI[which(names(EVPSI) == oss)])

}  else{
      df_enb["Optimal strategy", n] <- "Approve"   # store the strategy 
      df_enb["AWR", n]              <- round(v_enb_AWR[which.max(v_enb_AWR)]) 
       # Calculate the expected net value for approve
       df_enb["Approve", n]         <- calc_enb_approve(iNB = iNMB,
                                           n_patients_current = n_patients_current,
                                           n_patients_future = n_patients_future)
}
  if(oss > 2500){
          
      df_enb["Costs RCT N=2500", n]    <- round((c_RCT_fixed + 2500 * c_RCT_ppo))
      df_enb["EVSI N=2500", n]        <- round(EVPSI[which(names(EVPSI) == 2500)])
      df_enb["AWR N=2500", n]          <- calc_enb_AWR(iNB = iNMB,
                                                  rct_ratio = n_p_rct_ratio,
                                                  sample_size = 2500,
                                                  EVPSI = EVPSI[which(names(EVPSI) == 2500)],
                                                  n_patients_current = n_patients_current,
                                                  n_patients_future = n_patients_future,
                                                  c_RCT_fixed = c_RCT_fixed,
                                                  c_RCT_pp = c_RCT_ppo)
      
          
    df_enb["OIR N=2500",   n]  <- calc_enb_OIR(iNB = iNMB, 
                              rct_ratio = n_p_rct_ratio, 
                              sample_size = 2500, 
                              EVPSI =  EVPSI[which(names(EVPSI) == 2500)], 
                              n_patients_future = n_patients_future, 
                              c_RCT_fixed = c_RCT_fixed, 
                              c_RCT_pp = c_RCT_ppo)
  }
}

}

# Note: this step is only done for the studies that show positive EVPPI
df_oss <- matrix(NA, nrow = 3, ncol = length(names(l_enb)), 
                 dimnames = list(c("Implementation", "MaxENBS", "Nstar"), names(l_enb)))


for (n in names(l_enb)){
#### Optimal Sample Size (OSS), n*
l_oss[[n]] <- summarise(group_by(l_enb[[n]], Study),
                        Implementation = Implementation[1],
                        MaxENBS = max(ENB),
                        Nstar   = N[which.max(ENB)])

df_oss[, n] <- t(l_oss[[n]]) # transpose the data and store in a dataframe
}


df_enb_plot <- df_enb
colnames(df_enb_plot) <- remove_date_from_name(colnames(df_enb_plot))

# New order table 
df_enb_plot_order <- df_enb_plot[, c(which(df_enb_plot["Optimal strategy", ] == "OIR"),
which(df_enb_plot["Optimal strategy", ] == "AWR"),
which(df_enb_plot["Optimal strategy", ] == "Approve"),
which(df_enb_plot["Optimal strategy", ] == "Reject"))]
  
  #####################
  df_enb_plot[is.na(df_enb_plot)] <- "n/a"
  file_name <- paste0("../figures/df_table_enb_QALY_", perspective, ".png")
  png(file_name, width = 3000, height = 2000, bg = "white", pointsize = 22)
  grid.table(df_enb_plot_order)
  dev.off()
  
  # Save the output with the respective suffix
  # At the end of the code, save the outputs with the respective suffix.
  save(df_enb, file = paste0("../output/df_enb_", perspective, ".rda"))
  save(l_enb, file = paste0("../output/l_enb_", perspective, ".rda"))
  save(df_enb_plot, file = paste0("../output/df_enb_plot_QALY_", perspective, ".rda"))
 
  # Assign created lists to global variables
  assign(paste0("df_enb_QALY_", perspective), df_enb, envir = .GlobalEnv)
  assign(paste0("l_enb_QALY_", perspective), l_enb, envir = .GlobalEnv)
  assign(paste0("df_enb_plot_QALY_", perspective), df_enb_plot, envir = .GlobalEnv)
}

# Run the function for each perspective
calculate_net_value_QALY("resp")
calculate_net_value_QALY("prosp")
```

#####  9.6.6.1 LY
```{r}
calculate_net_value_LY <- function(perspective = c("prosp", "resp")){
  perspective <- match.arg(perspective)
  
  # Use different inputs based on the perspective
  if (perspective == "prosp") {
    l_df_evppi_pop <- l_df_evppi_pop_prosp
    l_pop_evpsi_rct_r_LY <- l_pop_evpsi_rct_r_LY_prosp
    l_df_evppi_pop <- l_df_evppi_pop_prosp
    l_pop_all <- l_pop_all_prosp
  } else if (perspective == "resp"){
    l_df_evppi_pop <- l_df_evppi_pop_resp
    l_pop_evpsi_rct_r_LY <- l_pop_evpsi_rct_r_LY_resp
    l_df_evppi_pop <- l_df_evppi_pop_resp
    l_pop_all <- l_pop_all_resp
  }
  
  ##################### Original function
  
  l_enb <- l_oss <- list()


v_names_rows_enb <- c("Optimal strategy", 
                      "Optimal sample size (N*)", 
                      "Net value for:", 
                        "OIR", 
                        "AWR", 
                        "Approve", 
                        "Reject",
                      "Equation parameters:",
                      "Costs RCT",
                      "EVSI N*",
                      "Below values for sample size of N = 2500", 
                      "Costs RCT N=2500",
                      "EVSI N=2500",
                        "AWR N=2500", 
                        "OIR N=2500")

m_enb <- matrix(data = NA,
                nrow = length(v_names_rows_enb),
                ncol = length(v_names_trt_report_full),
                dimnames = list(v_names_rows_enb, v_names_trt_report_full))

df_enb <- as.data.frame(m_enb)

#The optimal sample size (OSS) is determined by maximizing the function in the quadrant with respect to n. 

for (n in v_names_trt_report_full){
options(scipen = 999)
  
# select the values needed in the equations 
iNMB               <- l_df_PSA_LY[[n]]$iNMB[2] 
wtp                <- l_param_trt[[n]]$wtp
EVPPI              <- l_df_evppi_pop[[n]][, "LY"][l_df_evppi_pop[[n]][, "WTP"] == wtp]

l_pop_evpsi_rct_r <- l_pop_evpsi_rct_r_LY


n_patients_current <- l_pop_all[[n]]$n_patients_current
n_patients_future  <- l_pop_all[[n]]$n_patients_future   
n_p_rct_ratio      <- 0.5  # proportion of the RCT participants in the treatment arm
c_RCT_fixed        <- l_param_trt[[n]]$c_RCT_fixed
c_RCT_ppo          <- l_param_trt[[n]]$c_RCT_ppo
n_samp_size        <- n_rct  # vector of sample size values
n_samp_size_real   <- 2500   # The most realistic sample size - used to report if optimal sample size > 2500

  df_enb["Reject", n] <- 0

  if(iNMB <= 0 & EVPPI <= 0){ # Reject
  df_enb["Optimal strategy", n] <- "Reject"   # store the strategy
  
  #### Calculations for the OIR and AWR and approve
  EVPSI <- 0  # Set EVPSI on zero
  
  ## Approve ##
  df_enb["Approve", n] <- calc_enb_approve(iNB = iNMB,
                            n_patients_current = n_patients_current,
                             n_patients_future = n_patients_future)
 ## Only in research ##
  v_enb_OIR             <- calc_enb_OIR(iNB = iNMB,
                                  rct_ratio = n_p_rct_ratio,
                                sample_size = n_samp_size,
                                      EVPSI = EVPSI,
                         n_patients_future = n_patients_future,
                               c_RCT_fixed = c_RCT_fixed,
                                  c_RCT_pp = c_RCT_ppo)
  df_enb["OIR", n] <- v_enb_OIR[which.max(v_enb_OIR)] # select the maximum value. Note in negative values this is the least negative. 
  # this can result in a sample size of zero if that is the least 
 
  ## Approve with research ##
  v_enb_AWR <-  calc_enb_AWR(iNB = iNMB,
                             rct_ratio = n_p_rct_ratio,
                             sample_size = n_samp_size,
                             EVPSI = EVPSI,
                             n_patients_future = n_patients_future,
                             n_patients_current = n_patients_current,
                             c_RCT_fixed = c_RCT_fixed,
                             c_RCT_pp = c_RCT_ppo)
  
  df_enb["AWR", n] <- v_enb_AWR[which.max(v_enb_AWR)]
  
  
  
} else if (iNMB > 0 & EVPPI <= 0){
   # Store the strategy 
  df_enb["Optimal strategy", n] <- "Approve"   
  
  # Calculate the expected net value for approve
  df_enb["Approve", n] <- calc_enb_approve(iNB = iNMB,
                          n_patients_current = n_patients_current,
                          n_patients_future = n_patients_future)
  
  #### Calculations for the OIR and AWR 
  EVPSI <- 0
 
  v_enb_OIR <- calc_enb_OIR(iNB = iNMB,
                            rct_ratio = n_p_rct_ratio,
                            sample_size = n_samp_size,
                            EVPSI = EVPSI,
                            n_patients_future = n_patients_future,
                            c_RCT_fixed = c_RCT_fixed,
                            c_RCT_pp = c_RCT_ppo)
  
  df_enb["OIR", n] <- v_enb_OIR[which.max(v_enb_OIR)]
  
  v_enb_AWR <-  calc_enb_AWR(iNB = iNMB,
                             rct_ratio = n_p_rct_ratio,
                             sample_size = n_samp_size,
                             EVPSI = EVPSI,
                             n_patients_current = n_patients_current,
                             n_patients_future = n_patients_future,
                             c_RCT_fixed = c_RCT_fixed,
                             c_RCT_pp = c_RCT_ppo)

  df_enb["AWR", n] <- v_enb_AWR[which.max(v_enb_AWR)]
  
  
} else if(iNMB <= 0 & EVPPI > 0){ 
  EVPSI        <- l_pop_evpsi_rct_r[[n]]$EVPSI # select EVPSI per person
  names(EVPSI) <- l_pop_evpsi_rct_r[[n]]$N

    # Calculate only in research 
    v_enb_OIR <- calc_enb_OIR(iNB = iNMB, 
                              rct_ratio = n_p_rct_ratio, 
                              sample_size = n_samp_size, 
                              EVPSI = EVPSI, 
                              n_patients_future = n_patients_future, 
                              c_RCT_fixed = c_RCT_fixed, 
                              c_RCT_pp = c_RCT_ppo)
    oss <- n_samp_size[which.max(v_enb_OIR)]    
    
    df_enb["OIR", n] <- v_enb_OIR[which.max(v_enb_OIR)]
    
  ## Approve ##
  df_enb["Approve", n] <- calc_enb_approve(iNB = iNMB,
                          n_patients_current = n_patients_current,
                          n_patients_future = n_patients_future)
  
  v_enb_AWR<- calc_enb_AWR(iNB = iNMB,
                                    rct_ratio = n_p_rct_ratio,
                                    sample_size = n_samp_size,
                                    EVPSI = EVPSI,
                                    n_patients_current = n_patients_current,
                                    n_patients_future = n_patients_future,
                                    c_RCT_fixed = c_RCT_fixed,
                                    c_RCT_pp = c_RCT_ppo)
   df_enb["AWR",   n] <- v_enb_AWR[which.max(v_enb_AWR)]
    

  if(oss > 0){ 
    df_enb["Optimal strategy", n]         <- "OIR"   # store the strategy       
    #df_enb["OIR", n]                      <- v_enb_OIR[which.max(v_enb_OIR)]
    df_enb["Optimal sample size (N*)", n] <- oss
    df_enb["Costs RCT", n]                <- round((c_RCT_fixed + oss  * c_RCT_ppo)) 
    df_enb["EVSI N*", n]                 <- round(EVPSI[which(names(EVPSI) == oss)])
    
}  else {
      df_enb["Optimal strategy", n] <- "Reject"   # store the strategy 
      df_enb["Reject", n] <- 0
      #df_enb["OIR", n]                      <- v_enb_OIR[which.max(v_enb_OIR)]
      
      #df_enb["OIR", n]    <- "Worse than Reject" # If you decided OIR, it costs you a lot of money
}
  
  if(oss > 2500){
        df_enb["EVSI N=2500", n]   <- round(EVPSI[which(names(EVPSI) == n_samp_size_real)])
    df_enb["Costs RCT N=2500", n]   <- round((c_RCT_fixed + n_samp_size_real * c_RCT_ppo)) 
  
    df_enb["OIR N=2500",   n]  <- calc_enb_OIR(iNB = iNMB, 
                                    rct_ratio = n_p_rct_ratio, 
                              sample_size = n_samp_size_real, 
                              EVPSI =  EVPSI[which(names(EVPSI) == n_samp_size_real)], 
                              n_patients_future = n_patients_future, 
                              c_RCT_fixed = c_RCT_fixed, 
                              c_RCT_pp = c_RCT_ppo)
    
    df_enb["AWR N=2500",   n] <- calc_enb_AWR(iNB = iNMB,
                                    rct_ratio = n_p_rct_ratio,
                                    sample_size = n_samp_size_real,
                                    EVPSI = EVPSI[which(names(EVPSI) == n_samp_size_real)],
                                    n_patients_current = n_patients_current,
                                    n_patients_future = n_patients_future,
                                    c_RCT_fixed = c_RCT_fixed,
                                    c_RCT_pp = c_RCT_ppo)

  }

    
  l_enb[[n]] <- data.frame(N     = n_samp_size, 
                           Study = "RCT",
                            cRCT = round((c_RCT_fixed + n_samp_size * c_RCT_ppo)),
                            EVPSI = round(EVPSI),
                  Implementation = "OIR",
                           ENB   = v_enb_OIR,
                           nstar = oss,
                        ENBnstar = v_enb_OIR[which.max(v_enb_OIR)]) 

  
} else if(iNMB > 0 & EVPPI > 0){
  
    EVPSI        <- l_pop_evpsi_rct_r[[n]]$EVPSI # select EVPSI per person
    names(EVPSI) <- l_pop_evpsi_rct_r[[n]]$N
  
    v_enb_AWR <-  calc_enb_AWR(iNB = iNMB,
                                    rct_ratio = n_p_rct_ratio,
                                    sample_size = n_samp_size,
                                    EVPSI = EVPSI,
                                    n_patients_current = n_patients_current,
                                    n_patients_future = n_patients_future,
                                    c_RCT_fixed = c_RCT_fixed,
                                    c_RCT_pp = c_RCT_ppo)
    oss <- n_samp_size[which.max(v_enb_AWR)] 
    
    df_enb["AWR", n]  <- round(v_enb_AWR[which.max(v_enb_AWR)]) 
    
    # Calculate only in research 
    v_enb_OIR <- calc_enb_OIR(iNB = iNMB, 
                              rct_ratio = n_p_rct_ratio, 
                              sample_size = n_samp_size, 
                              EVPSI = EVPSI, 
                              n_patients_future = n_patients_future, 
                              c_RCT_fixed = c_RCT_fixed, 
                              c_RCT_pp = c_RCT_ppo)
  
    df_enb["OIR", n] <- v_enb_OIR[which.max(v_enb_OIR)]

    l_enb[[n]] <- data.frame(N   = n_samp_size, 
                             Study = "RCT",
                             cRCT = round((c_RCT_fixed + n_samp_size * c_RCT_ppo)),
                             EVPSI = EVPSI,
                             Implementation = "AWR",
                             ENB = v_enb_AWR,
                             nstar = oss)


  # Calculate the expected net value for approve
  df_enb["Approve", n] <- calc_enb_approve(iNB = iNMB,
                                           n_patients_current = n_patients_current,
                                           n_patients_future = n_patients_future)
      
    if(df_enb["AWR", n] > df_enb["Approve", n]){ 
      df_enb["Optimal strategy", n]    <- "AWR"   # store the strategy     
      df_enb["AWR", n]                 <- round(v_enb_AWR[which.max(v_enb_AWR)]) 
      df_enb["Optimal sample size (N*)", n] <- oss
      df_enb["Costs RCT", n]           <- round((c_RCT_fixed + oss * c_RCT_ppo))     
      df_enb["EVSI N*", n]            <- round(EVPSI[which(names(EVPSI) == oss)])

}  else{
      df_enb["Optimal strategy", n] <- "Approve"   # store the strategy 
      df_enb["AWR", n]              <- round(v_enb_AWR[which.max(v_enb_AWR)]) 
       # Calculate the expected net value for approve
       df_enb["Approve", n]         <- calc_enb_approve(iNB = iNMB,
                                           n_patients_current = n_patients_current,
                                           n_patients_future = n_patients_future)
}
  if(oss > 2500){
          
      df_enb["Costs RCT N=2500", n]    <- round((c_RCT_fixed + 2500 * c_RCT_ppo))
      df_enb["EVSI N=2500", n]        <- round(EVPSI[which(names(EVPSI) == 2500)])
      df_enb["AWR N=2500", n]          <- calc_enb_AWR(iNB = iNMB,
                                                  rct_ratio = n_p_rct_ratio,
                                                  sample_size = 2500,
                                                  EVPSI = EVPSI[which(names(EVPSI) == 2500)],
                                                  n_patients_current = n_patients_current,
                                                  n_patients_future = n_patients_future,
                                                  c_RCT_fixed = c_RCT_fixed,
                                                  c_RCT_pp = c_RCT_ppo)
      
          
    df_enb["OIR N=2500",   n]  <- calc_enb_OIR(iNB = iNMB, 
                              rct_ratio = n_p_rct_ratio, 
                              sample_size = 2500, 
                              EVPSI =  EVPSI[which(names(EVPSI) == 2500)], 
                              n_patients_future = n_patients_future, 
                              c_RCT_fixed = c_RCT_fixed, 
                              c_RCT_pp = c_RCT_ppo)
  }
}

}

# Note: this step is only done for the studies that show positive EVPPI
df_oss <- matrix(NA, nrow = 3, ncol = length(names(l_enb)), 
                 dimnames = list(c("Implementation", "MaxENBS", "Nstar"), names(l_enb)))


for (n in names(l_enb)){
#### Optimal Sample Size (OSS), n*
l_oss[[n]] <- summarise(group_by(l_enb[[n]], Study),
                        Implementation = Implementation[1],
                      MaxENBS = max(ENB),
                      Nstar   = N[which.max(ENB)])

df_oss[, n] <- t(l_oss[[n]]) # transpose the data and store in a dataframe
}


df_enb_plot <- df_enb
colnames(df_enb_plot) <- remove_date_from_name(colnames(df_enb_plot))

# New order table 
df_enb_plot_order <- df_enb_plot[, c(which(df_enb_plot["Optimal strategy", ] == "OIR"),
which(df_enb_plot["Optimal strategy", ] == "AWR"),
which(df_enb_plot["Optimal strategy", ] == "Approve"),
which(df_enb_plot["Optimal strategy", ] == "Reject"))]
  
  #####################
  df_enb_plot[is.na(df_enb_plot)] <- "n/a"
  file_name <- paste0("../figures/df_table_enb_LY_", perspective, ".png")
  png(file_name, width = 3000, height = 2000, bg = "white", pointsize = 22)
  grid.table(df_enb_plot_order)
  dev.off()
  
  # Save the output with the respective suffix
  # At the end of the code, save the outputs with the respective suffix.
  save(df_enb, file = paste0("../output/df_enb_", perspective, ".rda"))
  save(l_enb, file = paste0("../output/l_enb_", perspective, ".rda"))
  save(df_enb_plot, file = paste0("../output/df_enb_plot_LY_", perspective, ".rda"))
 
  # Assign created lists to global variables
  assign(paste0("df_enb_LY_", perspective), df_enb, envir = .GlobalEnv)
  assign(paste0("l_enb_LY_", perspective), l_enb, envir = .GlobalEnv)
  assign(paste0("df_enb_plot_LY_", perspective), df_enb_plot, envir = .GlobalEnv)
}

# Run the function for each perspective
calculate_net_value_LY("resp")
calculate_net_value_LY("prosp")
```

#### 9.6.7.2 Plot Net value 
```{r}
create_ENB_plots <- function(perspective) {
  
  if (perspective == "prosp") {
    l_enb_LY <- l_enb_LY_prosp
    l_enb_QALY <- l_enb_QALY_prosp
    suffix <- "_prosp"
  } else if (perspective == "resp") {
    l_enb_LY <- l_enb_LY_resp
    l_enb_QALY <- l_enb_QALY_resp
    suffix <- "_resp"
  } else {
    stop("Invalid perspective specified")
  }
  
  # Prepare LY plots
l_enb <- l_enb_LY

# Set xy limits; find maximum EVPI_LY value in all objects; LY will always be higher than QALY
max_ENB <- max(sapply(l_enb, function(x) max(x[, "ENB"])))
xlim <- c(0, max(sapply(l_enb, function(x) max(x[, "N"]))))
ylim <- c(0, max_ENB/1e6)

# create a list of plots
plot_list <- lapply(names(l_enb), function(n){
  ggplot(l_enb[[n]], aes(x = N, y = (ENB/1e6))) +
    geom_line() +
    xlab("Sample size") +
    ylab("ENB (Million $)") + 
    ggtitle(paste("ENB of", remove_date_from_name(n), "for strategy:", seb = ""),
            subtitle = l_enb[[n]]$Implementation[1]) +
    geom_vline(xintercept = mean(l_enb[[n]]$nstar), linetype = "dashed", 
               color = "gray", size = 0.8) +
    labs(caption = paste("ENB at N=2500:", round(mean(l_enb[[n]]$ENB[l_enb[[n]]$N == 2500]/1e6)), "and ENB at N*:", round(l_enb[[n]]$nstar/1e6), sep =" "), colour = "lightblue")
})


plot_list_xylim <- lapply(names(l_enb), function(n){
  ggplot(l_enb[[n]], aes(x = N, y = (ENB/1e6))) +
    geom_line() +
    xlab("Sample size") +
    ylab("ENB (Million $)") + 
    ggtitle(paste("ENB of", remove_date_from_name(n), "for strategy:", seb = ""),
            subtitle = l_enb[[n]]$Implementation[1]) +
    geom_vline(xintercept = mean(l_enb[[n]]$nstar), linetype = "dashed", 
               color = "gray", size = 0.8) +
    labs(caption = paste("ENB at N=2500:", round(mean(l_enb[[n]]$ENB[l_enb[[n]]$N == 2500]/1e6)), "and ENB at N*:", round(l_enb[[n]]$nstar/1e6), sep =" "), colour = "lightblue") +
    scale_x_continuous(limits = xlim) +
    scale_y_continuous(limits = ylim)
})

# arrange the plots in a grid
grid_plot <- ggarrange(plotlist = plot_list, nrow = n_rows_grid, ncol = n_cols_grid)+labs(title = "Expected Net Monetary Benefit - LY") +theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))
grid_plot_xylim <- ggarrange(plotlist = plot_list_xylim, nrow = n_rows_grid, ncol = n_cols_grid)+labs(title = "Expected Net Monetary Benefit - LY") +theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))

# save the plot
ggsave(filename = paste0("../figures/ENB_LY_grid", suffix, ".png"), plot = grid_plot, width = 30, height = 30, units = "in")
ggsave(filename = paste0("../figures/ENB_LY_grid_xylim", suffix, ".png"), plot = grid_plot_xylim, width = 30, height = 30, units = "in")


# Prepare QALY plots

l_enb <- l_enb_QALY

# create a list of plots
plot_list <- lapply(names(l_enb), function(n){
  ggplot(l_enb[[n]], aes(x = N, y = (ENB/1e6))) +
    geom_line() +
    xlab("Sample size") +
    ylab("ENB (Million $)") + 
    ggtitle(paste("ENB of", remove_date_from_name(n), "for strategy:", seb = ""),
            subtitle = l_enb[[n]]$Implementation[1]) +
    geom_vline(xintercept = mean(l_enb[[n]]$nstar), linetype = "dashed", 
               color = "gray", size = 0.8) +
    labs(caption = paste("ENB at N=2500:", round(mean(l_enb[[n]]$ENB[l_enb[[n]]$N == 2500]/1e6)), "and ENB at N*:", round(l_enb[[n]]$nstar/1e6), sep =" "), colour = "lightblue")
})

plot_list_xylim <- lapply(names(l_enb), function(n){
  ggplot(l_enb[[n]], aes(x = N, y = (ENB/1e6))) +
    geom_line() +
    xlab("Sample size") +
    ylab("ENB (Million $)") + 
    ggtitle(paste("ENB of", remove_date_from_name(n), "for strategy:", seb = ""),
            subtitle = l_enb[[n]]$Implementation[1]) +
    geom_vline(xintercept = mean(l_enb[[n]]$nstar), linetype = "dashed", 
               color = "gray", size = 0.8) +
    labs(caption = paste("ENB at N=2500:", round(mean(l_enb[[n]]$ENB[l_enb[[n]]$N == 2500]/1e6)), "and ENB at N*:", round(l_enb[[n]]$nstar/1e6), sep =" "), colour = "lightblue")+
    scale_x_continuous(limits = xlim) +
    scale_y_continuous(limits = ylim)
})

# arrange the plots in a grid
grid_plot <- ggarrange(plotlist = plot_list, nrow = n_rows_grid, ncol = n_cols_grid)+labs(title = "Expected Net Monetary Benefit - QALY") +theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))
grid_plot_xylim <- ggarrange(plotlist = plot_list_xylim, nrow = n_rows_grid, ncol = n_cols_grid)+labs(title = "Expected Net Monetary Benefit - QALY ") +theme(plot.title = element_text(face = "bold", size = 20, hjust = 0.5))

# save the plot
ggsave(filename = paste0("../figures/ENB_QALY_grid", suffix, ".png"), plot = grid_plot, width = 30, height = 30, units = "in")
ggsave(filename = paste0("../figures/ENB_QALY_grid_xylim", suffix, ".png"), plot = grid_plot_xylim, width = 30, height = 30, units = "in")

}

create_ENB_plots(perspective = "resp")
create_ENB_plots(perspective = "prosp")
```
#10. Summary of results

###10.0 Update plot settings (time order) for cumulative meta-analysis VOI plots
```{r}
time_order <- v_names_time # Add accurate time order from published studies
time_order <- intersect(time_order, l_names$v_names_trt_report_full) # Select only those studies that were included in the current dataset (in case only subsets are run through the model, this prevents an error message from non-included studies)
```

###10.1 Summary of results 
####10.1.1. QALY
```{r}
options(scipen = 999)

# Function to run the remainder of the code
run_remaining_analysis_QALY <- function(perspective) {
  
  # Determine output lists based on perspective
  if (perspective == "prosp") {
    suffix <- "_prosp"
    df_enb_plot_QALY <- df_enb_plot_QALY_prosp
    df_summary_cea_QALY_PSA_report <- (df_summary_cea_QALY_PSA_prosp)
  } else if (perspective == "resp") {
    suffix <- "_resp"
    df_enb_plot_QALY <- df_enb_plot_QALY_resp
    df_summary_cea_QALY_PSA_report <- (df_summary_cea_QALY_PSA_resp)
  } else {
    stop("Invalid perspective specified")
  }
  
  # Check if all the column names in the structures are identical. If so, merge the data
  rownames(df_summary_cea_QALY_PSA_report) <- remove_date_from_name(rownames(df_summary_cea_QALY_PSA_report))
  #colnames(df_enb_plot_QALY) <- remove_date_from_name(colnames(df_enb_plot_QALY)) # not needed, already removed
  
  df_enb_plot_order <- df_enb_plot_QALY[match(rownames(df_summary_cea_QALY_PSA_report), colnames(df_enb_plot_QALY))]
  
  if (all(rownames(df_summary_cea_QALY_PSA_report) == colnames(df_enb_plot_order))) {
    m_summary_results_new <- rbind(t(df_summary_cea_QALY_PSA_report), df_enb_plot_order)
  }
  
  df_summary_results_round <- format_table_final(as.data.frame(m_summary_results_new), 
                     v_thousand = c("Future patients", "Current patients"),
                     v_million  = c("EVPPI", "Costs RCT", "AWR", "OIR", "Costs RCT N=2500", "OIR N=2500", "AWR N=2500", "Approve"),
                     integer = TRUE)
  
  df_summary_results_round_format_integer <- df_summary_results_round
  df_summary_results_round_format_integer[is.na(df_summary_results_round_format_integer)] <- "n/a"
  
  time_order <- sort(names(df_summary_results_round_format_integer))
  df_summary_results_round_format_integer_timeline <- df_summary_results_round_format_integer[,time_order]
  
  png(paste0("../figures/table_summary_results_integer_big_timeline_QALY", suffix, ".png"), width = 3000, height = 1000, bg = "white", pointsize = 22)
  grid.table(df_summary_results_round_format_integer_timeline)
  dev.off()

    # Assign created lists to global variables
      # Assign created lists to global variables
  assign(paste0("table_summary_results_integer_big_timeline_QALY_", perspective),   df_summary_results_round_format_integer_timeline, envir = .GlobalEnv)
 
}

# Run the function for the required perspectives
run_remaining_analysis_QALY(perspective = "resp")
run_remaining_analysis_QALY(perspective = "prosp")

```


####10.1.2. LY
```{r}
options(scipen = 999)

# Function to run the remainder of the code
run_remaining_analysis_LY <- function(perspective) {
  
  # Determine output lists based on perspective
  if (perspective == "prosp") {
    suffix <- "_prosp"
    df_enb_plot_LY <- df_enb_plot_LY_prosp
    df_summary_cea_LY_PSA_report <- (df_summary_cea_LY_PSA_prosp)
  } else if (perspective == "resp") {
    suffix <- "_resp"
    df_enb_plot_LY <- df_enb_plot_LY_resp
    df_summary_cea_LY_PSA_report <- (df_summary_cea_LY_PSA_resp)
  } else {
    stop("Invalid perspective specified")
  }
  
  # Check if all the column names in the structures are identical. If so, merge the data
  rownames(df_summary_cea_LY_PSA_report) <- remove_date_from_name(rownames(df_summary_cea_LY_PSA_report))
  #colnames(df_enb_plot_LY) <- remove_date_from_name(colnames(df_enb_plot_LY)) # not needed, already removed
  
  df_enb_plot_order <- df_enb_plot_LY[match(rownames(df_summary_cea_LY_PSA_report), colnames(df_enb_plot_LY))]
  
  if (all(rownames(df_summary_cea_LY_PSA_report) == colnames(df_enb_plot_order))) {
    m_summary_results_new <- rbind(t(df_summary_cea_LY_PSA_report), df_enb_plot_order)
  }
  
  df_summary_results_round <- format_table_final(as.data.frame(m_summary_results_new), 
                     v_thousand = c("Future patients", "Current patients"),
                     v_million  = c("EVPPI", "Costs RCT", "AWR", "OIR", "Costs RCT N=2500", "OIR N=2500", "AWR N=2500", "Approve"),
                     integer = TRUE)
  
  df_summary_results_round_format_integer <- df_summary_results_round
  df_summary_results_round_format_integer[is.na(df_summary_results_round_format_integer)] <- "n/a"
  
  time_order <- sort(names(df_summary_results_round_format_integer))
  df_summary_results_round_format_integer_timeline <- df_summary_results_round_format_integer[,time_order]
  
  png(paste0("../figures/table_summary_results_integer_big_timeline_LY", suffix, ".png"), width = 3000, height = 1000, bg = "white", pointsize = 22)
  grid.table(df_summary_results_round_format_integer_timeline)
  dev.off()
  
      # Assign created lists to global variables
  assign(paste0("table_summary_results_integer_big_timeline_LY_", perspective),   df_summary_results_round_format_integer_timeline, envir = .GlobalEnv)
  
}

# Run the function for the required perspectives
run_remaining_analysis_LY(perspective = "resp")
run_remaining_analysis_LY(perspective = "prosp")

```


# 11. Combine Prospective / Retrospective results
```{r}
# Add row Retrospective, Prospective and main analyis
table_summary_results_integer_big_timeline_QALY_prosp
table_summary_results_integer_big_timeline_QALY_resp

rownames_mainanalysis <- c("Cost-effective", "Incr cost Rx", "Incr effect Rx", 
                           "ICER", "Incr NMB", "Incr NHB")

# Note: If not using N = 2500 as max feasible, then use the following code
#rownames_VOI <- c("EVPPI (Million)", "Future patients (Thousand)", "Current patients (Thousand)", 
#                  "Optimal strategy", "Optimal sample size (N*)", "Costs RCT (Million)", "EVSI N*",
#                  "OIR (Net Value,Million)", "AWR (Net Value,Million)", "Approve (Net Value,Million)", "Reject")

rownames_VOI <- c("EVPPI (Million)", "Future patients (Thousand)", "Current patients (Thousand)", 
                  "Optimal strategy", "Optimal sample size (N*)", "Costs RCT N=2500 (Million)", "EVSI N=2500",
                  "OIR N=2500 (Million)", "AWR N=2500 (Million)", "Approve (Net Value,Million)", "Reject")

# Change the prospective and retrospective tables into a tibble to facilitate data manipulation
df_prosp <- table_summary_results_integer_big_timeline_QALY_prosp %>%
  rownames_to_column(var = "Item") %>%
  mutate(Analysis = case_when(
    Item %in% rownames_mainanalysis ~ "Main analysis",
    Item %in% rownames_VOI ~ "Prospective analysis",
    TRUE ~ ""
  )) %>%
  filter(Analysis != "")

df_resp <- table_summary_results_integer_big_timeline_QALY_resp %>%
  rownames_to_column(var = "Item") %>%
  mutate(Analysis = case_when(
    Item %in% rownames_VOI ~ "Retrospective analysis",
    TRUE ~ ""
  )) %>%
  filter(Analysis != "")

# Combine the data frames
df_combined_resp_prosp <- bind_rows(df_prosp, df_resp)

# Rearrange columns
df_combined_resp_prosp <- df_combined_resp_prosp %>%
  select(Analysis, Item, starts_with("k"))


view(df_combined_resp_prosp)
```
# 12. Create timeline figure
## 12.1 Create dataframe for timeline
```{r}
# Specify last date that will be included in timeline
end_timeline <- as.Date("2022-01-01")

# Entry data
## Publications
v_dates <- as.Date(substr(names(l_param_trt),(nchar(names(l_param_trt))+1)-10,nchar(names(l_param_trt)))) 
sorted_dates <- v_dates[order(v_dates)]
start <- sorted_dates
end   <- sorted_dates # Note, alternatively, use qualitative dataframe and use start date, end date, date of publication
event <- colnames(df_combined_resp_prosp)[!colnames(df_combined_resp_prosp) %in% c("Analysis", "Item")]
group <- rep("Publications", length(event))

df_timeline_publications <- data.frame (event, group, start, end)

## Cumulative meta analysis
### use the values saved in param_qual under cma_strategy
cma_strategy_rows <- param_qual[param_qual$Param == "cma_strategy", ] # select rows that specify strategy
event <- cma_strategy_rows$Med # Extract the "Med" values from the cma_strategy rows
start <- sorted_dates
end   <- c(sorted_dates[-1], end_timeline) # move each date to the left, remove the first date from start, add the end of the timeline as the last date.
group <- rep("Cumulative MA", length(event))

df_timeline_cma <- data.frame (event, group, start, end)

## Policy recommendations
### No approval: first included publication. EUA: 24-06-2021. Approval: 22_12_2021
first_date <- sorted_dates[1]
eua_date <- as.Date("2021-06-24")  
# approve_date <- as.Date("2022-12-21") # Add if this becomes part of the timeline

# If Approval is reached:
#event <- c("No approval status", "EUA", "Approve")
#start <- c(first_date, eua_date, approve_date)
#end   <- c(eua_date, approve_date,end_timeline)
#group <- rep("Policy", length(event))

# If Approval is not yet reached:
event <- c("No approval status", "EUA")
start <- c(first_date, eua_date)
end   <- c(eua_date, end_timeline)
group <- rep("Policy", length(event))

df_timeline_policy <- data.frame (event, group, start, end)


## VOI prospective
optimal_strategy_values <- unlist(unname(as.vector(df_prosp[df_prosp$Item == "Optimal strategy", ])))
v_optimal_strategy_values <- optimal_strategy_values[!optimal_strategy_values %in% c("Optimal strategy", "Prospective analysis")]
v_optimal_strategy_values_prosp <- v_optimal_strategy_values
event <- v_optimal_strategy_values
start <- sorted_dates
end <- c(sorted_dates[-1], end_timeline) # move each date to the left, remove the first date from start, add the end of the timeline as the last date.
group <- rep("Prospective VOI", length(event))

df_timeline_voi_prosp <- data.frame (event, group, start, end)

## VOI retrospective
optimal_strategy_values <- unlist(unname(as.vector(df_resp[df_resp$Item == "Optimal strategy", ])))
v_optimal_strategy_values <- optimal_strategy_values[!optimal_strategy_values %in% c("Optimal strategy", "Retrospective analysis")]
v_optimal_strategy_values_resp <- v_optimal_strategy_values
event <- v_optimal_strategy_values
start <- sorted_dates
end <- c(sorted_dates[-1], end_timeline) # move each date to the left, remove the first date from start, add the end of the timeline as the last date.
group <- rep("Retrospective VOI", length(event))

df_timeline_voi_resp <- data.frame (event, group, start, end)

# Combine the approachhes into df_timeline
df_timeline <- rbind(df_timeline_publications, df_timeline_cma, df_timeline_policy, df_timeline_voi_prosp, df_timeline_voi_resp)
df_timeline

# Specify colors conditional on status

df_timeline$color <- case_when(
  df_timeline$event == "Reject" ~ "#DD4B39",
  df_timeline$event == "Approve" ~ "#a5d6a7",
  df_timeline$event %in% c("AWR", "EUA") ~ "#DEEBF7",
  df_timeline$event == "EUA" ~ "#DEEBF7",
  df_timeline$event == "OIR" ~ color_print,
  df_timeline$event == "No approval status" ~ color_print,
  TRUE ~ "#1565c0")

save(df_timeline, file = "../output/df_timeline.rda")
write_xlsx(df_timeline, "../output/df_timeline.xlsx")

# Create additional "clean" version of the dataframe where if multiple events within one group happen at the same start date only the latter is saved; this table is only used for visualization purposes
remove_duplicates <- function(df) {
  df %>% 
    group_by(group) %>%
    arrange(group, start) %>%
    filter(!duplicated(start, fromLast = TRUE)) %>%
    ungroup()
}

# Apply the function to your dataframe
df_timeline_clean <- remove_duplicates(df_timeline)

# Print the cleaned start dates (to check if done correctly)
df_timeline_clean$start

# Reorder timeline dataframe
# Create an ordered factor for the groups
group_order <- c("Publications", "Policy", "Cumulative MA", "Prospective VOI", "Retrospective VOI")
df_timeline_clean$group <- factor(df_timeline_clean$group, levels = group_order, ordered = TRUE)
df_timeline_clean <- df_timeline_clean %>%  arrange(group, start)
df_timeline_clean
```


### 12.1 Create figures timeline
```{r}
load(file = "../output/df_timeline.rda")
#df_timeline <- read_excel("../output/df_timeline.xlsx") # load from excel if making any adjustments for layout

# Overwrite with df_timeline_clean to avoid multiple events at same time
df_timeline <- df_timeline_clean

# Interactive using vistime
vistime(df_timeline)

# To improve the readability of the graph, we want to group together the values that are the same within one timeline so that the label is printed only once

# Saveable using ggplot2
gg_vistime(df_timeline)

# With labels
df_timeline_plot <- df_timeline %>%
  gg_vistime(start = "start", end = "end", title = "Timeline Plot of 4 approaches to Decision Making", 
             group = "group", event = "event", color = "color")

ggplot2::ggsave(
  plot = df_timeline_plot, 
  filename = here("../figures", "timeline_plot.png"), 
  device = "png"
)

df_timeline_plot

# Without labels
df_timeline_plot_nolabel <- df_timeline %>%
  gg_vistime(start = "start", end = "end", title = "Timeline of publications and 4 approaches to Decision Making", 
             group = "group", event = "event", color = "color", show_labels = FALSE) 
df_timeline_plot_nolabel

ggplot2::ggsave(
  plot = df_timeline_plot_nolabel, 
  filename = here("../figures", "timeline_plot_nolabel.png"), 
  device = "png"
)


```

###12.1.2 Add legend
```{r}
# Create legend data
legend_data <- data.frame(
  color = c("#DD4B39", "#a5d6a7", "#DEEBF7", "#dfb94c"),
  event = c("Reject", "Approve", "AWR/EUA", "OIR/No approval status")
)

# Function to create a temporary file path for the plot images
temp_file <- function(ext = "png") {
  tempfile(tmpdir = tempdir(), fileext = paste0(".", ext))
}

# Create the base R plot with adjusted legend position and font size
plot(NULL, xaxt = 'n', yaxt = 'n', bty = 'n', ylab = '', xlab = '', xlim = 0:1, ylim = 0:1)
legend("center", legend = c("Reject", "Approve", "AWR/EUA", "OIR/No approval status"), pch = 15, pt.cex = 5, cex = 2.5, bty = 'n', col = c("#DD4B39", "#a5d6a7", "#DEEBF7", "#dfb94c"))
mtext("Optimal strategy", at = 0.2, cex = 2)

# Save the base R plot with larger dimensions to a temporary file
legend_file <- temp_file()
png(legend_file, width = 600, height = 600)
plot(NULL, xaxt = 'n', yaxt = 'n', bty = 'n', ylab = '', xlab = '', xlim = 0:1, ylim = 0:1)
legend("topleft", legend = c("Reject", "Approve", "AWR/EUA", "OIR/No approval status"), pch = 15, pt.cex = 7, cex = 3.5, bty = 'n', col = c("#DD4B39", "#a5d6a7", "#DEEBF7", "#dfb94c"))
mtext("Optimal strategy", at = 0.2, cex = 3.5)
dev.off()

# Assuming df_timeline_plot_nolabel is a ggplot object
# Save the ggplot object to a temporary file
timeline_file <- temp_file()
ggsave(timeline_file, df_timeline_plot_nolabel, width = 10, height = 10)

# Combine the plots using magick
timeline_image <- image_read(timeline_file)
legend_image <- image_read(legend_file)
combined_image <- image_append(c(timeline_image, legend_image), stack = FALSE)


# Save the combined image to the specified folder
image_write(combined_image, "../figures/timeline_inc_legend.png")

# Clean up temporary files
unlink(legend_file)
unlink(timeline_file)
```



## 12.2 Calculate loss from wrong strategy
- Take value from optimal strategy retrospective
- Save suggested optimal value by alternatlive approach
- Take respective value from retrospective strategy from summary table for that strategy
- Take that value - the value optimal strategy = loss
```{r}
df_results_resp <- table_summary_results_integer_big_timeline_QALY_resp # Choose the df to be used for loss calculation
v_dates

# These are the optimal strategies for each of the approaches
v_optimal_strategy_values
v_optimal_strategy_values_prosp
cma_strategy_rows$Med

# Note: timeline policy addressed in next chunk

##### Retrospective
# Change to "OIR (Million)", "AWR (Million)", "Approve (Million)", "Reject" so that it matches the rownames
# Use this next line if using the N=2500 value (Note: Adjust if using the optimal values)
v_optimal_strategy_values_updated <- ifelse(v_optimal_strategy_values == "AWR", "AWR N=2500", 
                                            ifelse(v_optimal_strategy_values == "OIR", "OIR N=2500",
                                                   ifelse(v_optimal_strategy_values == "Approve", "Approve", v_optimal_strategy_values)))


# Remove the strategy name if still present in the vector (if this has become a rowname in previous code, otherwise this code doesn't change the vector)
if ("Retrospective analysis" %in% v_optimal_strategy_values_updated) {
  v_optimal_strategy_values_updated <- v_optimal_strategy_values_updated[v_optimal_strategy_values_updated != "Retrospective analysis"]
}

# Save only the relevant rows, to make it easier to check if the correct value is taken
df_loss <- df_results_resp[unique(v_optimal_strategy_values_updated),]

# Create a new vector that can save the respective values
new_vec <- numeric(length = ncol(df_loss))

# Extract values
for (i in 1:length(v_optimal_strategy_values_updated)) {
  if (v_optimal_strategy_values_updated[i] == "AWR N=2500") {
    new_vec <- new_vec + as.numeric(df_loss["AWR N=2500",]) * (i == seq_along(v_optimal_strategy_values_updated))
  } else if (v_optimal_strategy_values_updated[i] == "OIR N=2500") {
    new_vec <- new_vec + as.numeric(df_loss["OIR N=2500",]) * (i == seq_along(v_optimal_strategy_values_updated))
  } else if (v_optimal_strategy_values_updated[i] == "Approve") {
    new_vec <- new_vec + as.numeric(df_loss["Approve",]) * (i == seq_along(v_optimal_strategy_values_updated))
  } else if (v_optimal_strategy_values_updated[i] == "Reject") {
    new_vec <- new_vec + as.numeric(df_loss["Reject",]) * (i == seq_along(v_optimal_strategy_values_updated))
  }
}
# Save extracted values
v_optimal_strategy_value_EV_resp <- new_vec

##### Prospective
df_results_prosp <- table_summary_results_integer_big_timeline_QALY_prosp # Choose the df to be used for loss calculation

# Change to "OIR (Million)", "AWR (Million)", "Approve (Million)", "Reject" so that it matches the rownames
v_optimal_strategy_values_updated <- ifelse(v_optimal_strategy_values_prosp == "AWR", "AWR N=2500", 
                                            ifelse(v_optimal_strategy_values_prosp == "OIR", "OIR N=2500",
                                                   ifelse(v_optimal_strategy_values_prosp == "Approve", "Approve", v_optimal_strategy_values)))

# Remove the strategy name if still present in the vector
if ("Prospective analysis analysis" %in% v_optimal_strategy_values_updated) {
  v_optimal_strategy_values_updated <- v_optimal_strategy_values_updated[v_optimal_strategy_values_updated != "Prospective analysis"]
}

# Save only the relevant rows, to make it easier to check if the correct value is taken; Always from gold standard retrospective
df_loss <- df_results_resp[unique(v_optimal_strategy_values_updated),] # Keep as _resp! This is the reference

# Create a new vector that can save the respective values
new_vec <- numeric(length = ncol(df_loss))

# Extract values
for (i in 1:length(v_optimal_strategy_values_updated)) {
  if (v_optimal_strategy_values_updated[i] == "AWR N=2500") {
    new_vec <- new_vec + as.numeric(df_loss["AWR N=2500",]) * (i == seq_along(v_optimal_strategy_values_updated))
  } else if (v_optimal_strategy_values_updated[i] == "OIR N=2500") {
    new_vec <- new_vec + as.numeric(df_loss["OIR N=2500",]) * (i == seq_along(v_optimal_strategy_values_updated))
  } else if (v_optimal_strategy_values_updated[i] == "Approve") {
    new_vec <- new_vec + as.numeric(df_loss["Approve",]) * (i == seq_along(v_optimal_strategy_values_updated))
  } else if (v_optimal_strategy_values_updated[i] == "Reject") {
    new_vec <- new_vec + as.numeric(df_loss["Reject",]) * (i == seq_along(v_optimal_strategy_values_updated))
  }
}
# Save extracted values
v_optimal_strategy_value_EV_prosp <- new_vec

##### CMA
# Change to "OIR (Million)", "AWR (Million)", "Approve (Million)", "Reject" so that it matches the rownames
v_optimal_strategy_values_updated <- ifelse(cma_strategy_rows$Med == "AWR", "AWR N=2500", 
                                            ifelse(cma_strategy_rows$Med == "OIR", "OIR N=2500",
                                                   ifelse(cma_strategy_rows$Med == "Approve", "Approve", v_optimal_strategy_values)))

# Save only the relevant rows, to make it easier to check if the correct value is taken
df_loss <- df_results_resp[unique(v_optimal_strategy_values_updated),] # Keep as _resp! This is the reference

# Create a new vector that can save the respective values
new_vec <- numeric(length = ncol(df_loss))

# Extract values
for (i in 1:length(v_optimal_strategy_values_updated)) {
  if (v_optimal_strategy_values_updated[i] == "AWR N=2500") {
    new_vec <- new_vec + as.numeric(df_loss["AWR N=2500",]) * (i == seq_along(v_optimal_strategy_values_updated))
  } else if (v_optimal_strategy_values_updated[i] == "OIR N=2500") {
    new_vec <- new_vec + as.numeric(df_loss["OIR N=2500",]) * (i == seq_along(v_optimal_strategy_values_updated))
  } else if (v_optimal_strategy_values_updated[i] == "Approve") {
    new_vec <- new_vec + as.numeric(df_loss["Approve",]) * (i == seq_along(v_optimal_strategy_values_updated))
  } else if (v_optimal_strategy_values_updated[i] == "Reject") {
    new_vec <- new_vec + as.numeric(df_loss["Reject",]) * (i == seq_along(v_optimal_strategy_values_updated))
  }
}
# Save extracted values
v_optimal_strategy_value_EV_cma <- new_vec

# The new vectors, when following the optimal strategy according to the approach, what is the respective value in the retrospective analysis?
v_optimal_strategy_value_EV_cma
v_optimal_strategy_value_EV_prosp
v_optimal_strategy_value_EV_resp
```

###12.3 Calculate expected value policy approach
- Align policy approach with timeline publication
- Repeat current policy approach until next event.
- Count number of times a publication came out before each event, repeat the event that amount of times, repeat the last value in events until the publication dates end.
- Set no approval status yet to value of OIR and EUA to AWR
```{r}
#df_timeline_policy
v_publ_date <- (v_dates)
v_policy_date <- df_timeline_policy$start
v_policy_event <- df_timeline_policy$event

# Adjust vector with policy events, to have one blank event prior to the vector to initialize on
v_policy_event_code <- c("startcode", v_policy_event)

# initialize variables
policy_events <- character(length(v_publ_date))
current_event_index <- 1
current_policy_index <- 1
next_event_date <- v_policy_date[current_policy_index]

# loop through publication dates and assign policy events
for (i in seq_along(v_publ_date)) {
  
  # if the current publication date is after the next policy event date, update the event and index
  if (v_publ_date[i] >= next_event_date) {
    current_policy_index <- current_policy_index + 1
    current_event_index <- current_event_index + 1
    next_event_date <- ifelse(current_policy_index > length(v_policy_date), NA, v_policy_date[current_policy_index])
  }
  
  # assign the policy event to the current publication date
  policy_events[i] <- v_policy_event_code[current_event_index]
  
  # if there are no more policy events, repeat the last one for the remaining dates
  if (is.na(next_event_date)) {
    policy_events[(i + 1):length(v_publ_date)] <- v_policy_event_code[length(v_policy_event_code)]
    break
  }
}

# print the resulting policy events
policy_events

# Use the vector policy events to calculate the respective Expected Value from this strategy
##### Policy
# Change to "OIR (Million)", "AWR (Million)", "Approve (Million)", "Reject" so that it matches the rownames
v_optimal_strategy_values_updated <- ifelse(policy_events == "EUA", "AWR N=2500", 
                                            ifelse(policy_events == "No approval status", "OIR N=2500",
                                                   ifelse(policy_events == "Approve", "Approve", v_optimal_strategy_values)))

# Save only the relevant rows, to make it easier to check if the correct value is taken
df_loss <- df_results_resp[unique(v_optimal_strategy_values_updated),] # Keep retrospective, this is the reference

# Create a new vector that can save the respective values
new_vec <- numeric(length = ncol(df_loss))

# Extract values
for (i in 1:length(v_optimal_strategy_values_updated)) {
  if (v_optimal_strategy_values_updated[i] == "AWR N=2500") {
    new_vec <- new_vec + as.numeric(df_loss["AWR N=2500",]) * (i == seq_along(v_optimal_strategy_values_updated))
  } else if (v_optimal_strategy_values_updated[i] == "OIR N=2500") {
    new_vec <- new_vec + as.numeric(df_loss["OIR N=2500",]) * (i == seq_along(v_optimal_strategy_values_updated))
  } else if (v_optimal_strategy_values_updated[i] == "Approve") {
    new_vec <- new_vec + as.numeric(df_loss["Approve",]) * (i == seq_along(v_optimal_strategy_values_updated))
  } else if (v_optimal_strategy_values_updated[i] == "Reject") {
    new_vec <- new_vec + as.numeric(df_loss["Reject",]) * (i == seq_along(v_optimal_strategy_values_updated))
  }
}
# Save extracted values
v_optimal_strategy_value_EV_policy <- new_vec
v_optimal_strategy_value_EV_policy
```

###12.4 Create loss table and figures
```{r}
# Check that all strategy EV's now contain the same number of items (number of publications), and that EV_resp is always the highest
v_optimal_strategy_value_EV_cma
v_optimal_strategy_value_EV_prosp
v_optimal_strategy_value_EV_policy
v_optimal_strategy_value_EV_resp

# Check the strategies from each of the approaches
v_optimal_strategy_values
v_optimal_strategy_values_prosp
cma_strategy_rows$Med
policy_events

v_publ_date


dput(v_optimal_strategy_value_EV_cma    )
dput(v_optimal_strategy_value_EV_prosp  )
dput(v_optimal_strategy_value_EV_policy )
dput(v_optimal_strategy_value_EV_resp   )
dput(v_optimal_strategy_values          ) 
dput(v_optimal_strategy_values_prosp    )
dput(cma_strategy_rows$Med              )
dput(policy_events                      )

# Create a new table
# create a dataframe with two rows and one column each
df_EV_loss  <- data.frame(Date = v_publ_date, 
                 `Optimal strategy (Retrospective)`    = v_optimal_strategy_values,
                 `EV Optimal strategy (Retrospective)` = v_optimal_strategy_value_EV_resp,
                 `Policy strategy`                     = policy_events  ,
                 `Policy EV`                           = v_optimal_strategy_value_EV_policy,
                 `Policy EV loss`                      = v_optimal_strategy_value_EV_resp - v_optimal_strategy_value_EV_policy ,
                 `CMA strategy`                        = cma_strategy_rows$Med ,
                 `CMA EV`                              = v_optimal_strategy_value_EV_cma,
                 `CMA EV loss`                         = v_optimal_strategy_value_EV_resp - v_optimal_strategy_value_EV_cma,
                 `Prospective VOI strategy`            = v_optimal_strategy_values_prosp,
                 `Prospective VOI EV`                  = v_optimal_strategy_value_EV_prosp,
                 `Prospective VOI EV loss`             = v_optimal_strategy_value_EV_resp -v_optimal_strategy_value_EV_prosp
                 )

# Change to tibble for printing / reading, in transpose
df_EV_loss_t <- as_tibble(t(df_EV_loss))
colnames(df_EV_loss_t) <- as.character(df_EV_loss[1, ])
colnames(df_EV_loss_t) <- v_names_time
df_EV_loss_t$Item <- colnames(df_EV_loss)
df_EV_loss_t <- df_EV_loss_t %>%
  select(Item, everything())

#df<- df_EV_loss_t %>%
#  mutate(across(where(~ grepl("EV", Item)), as.numeric))

# If Item is not recognized as a column name, use this
colnames(df_EV_loss_t)
df <- df_EV_loss_t %>% 
  mutate(across(where(~ grepl("EV",1)), as.numeric))
df

# Use dataframe to create graph
df_EV_loss

png(paste0("../figures/table_EV_loss.png"), width = 3000, height = 1000, bg = "white", pointsize = 22)
grid.table(df_EV_loss)
dev.off()

```
###12.5 Plot expected value and loss
```{r}
color_policy <- "#52a98e"
color_cma <- color_print
color_prosp <- "#A65C4F"
color_resp <- "#c6e2cf"


# Plot values over time
ggplot(df_EV_loss, aes(x = Date, y = EV.Optimal.strategy..Retrospective., group = 1)) +
  geom_line(aes(color = "EV Optimal strategy (Retrospective)")) +
  geom_line(aes(y = Policy.EV, color = "Policy EV")) +
  geom_line(aes(y = CMA.EV, color = "CMA EV")) +
  geom_line(aes(y = Prospective.VOI.EV, color = "Prospective VOI EV")) +
  scale_y_continuous(name = "Expected Value (Million $)", labels = scales::comma) +
  scale_color_manual(name = "Item", values = c("EV Optimal strategy (Retrospective)" = color_resp, 
                                                "Policy EV" = color_policy, 
                                                "CMA EV" = color_cma,
                                                "Prospective VOI EV" = color_prosp)) +
  labs(title = "Expected Value over Time",
       x = "Date") +
  theme_minimal()

# Plot loss over time
# Plot values over time
ggplot(df_EV_loss, aes(x = Date, y = EV.Optimal.strategy..Retrospective., group = 1)) +
  geom_line(aes(color = "EV Optimal strategy (Retrospective)")) +
  geom_line(aes(y = Policy.EV.loss, color = "EV loss from policy approach")) +
  geom_line(aes(y = CMA.EV.loss, color = "EV loss from CMA approach")) +
  geom_line(aes(y = Prospective.VOI.EV.loss, color = "EV loss from Prospective VOI approach")) +
  scale_y_continuous(name = "Expected Value (Million)", labels = scales::comma) +
  scale_color_manual(name = "Item", values = c("EV Optimal strategy (Retrospective)" = color_resp, 
                                                "EV loss from Policy approach" = color_policy, 
                                                "EV loss from CMA approach" = color_cma,
                                                "EV loss from Prospective VOI approach" = color_prosp)) +
  labs(title = "Expected Value over Time",
       x = "Date") +
  theme_minimal()

# Create a bar chart
# Use names study as events
v_names_report <- remove_date_from_name(  v_names_time)
df_EV_loss_2 <- df_EV_loss #create copy
df_EV_loss_2$Study <- v_names_report
df_EV_loss_2

# Pivot the data from wide to long format and filter only the relevant columns
df_long <- df_EV_loss_2 %>% 
  select(Study, c("CMA.EV.loss", "Policy.EV.loss", "Prospective.VOI.EV.loss")) %>% 
  pivot_longer(cols = c("CMA.EV.loss", "Policy.EV.loss", "Prospective.VOI.EV.loss"), names_to = "group", values_to = "value")

# Reorder the factor levels of Study according to v_names_report
df_long$Study <- factor(df_long$Study, levels = v_names_report)

# Create the bar chart with custom colors
plot_EV_loss_publ <- ggplot(df_long, aes(x = Study, y = value, fill = group)) +
  geom_col(position = position_dodge(width = 0.9), color = "black", size = 0.3) +
  scale_fill_manual(values = c(color_print, my_green, my_greengray)) +
  ggtitle("Expected Value loss from choosing suboptimal strategy") +
  labs(x = "Study", y = "EV (Million)", fill = "") +
  theme_minimal() +
  theme(plot.background = element_rect(fill = "white"),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 8), 
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank())

ggsave(filename = "../figures/EV_loss_publ.png", plot = plot_EV_loss_publ, width = 10, height = 10, units = "in")
plot_EV_loss_publ

# Create zoomed in figure to illustrate the differences (ylim)
plot_EV_loss_publ_zoom <- ggplot(df_long, aes(x = Study, y = value, fill = group)) +
  geom_col(position = position_dodge(width = 0.9), color = "black", size = 0.3) +
  scale_fill_manual(values = c(color_print, my_green, my_greengray)) +
  ggtitle("Expected Value loss from choosing suboptimal strategy") +
  labs(x = "Study", y = "EV (Million)", fill = "") +
  theme_minimal() +
  theme(plot.background = element_rect(fill = "white"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 8), 
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  coord_cartesian(ylim = c(0, 25000))  # Set y-axis limit to 25000

ggsave(filename = "../figures/EV_loss_publ_zoom.png", plot = plot_EV_loss_publ_zoom, width = 10, height = 10, units = "in")
plot_EV_loss_publ_zoom

```

#13 Plot key values over time
```{r}
df_combined_resp_prosp # Make sure that this table represents either the N <2500 values or the N=optimal values, depending on which should be displayed

### EVPPI
# Convert the dates in k0_treatments column to date format
new_row_dates <- c("Main analysis", "Date", as.character(v_dates))
df_combined_resp_prosp2 <- rbind(df_combined_resp_prosp, new_row_dates)

# filter the data
df_plot <- df_combined_resp_prosp2 %>% 
  filter(Analysis %in% c("Prospective analysis", "Retrospective analysis"),
         Item %in% c("EVPPI (Million)", "Date"))

# melt the data
df_plot <- df_plot %>% 
  pivot_longer(cols = -c(Analysis, Item), names_to = "Date", values_to = "Value") 

df_plot$Date <- rep(v_dates,2) # Repeat 2 times, 1 for prosp, 1 for resp

# create the plot
plot_EVPPI_time <- ggplot(df_plot, aes(x = as.Date(Date), y = as.numeric(Value), color = Analysis)) +
  geom_line() +
  scale_y_continuous(labels = scales::dollar) +
  scale_color_manual(values = c( "Prospective analysis" = color_prosp, "Retrospective analysis" = color_resp)) +
  labs(title = "EVPPI per VOI approach over time",
       y = "EVPPI (Million)",
       x = "Date",
       color = "VOI Approach")


ggsave("../figures/plot_EVPPI_time.png", width = 10, height = 6, bg = "white")



```

```{r}
# filter the data for each item separately
df_main_inc_costs <- df_combined_resp_prosp2 %>% 
  filter(Analysis == "Main analysis", Item == "Incr cost Rx")

df_main_inc_qalys <- df_combined_resp_prosp2 %>% 
  filter(Analysis == "Main analysis", Item ==  "Incr effect Rx")

df_main_inc_nmb <- df_combined_resp_prosp2 %>% 
  filter(Analysis == "Main analysis", Item == "Incr NMB")

# melt the data for each item separately
df_main_inc_costs <- df_main_inc_costs %>% 
  pivot_longer(cols = -c(Analysis, Item), names_to = "Date", values_to = "Value") 
df_main_inc_costs$Date <- rep(v_dates, each = 1) # only once as this is only the main analysis

df_main_inc_qalys <- df_main_inc_qalys %>% 
  pivot_longer(cols = -c(Analysis, Item), names_to = "Date", values_to = "Value") 
df_main_inc_qalys$Date <- rep(v_dates, each = 1)

df_main_inc_nmb <- df_main_inc_nmb %>% 
  pivot_longer(cols = -c(Analysis, Item), names_to = "Date", values_to = "Value") 
df_main_inc_nmb$Date <- rep(v_dates, each = 1)

# create plots for each item separately and combine them
plot1 <- ggplot(df_main_inc_costs, aes(x = as.Date(Date), y = as.numeric(Value))) +
  geom_line(color = my_darkgreen) +
  scale_y_continuous(labels = scales::dollar) +
  labs(title = "iCosts estimate over time",
       y = "Incremental Costs ($)",
       x = "Date")

plot2 <- ggplot(df_main_inc_qalys, aes(x = as.Date(Date), y = as.numeric(Value))) +
  geom_line(color = my_darkred) +
  labs(title = "iQALYs estimate over time",
       y = "Incremental QALYs",
       x = "Date")

plot3 <- ggplot(df_main_inc_nmb, aes(x = as.Date(Date), y = as.numeric(Value))) +
  geom_line(color = color_print) +
  scale_y_continuous(labels = scales::dollar) +
  labs(title = "iNMB estimate over time",
       y = "Incremental net monetary benefit ($)",
       x = "Date")

# arrange the plots in one row using ggarrange
ggarrange(plot1, plot2, plot3, ncol = 3)

ggsave("../figures/Main analysis - time.png", ggarrange(plot1, plot2, plot3, ncol = 3), width = 12, height = 4)


```


# Adjust rounding for tables manuscript
```{r}
# Function to convert the complex dataframe-list structure in this code
convert_to_numeric <- function(x) {
  if(is.data.frame(x) | is.list(x)) {
    return(modify(x, convert_to_numeric)) # recursion: apply the function to each element of the list or data frame
  }
  
  if(is.character(x)) {
    x_numeric <- suppressWarnings(as.numeric(x))
    if(any(!is.na(x_numeric))) { # if any elements could be converted to numeric
      x[!is.na(x_numeric)] <- round(x_numeric[!is.na(x_numeric)], 2)
    }
  }
  
  return(x)
}

# Convert those tables that are used in the paper
df_combined_resp_prosp_rounded <- convert_to_numeric(df_combined_resp_prosp)
df_combined_resp_prosp_rounded

table_summary_results_integer_big_timeline_QALY_prosp_rounded <- convert_to_numeric(table_summary_results_integer_big_timeline_QALY_prosp)
rownames(table_summary_results_integer_big_timeline_QALY_prosp_rounded) <- rownames(table_summary_results_integer_big_timeline_QALY_prosp)
table_summary_results_integer_big_timeline_QALY_prosp_rounded

table_summary_results_integer_big_timeline_QALY_resp_rounded <- convert_to_numeric(table_summary_results_integer_big_timeline_QALY_resp)
rownames(table_summary_results_integer_big_timeline_QALY_resp_rounded) <- rownames(table_summary_results_integer_big_timeline_QALY_resp)
table_summary_results_integer_big_timeline_QALY_resp_rounded

```


# 14 Sensitivity analyses
Adjust initial parameters accordingly at the start of the code to choose the sensitivity analysis, run analysis, then save key results as follows in the assigned folder
```{r}

# Specify which items should be collected and saved
for (suffix in sa_suffixes) {
  # Save plots and images with the current suffix
  ggsave(filename = paste0("../figures/sensitivity_analyses/EV_loss_publ_", suffix, ".png"), plot = plot_EV_loss_publ, width = 10, height = 10, units = "in")
  image_write(combined_image, paste0("../figures/sensitivity_analyses/timeline_inc_legend_", suffix, ".png"))
  ggsave(filename = paste0("../figures/sensitivity_analyses/EV_loss_publ_", suffix, ".png"), plot = plot_EV_loss_publ_zoom, width = 10, height = 10, units = "in")
  image_write(combined_image, paste0("../figures/sensitivity_analyses/timeline_inc_legend_zoom_", suffix, ".png"))
  
  # Save table resp_prosp with the current suffix
  png(paste0("../figures/sensitivity_analyses/table_summary_resp_prosp_", suffix, ".png"), width = 3000, height = 1000, bg = "white", pointsize = 22)
  grid.table(df_combined_resp_prosp_rounded)
  dev.off()
  
  # Save table QALY_prosp with the current suffix
  png(paste0("../figures/sensitivity_analyses/table_summary_prosp_", suffix, ".png"), width = 3000, height = 1000, bg = "white", pointsize = 22)
  grid.table(table_summary_results_integer_big_timeline_QALY_prosp_rounded)
  dev.off()
  
  # Save table QALY_resp with the current suffix
  png(paste0("../figures/sensitivity_analyses/table_summary_resp_", suffix, ".png"), width = 3000, height = 1000, bg = "white", pointsize = 22)
  grid.table(table_summary_results_integer_big_timeline_QALY_resp_rounded)
  dev.off()

}

```


# 15 Print "Ready"
```{r}
print("ready")
```


# 16 Acknowlegdement
This study is based on our initial publication and model on emerging COVID-19 therapies. The current version of the projects expands on the initial project by taking into account the cumulative accrual of evidence across a timeline and integrates the predictions as they came out across time. The original work can be read on through in the following published work:
Dijk, S. W., Krijkamp, E. M., Kunst, N., Gross, C. P., Wong, J. B., & Hunink, M. M. (2022). Emerging therapies for COVID-19: the value of information from more clinical trials. Value in Health, 25(8), 1268-1280. <https://doi.org/10.1016/j.jval.2022.03.016>

All references to input parameters and datasets can be found in the provided excel parameters sheet and the main manuscript of this paper

For this study we made use of the template developed by the Decision Analysis in R for Technologies in Health (DARTH) workgroup: <http://darthworkgroup.com>.
We also build on the work performed by the Collaborative Network for Value of Information (ConVOI) group

We also thank the Institute For Health Metrics and Evaluation (IHME). Without their efforts to collect and make hospitalization data publicly available throughout the pandemic timeline, this methodological work would not be possible

This research was funded by the Gordon and Betty Moore Foundation through grant GBMF9634 to Johns Hopkins University to support the work of the Society for Medical Decision Making COVID-19 Decision Modeling Initiative.


